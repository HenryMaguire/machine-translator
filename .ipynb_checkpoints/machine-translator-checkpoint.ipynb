{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Neural Machine Translator\n",
    "\n",
    "In this notebook I will create a sequence-to-sequence translation system in Tensorflow. This will be done using single-layer encoder and decoder architecture, without using the Tensorflow native seq-to-seq modules. The method is heavily inspired by [these tutorials](https://github.com/ematvey/tensorflow-seq2seq-tutorials), particularly the implementation of previously fed tokens into the `tf.nn.raw_rnn` as proposed in the second tutorial. My code goes one step further and is able to feed in either the _ground truth_, previously generated tokens or a random combination of the two. While feeding in only the ground truth speeds up training and passing previously generated tokens increases robustness and performance, a combination of the two has been shown to interpolate between these two extremes. My NMT implementation was benchmarked against a direct dictionary based method using the [GoogleTrans](https://pypi.python.org/pypi/googletrans) API."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Loading the preprocessed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens in s_train are of type  <type 'int'>\n",
      "Tokens in raw_s_train are of type  <type 'unicode'>\n",
      "s_test and raw_s_test are the same length? :  True\n",
      "17742 17742\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import os\n",
    "import numpy as np\n",
    "from utils import load_obj\n",
    "\n",
    "logging.getLogger(\"tensorflow\").setLevel(logging.WARNING)\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "logging.basicConfig(level=logging.DEBUG, filename=\"logfile\", filemode=\"a+\",\n",
    "                        format=\"%(asctime)-15s %(levelname)-8s %(message)s\")\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "lang_t = 'en'\n",
    "lang_s = 'fr'\n",
    "prep_path = \"short_data/\"\n",
    "\n",
    "data_path = \"\"\n",
    "data_dict = load_obj(prep_path+'data_dic')\n",
    "s_train = data_dict[\"s_train\"] # preprocessed data\n",
    "t_train = data_dict[\"t_train\"]\n",
    "s_test = data_dict[\"s_test\"]\n",
    "t_test = data_dict[\"t_test\"]\n",
    "word2id_s = data_dict[\"word2id_s\"] # word-to-ID dictionaries \n",
    "word2id_t = data_dict[\"word2id_t\"]\n",
    "id2word_s = data_dict[\"id2word_s\"]\n",
    "id2word_t = data_dict[\"id2word_t\"]\n",
    "\n",
    "vocab_size_t = len(word2id_t.keys()) # Includes UNK, EOS and PAD tokens\n",
    "vocab_size_s = len(word2id_s.keys())\n",
    "\n",
    "raw_s_test = load_obj(\"short_data/source_test\") # Data for benchmark model \n",
    "raw_t_test = load_obj(\"short_data/target_test\") # Data for benchmark model \n",
    "print \"Tokens in s_train are of type \", type(s_test[0][0])\n",
    "print \"Tokens in raw_s_train are of type \", type(raw_s_test[0][0])\n",
    "print \"s_test and raw_s_test are the same length? : \", len(s_test) == len(raw_s_test)\n",
    "print len(s_test),  len(raw_s_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Benchmark model\n",
    "\n",
    "Here I use the [GoogleTrans]() python package to translate the corpus by translating each individual word in the text. There seems to be an issue with the number of JSON requests the model makes to the Google Translate service, so it needs to work in passes. If a phrase is skipped due to a JSON error, keep it stored and try again later (with a new Translator instance)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No JSON object could be decoded for phrase 110\n",
      "No JSON object could be decoded for phrase 236\n",
      "No JSON object could be decoded for phrase 368\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-150-76f784b6bebb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;31m# Takes a while to run, running this cell is not for the faint hearted\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;31m# BM_translated is ([french sequences], [english translations])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m \u001b[0mBM_translated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtranslate_word_by_word\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_s_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0;34m\"Corpus translated from {} to {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlang_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlang_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-150-76f784b6bebb>\u001b[0m in \u001b[0;36mtranslate_word_by_word\u001b[0;34m(source_text)\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;31m# Need to keep track of phrase ordering by labelling\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0msource_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mphr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mphr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[0mtrans_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskipped_phrases\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgoogletrans_pass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_lang\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlang_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m     print \"There are {} phrases which could not be translated first time around.\".format(\n\u001b[1;32m     33\u001b[0m                                                                     len(skipped_phrases))\n",
      "\u001b[0;32m<ipython-input-150-76f784b6bebb>\u001b[0m in \u001b[0;36mgoogletrans_pass\u001b[0;34m(s_text, target_lang)\u001b[0m\n\u001b[1;32m     17\u001b[0m             trans_corpus.append((i, [trans.text for\n\u001b[1;32m     18\u001b[0m                                 trans in translator.translate(\n\u001b[0;32m---> 19\u001b[0;31m                                 phrase, dest=target_lang)]))\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0;31m# Making a new Translator instance seems to help JSON errors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/googletrans/client.pyc\u001b[0m in \u001b[0;36mtranslate\u001b[0;34m(self, text, dest, src)\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m                 \u001b[0mtranslated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranslate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m                 \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtranslated\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/googletrans/client.pyc\u001b[0m in \u001b[0;36mtranslate\u001b[0;34m(self, text, dest, src)\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m         \u001b[0morigin\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_translate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m         \u001b[0;31m# this code will be updated when the format is changed.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/googletrans/client.pyc\u001b[0m in \u001b[0;36m_translate\u001b[0;34m(self, text, dest, src)\u001b[0m\n\u001b[1;32m     59\u001b[0m                                     token=token)\n\u001b[1;32m     60\u001b[0m         \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0murls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRANSLATE\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhost\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pick_service_url\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/requests/sessions.pyc\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, url, **kwargs)\u001b[0m\n\u001b[1;32m    519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'allow_redirects'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'GET'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/requests/sessions.pyc\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    492\u001b[0m             \u001b[0mhooks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m         )\n\u001b[0;32m--> 494\u001b[0;31m         \u001b[0mprep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    495\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    496\u001b[0m         \u001b[0mproxies\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mproxies\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/requests/sessions.pyc\u001b[0m in \u001b[0;36mprepare_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    435\u001b[0m             \u001b[0mauth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmerge_setting\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mauth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m             \u001b[0mcookies\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmerged_cookies\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 437\u001b[0;31m             \u001b[0mhooks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmerge_hooks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhooks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    438\u001b[0m         )\n\u001b[1;32m    439\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/requests/models.pyc\u001b[0m in \u001b[0;36mprepare\u001b[0;34m(self, method, url, headers, files, data, params, auth, cookies, hooks, json)\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 305\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_url\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    306\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_headers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_cookies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcookies\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/requests/models.pyc\u001b[0m in \u001b[0;36mprepare_url\u001b[0;34m(self, url, params)\u001b[0m\n\u001b[1;32m    421\u001b[0m             \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_native_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 423\u001b[0;31m         \u001b[0menc_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_encode_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    424\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0menc_params\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mquery\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/requests/models.pyc\u001b[0m in \u001b[0;36m_encode_params\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    103\u001b[0m                             (k.encode('utf-8') if isinstance(k, str) else k,\n\u001b[1;32m    104\u001b[0m                              v.encode('utf-8') if isinstance(v, str) else v))\n\u001b[0;32m--> 105\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0murlencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdoseq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python/2.7.12_2/Frameworks/Python.framework/Versions/2.7/lib/python2.7/urllib.pyc\u001b[0m in \u001b[0;36murlencode\u001b[0;34m(query, doseq)\u001b[0m\n\u001b[1;32m   1345\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1346\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mquery\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1347\u001b[0;31m             \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mquote_plus\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1348\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m                 \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mquote_plus\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python/2.7.12_2/Frameworks/Python.framework/Versions/2.7/lib/python2.7/urllib.pyc\u001b[0m in \u001b[0;36mquote_plus\u001b[0;34m(s, safe)\u001b[0m\n\u001b[1;32m   1301\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mquote_plus\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msafe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1302\u001b[0m     \u001b[0;34m\"\"\"Quote the query fragment of a URL; replacing ' ' with '+'\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1303\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0;34m' '\u001b[0m \u001b[0;32min\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1304\u001b[0m         \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mquote\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msafe\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1305\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'+'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from googletrans import Translator\n",
    "from utils import save_obj\n",
    "\n",
    "def googletrans_pass(s_text, target_lang='fr'):\n",
    "    \"\"\" This function makes a single pass through the data and tries to \n",
    "    translate each phrase one word at a time. Occasionally there are JSON\n",
    "    errors, probably due to too many requests being made. In this case\n",
    "    a new Translator instance is made and the failed attempts/skipped phrases\n",
    "    are returned, to be attempted again.\n",
    "    \"\"\"\n",
    "    translator = Translator()\n",
    "    trans_corpus = []\n",
    "    skipped_phrases = []\n",
    "    for i, phrase in s_text:\n",
    "        try:\n",
    "            # Appends (original index, translation)\n",
    "            trans_corpus.append((i, [trans.text for\n",
    "                                trans in translator.translate(\n",
    "                                phrase, dest=target_lang)]))\n",
    "        except ValueError as err:\n",
    "            # Making a new Translator instance seems to help JSON errors\n",
    "            translator = Translator()\n",
    "            # makes sure to keep skipped string and index\n",
    "            skipped_phrases.append((i, phrase))\n",
    "            print \"{} for phrase {}\".format(err, i)\n",
    "    return trans_corpus, skipped_phrases\n",
    "\n",
    "def translate_word_by_word(source_text):\n",
    "    # Need to keep track of phrase ordering by labelling\n",
    "    source_text = [(i, phr) for i, phr in enumerate(source_text)]\n",
    "    trans_text, skipped_phrases = googletrans_pass(source_text, target_lang=lang_t)\n",
    "    print \"There are {} phrases which could not be translated first time around.\".format(\n",
    "                                                                    len(skipped_phrases))\n",
    "    # Keep making passes until there are no more untranslated phrases left\n",
    "    j = 2\n",
    "    while len(skipped_phrases)>0:\n",
    "        translated_corpus = []\n",
    "        tc_s, skipped_phrases = googletrans_pass(skipped_phrases, target_lang=lang_t)\n",
    "        trans_text += tc_s\n",
    "        print \"There are {} phrases which could not be translated in pass {}.\".format(\n",
    "                                                            len(skipped_phrases), j)\n",
    "        j+=1\n",
    "    # Sort the phrases via their original indexes.\n",
    "    # Sorted function gives ([indices], [phrases]) so just need 2nd element\n",
    "    #trans_text = zip(*sorted(trans_text))[1]\n",
    "    return trans_text\n",
    "\n",
    "# Takes a while to run, running this cell is not for the faint hearted\n",
    "# BM_translated is ([french sequences], [english translations])\n",
    "BM_translated = translate_word_by_word(raw_s_test)\n",
    "\n",
    "print \"Corpus translated from {} to {}\".format(lang_s, lang_t)\n",
    "#save_obj(BM_translated, \"BM_translated\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'walter', u'r.macdonald', u'asaf', u'trigence', u'corp', u'what', u'are', u'the', u'advantages', u'for', u'mon', u'business', u'?'] [u'walter', u'r.macdonald', u'cfo', u'trigence', u'corp.', u'what', u'&aposs', u'in', u'it', u'for', u'my', u'company', u'?']\n"
     ]
    }
   ],
   "source": [
    "#BM_trans_1 #=  #zip(*sorted(BM_trans_1))[1] #, raw_t_test[0:1000])\n",
    "print BM_trans_1[-1], raw_t_test[999] \n",
    "#save_obj(BM_trans_1, \"short_data/BM_part_1\")\n",
    "#print p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import load_obj\n",
    "bm_1 = load_obj(\"short_data/BM_part_1\")\n",
    "BM_trans_2 = load_obj(\"short_data/BM_part_2\")\n",
    "bm_2 = zip(*sorted(BM_trans_2))[1]\n",
    "bm_trans = bm_1 + bm_2\n",
    "save_obj(bm_trans, \"short_data/BM_translated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_obj(BM_translated, \"short_data/BM_translated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[((0, [u'in', u'oakes', u'the', u'judge', u'in', u'chef', u'dickson', u'wrote', u'at', u'the', u'page', u'139']), [u'in', u'oakes', u'dickson', u'cj', u'wrote', u'at', u'139']), ((1, [u'projections', u'video']), [u'video', u'projection']), ((2, [u'the', u'n&apos', u'Y', u'a', u'not', u'at', u'to choose', u'between', u'these', u'tasks', u'closely', u'linked', u'who', u'are', u'all', u'two', u'required']), [u'it', u'is', u'not', u'a', u'question', u'of', u'&quot', u'either', u'/', u'or', u'&quot']), ((3, [u'growth', u'spring']), [u'slow', u'growth']), ((4, [u'after', u'the', u'breakfast', u'visit', u'from', u'the', u'river', u'maritza', u'and', u'from', u'the', u'fair', u'international', u'from', u'plovdiv']), [u'after', u'breakfast', u'visit', u'of', u'maritza', u'river', u'and', u'the', u'international', u'fair', u'of', u'plovdiv']), ((5, [u'massey', u'block', u'the', u'massey', u'block', u'winnipeg', u'with', u'the', u'permission', u'from', u'western', u'canada', u'pictorial', u'index']), [u'massey', u'block', u'massey', u'block', u'winnipeg', u'designed', u'by', u'george', u'browne', u'jr', u'courtesy', u'western', u'canada', u'pictorial', u'index']), ((6, [u'the', u'mostly', u'of the', u'drawings', u'are', u'usually', u'fabricated', u'sure', u'order', u'from', u'various', u'companies']), [u'most', u'sketches', u'are', u'usually', u'made', u'to', u'order', u'various', u'companies']), ((7, [u'a', u'brush', u'n&apos', u'a', u'never', u'summer', u'also', u'read']), [u'the', u'lightest', u'touch', u'ever', u'made', u'in', u'car', u'wash', u'brushes']), ((8, [u'monsieur', u'the', u'President', u'the', u'Y', u'a', u'a lot', u'from', u'things', u'positives', u'at', u'say', u'the', u'subject', u'of', u'report', u'brok']), [u'there', u'are', u'many', u'good', u'things', u'to', u'say', u'about', u'mr', u'brok', u'&aposs', u'report']), ((9, [u'the', u'contracts', u'from', u'services', u'complexes', u'will', u'awarded', u'at', u'go', u'after', u'a', u'request', u'from', u'proposition', u'dp']), [u'complicated', u'service', u'contracts', u'will', u'be', u'awarded', u'based', u'on', u'rfp']), ((10, [u'the', u'envisage', u'also', u'a', u'new', u'connection', u'the', u'pipeline', u'yamal']), [u'the', u'company', u'is', u'also', u'considering', u'new', u'interconnection', u'with', u'the', u'yamal', u'pipeline']), ((11, [u'l&apos', u'a', u'of the', u'two', u'halves', u'East', u'supposed', u'be', u'enclosed', u'in', u'l&apos', u'other', u'after', u'be', u'past', u'by', u'the', u'closing']), [u'one', u'half', u'is', u'designed', u'to', u'snap', u'irreversibly', u'into', u'the', u'other', u'half', u'through', u'the', u'hasp']), ((12, [u'l&apos', u'aigle', u'royal', u'and', u'the', u'coyote', u'are', u'after', u'important', u'predators', u'of', u'you', u'of the', u'Sage']), [u'golden', u'eagles', u'and', u'coyotes', u'are', u'important', u'predators', u'of', u'sage', u'grouse']), ((13, [u'words', u'Keywords', u'calibration', u'from', u'standards', u'properties', u'geometric', u'reliability', u'steel', u'resistance', u'in', u'tension', u'resistance', u'the', u'flexing']), [u'key', u'words', u'code', u'calibration', u'geometric', u'properties', u'reliability', u'steel', u'tensile', u'strength', u'yield', u'strength']), ((14, [u'by', u'elsewhere', u'the', u'hormones', u'can', u'fire', u'sure', u'of the', u'structures', u'other', u'what', u'the', u'lca']), [u'alternatively', u'hormones', u'may', u'act', u'on', u'structures', u'other', u'then', u'the', u'acl']), ((15, [u'and', u'we', u'Y', u'succeed']), [u'achieve', u'it', u'we', u'will']), ((16, [u'ibid', u'p.', u'198', u'and', u'199']), [u'ibid', u'pp.', u'198', u'and', u'199']), ((17, [u'this', u'perturbation', u'a', u'summer', u'investigated', u'at', u'l&apos', u'aide', u'from', u'the', u'microscopy', u'electronic', u'and', u'after', u'analyses', u'biochemical']), [u'this', u'perturbation', u'was', u'monitored', u'using', u'electron', u'microscopy', u'and', u'biochemical', u'analyses']), ((18, [u'finally', u'the', u'populations', u'ask', u'often', u'the', u'women', u'from', u'present', u'at', u'new', u'the', u'piece']), [u'people', u'often', u'ask', u'the', u'women', u'to', u'do', u'the', u'play', u'again']), ((19, [u'Mrs', u'liz-anne', u'gillham-eisen', u'context']), [u'ms.', u'liz', u'anne', u'gillham-eisen', u'context']), ((20, [u'launching', u'from', u'l&apos', u'year', u'international', u'from', u'l&apos', u'water', u'fresh', u'2003']), [u'launch', u'of', u'the', u'international', u'year', u'of', u'freshwater', u'2003']), ((21, [u'in', u'definitive', u'all', u'the', u'classes', u'after', u'assets', u'have', u'summer', u'affected', u'actions', u'obligations', u'and', u'currencies']), [u'in', u'the', u'end', u'all', u'emerging', u'market', u'asset', u'classes', u'were', u'hit', u'stocks', u'bonds', u'and', u'currencies']), ((22, [u'1999.', u'www.psephisma.org', u'8080', u'/', u'site', u'/', u'index.xsp', u'ricay', u'agustin']), [u'washington', u'dc']), ((23, [u'this', u'affirmation', u'must', u'be', u'returned', u'in', u'l&apos', u'empire', u'of', u'journalism', u'creative', u':']), [u'this', u'allegation', u'must', u'be', u'consigned', u'to', u'the', u'domain', u'of', u'creative', u'journalism', u':']), ((24, [u'english', u'version', u'available']), [u'version', u'fran\\xe7aise', u'disponible']), ((25, [u'&quot', u'the', u'government', u'must', u'take', u'conscience', u'from', u'this', u'what', u'it', u'involved']), [u'&quot', u'government', u'needs', u'to', u'realize', u'what', u'is', u'underlying', u'this']), ((26, [u'this', u'who', u'Explain', u'Why', u'the', u'a', u'fact', u'this', u'that after', u'the', u'needed']), [u'which', u'is', u'why', u'he', u'has', u'done', u'all', u'right']), ((27, [u'25', u'February', u'2010', u'-', u'planetsolar', u'unveiled', u':']), [u'25th', u'february', u'2010', u'-', u'planetsolar', u'has', u'been', u'unveiled', u':']), ((28, [u'r', u'&apos', u'f', u'&apos', u'ences', u'selected', u'in', u'1.', u'from', u'villiers', u'e-m', u'wagner', u'd', u'schneider', u'a', u'and', u'al']), [u'selected', u'references', u'1.', u'de', u'villiers', u'e-m', u'wagner', u'd', u'schneider', u'a', u'et', u'al']), ((29, [u'It is', u'me', u'welcome', u'so', u'of', u'change', u'from', u'sentiments', u'from', u'm.', u'the', u'pen']), [u'so', u'i', u'welcome', u'mr', u'le', u'pen', u'&aposs', u'change', u'of', u'heart']), ((30, [u'communications', u'and', u'relations', u'public']), [u'communications', u'&amp', u'public', u'relations']), ((31, [u'the', u'n&apos', u'East', u'not', u'true', u'what', u'600', u'members', u'of', u'falun', u'palace', u'have', u'summer', u'arrested']), [u'it', u'is', u'untrue', u'that', u'600', u'falun', u'gong', u'members', u'were', u'arrested']), ((32, [u'sainsbury', u'offer', u'plus', u'from', u'1', u'300', u'products', u'biological']), [u'sainsbury', u'offers', u'more', u'than', u'1300', u'organic', u'products']), ((33, [u'discover', u'of the', u'receipts', u'original', u'and', u'full', u'from', u'flavors']), [u'discover', u'original', u'recipes', u'and', u'plenty', u'of', u'flavours']), ((34, [u'the', u'occupied', u'now', u'son', u'post', u'current', u'from', u'director', u'from', u'region', u'since', u'1995']), [u'he', u'has', u'served', u'in', u'his', u'current', u'position', u'of', u'regional', u'director', u'since', u'1995']), ((35, [u'c-ac-96-85f', u'mifflin', u'restores', u'the', u'facts', u'the', u'subject', u'of the', u'fishermen', u'from', u'lobster', u'the', u'25', u'October', u'1996']), [u'nr-hq-96-85e', u'mifflin', u'sets', u'the', u'record', u'straight', u'on', u'lobster', u'fishers', u'october', u'25', u'1996']), ((36, [u'the', u'plus', u'notable', u'East', u'the', u'lac', u'victoria', u'in', u'the', u'South']), [u'the', u'most', u'notable', u'is', u'lake', u'victoria', u'in', u'the', u'south']), ((37, [u'in', u'outraged', u'from', u'new', u'lenders', u'font', u'their', u'Entrance', u'sure', u'the', u'market']), [u'new', u'lenders', u'are', u'also', u'entering', u'the', u'marketplace']), ((38, [u'petite', u'history', u'international', u'of the', u'missions', u'towards', u'mars']), [u'past', u'missions', u'to', u'mars']), ((39, [u'concession', u'after', u'arms', u'and', u'from', u'supports', u'at', u'the', u'royal', u'roads', u'university', u'victoria', u'British Columbia', u'the', u'24', u'mars', u'1998']), [u'grant', u'of', u'arms', u'and', u'supporters', u'to', u'royal', u'roads', u'university', u'victoria', u'british', u'columbia', u'march', u'24', u'1998']), ((40, [u'these', u'interviews', u'codified', u'aim', u'at', u'to define', u'a', u'contract', u'between', u'the', u'employees', u'and', u'their', u'higher']), [u'annual', u'and', u'formalised', u'interviews', u'aim', u'at', u'a', u'contract', u'between', u'staff', u'members', u'and', u'their', u'superiors']), ((41, [u'the', u'described', u'faithfully', u'the', u'plans', u'and', u'the', u'priorities', u'from', u'l&apos', u'organisation']), [u'it', u'accurately', u'portrays', u'the', u'agency', u'&aposs', u'plans', u'and', u'priorities']), ((42, [u'Home', u'&gt', u'l&apos', u'encyclopedia', u'Canadian', u'&gt', u'biography', u'&gt', u'dramaturges', u'&gt', u'deverell', u'rex', u'for', u'to print']), [u'home', u'&gt', u'the', u'canadian', u'encyclopedia', u'&gt', u'biography', u'&gt', u'playwrights', u'&gt', u'deverell', u'rex', u'print', u'version']), ((43, [u'the', u'mostly', u'of the', u'savings', u'Scandinavian', u'rely', u'mostly', u'sure', u'the', u'commerce']), [u'most', u'scandinavian', u'economies', u'are', u'heavily', u'reliant', u'on', u'trade']), ((44, [u'the', u'pays', u'who', u'followed', u'the', u'advice', u'of', u'imf', u'born', u's&apos', u'in', u'out', u'never', u'also', u'good']), [u'countries', u'that', u'relied', u'on', u'imf', u'advice', u'fared', u'far', u'less', u'well']), ((45, [u'a', u'fine', u'layer', u'from', u'metal', u'or', u'from', u'plastic', u'can', u'block', u'the', u'radiation', u'beta']), [u'thin', u'sheets', u'of', u'metal', u'or', u'plastic', u'may', u'stop', u'beta', u'particles']), ((46, [u'this', u'redundancy', u'aide', u'at', u'minimize', u'the', u'time', u'after', u'stop']), [u'this', u'reduncency', u'minimizes', u'the', u'amount', u'of', u'downtime']), ((47, [u'the', u'ready', u'mortgage', u'East', u'very', u'limit']), [u'mortgage', u'lending', u'is', u'very', u'limited']), ((48, [u'and', u'you', u'want', u'you', u'inscribe', u'at', u'a', u'course', u'thank you', u'from', u'fill', u'the', u'form', u'after', u'inscription', u'below']), [u'if', u'you', u'wish', u'to', u'enroll', u'for', u'a', u'course', u'please', u'complete', u'the', u'enrollment', u'form', u'below']), ((49, [u'the', u'halyards', u'strained', u'tremble', u'slightly', u'and', u'the', u'pavillon', u'slap']), [u'pennant', u'extends', u'and', u'flaps']), ((50, [u'hand', u'c.m.', u'g.d.', u'workman', u'L. J.', u'richards', u'r.', u'kieser', u'and', u'r.i.', u'perry']), [u'hand', u'c.m.', u'g.d.', u'workman', u'l.j.', u'richards', u'r.', u'kieser', u'and', u'r.i.', u'perry']), ((51, [u'the', u'advice', u'would have', u'could', u'fire', u'with', u'determination', u'for', u'make', u'moving forward', u'the', u'process', u'from', u'peace']), [u'the', u'council', u'could', u'have', u'acted', u'decisively', u'to', u'nudge', u'the', u'peace', u'process', u'forward']), ((52, [u'this', u'analysis', u'recommended', u'also', u'from', u'extend', u'the', u'duration', u'of', u'protocol', u'from', u'five', u'or', u'six', u'years']), [u'the', u'analysis', u'also', u'recommends', u'extending', u'the', u'duration', u'of', u'the', u'protocols', u'to', u'five', u'or', u'six', u'years']), ((53, [u'Contents', u'dredged', u'composed', u'from', u'roche', u'shot']), [u'dredged', u'material', u'consisting', u'of', u'blasted', u'rock']), ((54, [u'from', u'recent', u'statements', u'make', u'by', u'the', u'leader', u'of', u'hamas', u'Palestinian', u'the', u'confirm']), [u'recent', u'statements', u'made', u'by', u'the', u'hamas', u'palestinian', u'leadership', u'tell', u'us', u'that', u'much']), ((55, [u'Annex', u'like']), [u'annex', u'xi']), ((56, [u'the', u'attacks', u'terrorists', u'of', u'11', u'September', u'stay', u'at', u'never', u'engraved', u'in', u'we', u'memoirs']), [u'the', u'terrorist', u'attacks', u'of', u'11', u'september', u'will', u'forever', u'remain', u'etched', u'in', u'our', u'memory']), ((57, [u'many', u'neurones', u'unidentified', u'are', u'excited', u'by', u'all', u'these', u'peptides']), [u'many', u'nonidentified', u'neurons', u'were', u'excited', u'by', u'all', u'of', u'these', u'peptides']), ((58, [u'the', u'citizens', u'from', u'pays', u'tiers', u'are', u'supposed', u'be', u'transferred', u'sure', u'the', u'base', u'naval', u'from', u'guant\\xe1namo', u'bay']), [u'nationals', u'of', u'third', u'countries', u'are', u'allegedly', u'transferred', u'to', u'guant\\xe1namo', u'bay', u'naval', u'base']), ((59, [u'm.', u'raymond', u'leigh', u'mills']), [u'mr.', u'raymond', u'leigh', u'mills']), ((60, [u'the', u'figure', u'6-1', u'trained', u'a', u'example', u'after', u'a', u'report', u'daily', u'class', u'by', u'category']), [u'figure', u'6-1', u'shows', u'an', u'example', u'of', u'a', u'daily', u'category', u'report']), ((61, [u'taker', u'from', u'licence', u'and', u'who', u'not allowed', u'the', u'holder', u'or', u'at', u'all', u'other', u'no one', u'after', u'use', u'the', u'Mark']), [u'and', u'excludes', u'the', u'holder', u'and', u'any', u'other', u'person', u'from', u'using', u'the', u'mark']), ((62, [u'l&apos', u'study', u'a', u'revealed', u'that after', u'the', u'rest', u'after', u'other', u'observations', u'or', u'after', u'other', u'way', u'interesting', u'at', u'explorer']), [u'the', u'study', u'turned', u'up', u'some', u'other', u'interesting', u'observations', u'and', u'avenues', u'for', u'further', u'exploration']), ((63, [u'elaboration', u'or', u'modification', u'from', u'policies']), [u'policy', u'development', u'or', u'modification']), ((64, [u'venus', u'glasses', u'at', u'l&apos', u'East', u'little', u'before', u'l&apos', u'dawn']), [u'venus', u'dominates', u'the', u'eastern', u'sky', u'before', u'dawn']), ((65, [u'a', u'professor', u'm.', u'and', u'pedersen', u'their', u'a', u'so', u'request', u'from', u'go']), [u'while', u'they', u'were', u'waiting', u'a', u'teacher', u'mr.', u'k.p.', u'asked', u'them', u'to', u'leave']), ((66, [u'after', u'East', u'Why', u'the', u'commission', u'propose', u'after', u'to integrate', u'the', u'operators', u'after', u'aircraft', u'in', u'l&apos', u'ets']), [u'for', u'that', u'reason', u'the', u'commission', u'proposes', u'including', u'aircraft', u'operators', u'in', u'the', u'ets']), ((67, [u'1', u'00000', u'Bad day', u'martha', u'j.', u'1', u'00000', u'fernando', u'Velocci', u'1', u'00000', u'flagship', u'capital', u'partners', u'inc']), [u'1000.00', u'durdin', u'martha', u'j.', u'1000.00', u'fernando', u'velocci', u'1000.00', u'flagship', u'capital', u'partners', u'inc']), ((68, [u'after', u'East', u'this', u'anarchy', u'in', u'the', u'pillage', u'who', u'gene', u'the', u'rapporteur']), [u'it', u'is', u'this', u'anarchy', u'in', u'the', u'plundering', u'that', u'bothers', u'the', u'rapporteur']), ((69, [u'finished', u'the', u'excuses']), [u'no', u'more', u'excuses']), ((70, [u'position', u'from', u'departure', u'the', u'good', u'alignment', u'from', u'all', u'the', u'articulations']), [u'neutral', u'standing', u'posture']), ((71, [u'she', u'diffuse', u'sure', u'internet', u'in', u'son', u'site', u'in', u'line', u'the', u'r\\xe9sum\\xe9s', u'from', u'his', u'productions', u'and', u'from', u'his', u'activities']), [u'on', u'its', u'website', u'it', u'circulates', u'internet', u'summaries', u'of', u'its', u'production', u'and', u'activities']), ((72, [u'l&apos', u'uruguay', u'pays', u'the', u'plus', u'touch', u'a', u'checked in', u'a', u'drop', u'higher', u'at', u'10', u'%']), [u'uruguay', u'which', u'was', u'hit', u'the', u'hardest', u'posted', u'a', u'double-digit', u'drop']), ((73, [u'\\u2022', u'from', u'7', u'h', u'30', u'at', u'19', u'h', u'30', u'in', u'the', u'spindle', u'schedule', u'of the', u'rock']), [u'british', u'columbia', u'makes', u'no', u'provision', u'for', u'a', u'tie', u'after', u'a', u'recount']), ((74, [u'of the', u'reforms', u'for', u'defuse', u'the', u'crisis', u'are', u'required']), [u'reforms', u'to', u'defuse', u'the', u'crisis', u'are', u'needed']), ((75, [u'from', u'the', u'reception', u'from', u'the', u'order', u'the', u'client', u'East', u'at once', u'price', u'in', u'charge']), [u'customers', u'always', u'get', u'our', u'full', u'attention', u'the', u'moment', u'an', u'order', u'is', u'placed']), ((76, [u'measurement', u'and', u'possible', u'adverse', u'effects', u'&quot', u'hhs', u'publication', u'fda', u'81-8163', u'May', u'1981']), [u'measurement', u'and', u'possible', u'adverse', u'effects', u'&quot', u'hhs', u'publication', u'fda', u'81-8163', u'may', u'1981']), ((77, [u'a', u'album', u'dance-jazz', u'from', u'quality', u'who', u'approach', u'from', u'way', u'inattandue', u'of the', u'beats', u'hip', u'hop']), [u'the', u'prime', u'example', u'of', u'90', u'&quot', u's', u'jazz', u'with', u'some', u'really', u'tough', u'vocals', u'cuts']), ((78, [u'making', u'evidence', u'from', u'a lot', u'from', u'foresight', u'the', u'colonel', u'by', u'providence', u'boldly', u'a', u'system', u'after', u'locks', u'a lot', u'plus', u'big']), [u'with', u'considerable', u'foresight', u'colonel', u'by', u'boldly', u'advocated', u'a', u'system', u'of', u'much', u'larger', u'locks']), ((79, [u'from', u'new', u'methods', u'can', u'be', u'available', u'suite', u'at', u'the', u'publication', u'from', u'this', u'document']), [u'new', u'methods', u'may', u'become', u'available', u'after', u'publication', u'of', u'this', u'document']), ((80, [u'at', u' ', u'O', u'porno', u'and', u'blondes', u'hard', u':', u'so', u'the', u'Test', u'saddle', u'capacity', u'at', u'all', u'make']), [u'after', u'he', u'has', u'finished', u'screwing', u'her', u'anus', u'he', u'fills', u'her', u'mouth', u'with', u'cum']), ((81, [u'all', u'it', u'we', u'a', u'allowed', u'from', u'manage', u'l&apos', u'aspect', u'policy', u'of', u'process']), [u'that', u'made', u'the', u'politics', u'manageable']), ((82, [u'campbell', u'j.', u'Y.', u'and', u'p.', u'perron', u'1991']), [u'princeton', u'n.j.']), ((83, [u'lane', u'environment', u'contact', u'after', u'business']), [u'lane', u'environment', u'contact']), ((84, [u'\\u2022', u'of the', u'boards', u'or', u'of the', u'pages', u'web', u'interactives']), [u'\\u2022', u'video', u'conferencing', u'hall', u'wendell', u'&amp', u'tidwell', u'2003']), ((85, [u'modifications', u'in', u'waiting', u'after', u'authorization', u'finale']), [u'these', u'amendments', u'are', u'awaiting', u'final', u'approval']), ((86, [u'in', u'October', u'2004', u'the', u'therapist', u'was', u'supervised', u'sure', u'the', u'plan', u'clinique', u'by', u'tony', u'martens']), [u'as', u'of', u'october', u'2004', u'the', u'therapist', u'was', u'clinically', u'supervised', u'by', u'tony', u'martens']), ((87, [u'Yes', u'It is', u'n', u'&quot', u'was', u'not', u'again', u'authorized', u'at', u'come', u'right here']), [u'yeah', u'i', u'wasn', u'&apost', u'qualified', u'yet', u'to', u'come', u'here']), ((88, [u'differences', u'national', u'and', u'international']), [u'national', u'and', u'transnational', u'differences']), ((89, [u'animals', u'from', u'company', u'autoris\\xe9s.restaurant', u'accessible', u'in', u'armchair', u'rolling']), [u'free', u'car', u'parking', u'also', u'places', u'for', u'buses']), ((90, [u'illustration']), [u'nations', u'in', u'the', u'news']), ((91, [u'm.', u'sebastian', u'beliwine']), [u'mr.', u'sebastian', u'beliwine']), ((92, [u'\\\\', u'&quot', u'we', u'present', u'we', u'sincerest', u'condolences', u'at', u'loretta', u'at', u'their', u'children', u'and', u'at', u'their', u'grandchildren']), [u'\\\\', u'&quot', u'our', u'sincerest', u'condolences', u'to', u'loretta', u'the', u'children', u'and', u'the', u'grandchildren']), ((93, [u'16', u'gosden', u't', u'torgerson', u'dj', u'maynard', u'a.', u'what', u'is', u'to', u'be', u'done', u'about', u'fundholding', u'?']), [u'gosden', u't', u'torgerson', u'dj', u'maynard', u'a.', u'what', u'is', u'to', u'be', u'done', u'about', u'fundholding', u'?']), ((94, [u'the', u'declaration', u'equivalent', u'at', u'a', u'request', u'concrete', u'after', u'euthanasia']), [u'the', u'declaration', u'has', u'the', u'same', u'status', u'as', u'a', u'concrete', u'request', u'for', u'euthanasia']), ((95, [u'some', u'were', u'crowned', u'from', u'success', u'more', u'the', u'mostly', u'failed']), [u'although', u'initially', u'pushed', u'back', u'the', u'corps', u'did', u'not', u'repeat', u'the', u'mistakes', u'of', u'ypres']), ((96, [u'at', u'who', u's&apos', u'address', u'in', u'case', u'from', u'problem', u'?']), [u'where', u'do', u'i', u'go', u'if', u'i', u'encounter', u'a', u'problem', u'?']), ((97, [u'learning', u'from', u'the', u'suffolk', u'system', u'journal', u'of', u'money', u'credit', u'and', u'banking', u'vol.']), [u'learning', u'from', u'the', u'suffolk', u'system', u'&quot', u'journal', u'of', u'money', u'credit', u'and', u'banking', u'vol']), ((98, [u'cooked', u'saddle', u'chair', u'East', u'after', u'a', u'blanc', u'while', u'skinny', u'without', u'edges', u'puff', u'and', u'fresh', u'the', u'taste']), [u'once', u'cooked', u'the', u'meat', u'is', u'pure', u'white', u'lean', u'boneless', u'and', u'flaky', u'with', u'a', u'mild', u'flavour']), ((99, [u'May', u'adding', u'after', u'a', u'all', u'small', u'clip', u'from', u'the', u'zone', u'polar', u'with', u'from', u'beautiful', u'effects', u'aquatic']), [u'update', u'little', u'&quot', u'polar', u'zone', u'&quot', u'clip', u'added', u'with', u'superb', u'aquatic', u'effects']), ((100, [u'institute', u'of', u'big-dull', u'for', u'the', u'tourism', u'durable']), [u'gros', u'morne', u'institute', u'of', u'sustainable', u'tourism']), ((101, [u'the', u'diet', u'criminal', u'from', u'the', u'family', u'al-assad', u'born', u'must', u'not', u'be', u'reward', u'for', u'son', u'bad', u'behavior']), [u'the', u'al-assad', u'family', u'&aposs', u'criminal', u'regime', u'must', u'not', u'be', u'rewarded', u'for', u'bad', u'behaviour']), ((102, [u'diane', u'carroll', u'Deputy Minister', u'Assistant', u'Associ\\xe9s', u'\\xa9', u'e', u'policies', u'and', u'communications']), [u'diane', u'carroll', u'associate', u'assistant', u'deputy', u'minister', u'policy', u'and', u'communications']), ((103, [u'after', u'East', u'was', u'a', u'other', u'signification', u'from', u'What', u'candidature']), [u'that', u'is', u'another', u'characteristic', u'of', u'my', u'candidacy']), ((104, [u'a lot', u'from', u'we', u'comrades', u'born', u'are', u'never', u'earnings', u'the', u'pays']), [u'&quot', u'a', u'lot', u'of', u'our', u'boys', u'never', u'came', u'home']), ((105, [u'the', u'storms', u'winter', u'lead', u'sometimes', u'from', u'rares', u'birds', u'migratory', u'who', u'have', u'summer', u'deported']), [u'winter', u'storms', u'will', u'occasionally', u'bring', u'sightings', u'of', u'rare', u'migrating', u'birds', u'blown', u'off', u'course']), ((106, [u'advice', u'from', u'l&apos', u'europe', u'strasbourg', u'2002']), [u'hugh', u'starkey', u'the', u'open', u'university', u'milton', u'keynes']), ((107, [u'on', u'vagotomisa', u'a', u'other', u'group', u'from', u'rats-tests', u'and', u'on', u'unnerve', u'their', u'sinus', u'carotidien', u'before', u'l&apos', u'injection', u'after', u'extracts']), [u'another', u'group', u'of', u'assay', u'rats', u'was', u'vagotomized', u'as', u'well', u'as', u'carotid-sinus-denervated', u'before', u'extract', u'injection']), ((108, [u'correa', u'a', u'also', u'fact', u'reference', u'the', u'new', u'treatment', u'medical', u'of', u'President', u'Venezuelan', u'hugo', u'ch\\xe1vez', u'at', u'cuba']), [u'correa', u'also', u'referred', u'to', u'venezuelan', u'president', u'hugo', u'chavez', u'&aposs', u'new', u'health', u'treatment', u'in', u'cuba']), ((109, [u'in', u'reducing', u'the', u'amount', u'you', u'reduce', u'the', u'risks']), [u'less', u'to', u'store', u'means', u'less', u'of', u'a', u'hazard']), ((110, [u'??', u'these', u'two', u'massive', u'are', u'become', u'from', u'real', u'dumps', u':']), [u'&quot', u'both', u'mountains', u'are', u'a', u'mess', u'with', u'trash', u'lying', u'about']), ((111, [u'shopping', u'fenoarivo', u'shoes', u'laced', u'chic', u'for', u'men', u'in', u'spring', u'shoes']), [u'buy', u'fenoarivo', u'sale', u'&aposs', u'men', u'shoes', u'at', u'spring', u'shoes']), ((112, [u'name', u'from', u'l&apos', u'food', u'a', u'a', u'low', u'content', u'in', u'fats', u'saturated', u'and', u'trans']), [u'naming', u'the', u'food', u'is', u'low', u'in', u'saturated', u'and', u'trans', u'fats']), ((113, [u'melik', u'ParSignant', u'st\\xe9phane', u't']), [u'cairney', u'john', u'/', u'cheung', u'amy', u'h', u'/', u'kurdyak', u'paul', u'a', u'/', u'levitt', u'anthony', u'j']), ((114, [u'the', u'tissues', u'leaf', u'are', u'from', u'color', u'dark', u'and', u'hollowed']), [u'leaf', u'tissue', u'darkens', u'and', u'collapses']), ((115, [u'you', u'must', u'buy', u'a', u'key', u'usb', u'available', u'in', u'the', u'commerce']), [u'you', u'need', u'to', u'purchase', u'a', u'commercially', u'available', u'usb', u'device']), ((116, [u'is he', u'possible', u'that after', u'a', u'wife', u'pregnant', u'transmit', u'the', u'virus', u'of', u'nil', u'occidental', u'at', u'son', u'child', u'at', u'be born', u'?']), [u'can', u'a', u'pregnant', u'woman', u'pass', u'west', u'nile', u'virus', u'to', u'her', u'unborn', u'baby', u'?']), ((117, [u'tty', u'preferred', u'term', u'teletype', u'tdd', u'telecommunications', u'device', u'for', u'the', u'deaf', u'native', u'huh.']), [u'appointments', u'file', u'fichier', u'des', u'nominations', u'n.m.']), ((118, [u'the', u'judge', u'gibson', u'n&apos', u'a', u'found', u'no', u'other', u'conflict', u'relatively', u'the', u'other', u'questions', u'presented', u'in front of', u'his']), [u'judge', u'gibson', u'found', u'no', u'conflict', u'on', u'any', u'of', u'the', u'other', u'points', u'at', u'issue']), ((119, [u'guerin', u'm.r.', u'r.a.', u'jenkins', u'and', u'b.a.', u'tomkins']), [u'guerin', u'm.r.', u'r.a.', u'jenkins', u'and', u'b.a.', u'tomkins']), ((120, [u'&quot', u'all', u'the', u'people', u'who', u'hear', u'speak', u'from', u'the', u'hiking', u'wish', u'Y', u'participate', u'precise', u'the', u'police officer', u'beauvais']), [u'&quot', u'everybody', u'we', u'speak', u'to', u'about', u'the', u'event', u'jumps', u'on', u'board', u'&quot', u'said', u'const']), ((121, [u'jekanowslci', u'm.', u'ct', u'j.', u'it was ok']), [u'cambridge', u'mit', u'press']), ((122, [u'measures', u'preventive']), [u'preventive', u'measures']), ((123, [u'the', u'travelers', u'are', u'subject', u'the', u'system', u'judicial', u'of', u'pays', u'in', u'which', u'they', u'stay']), [u'someone', u'who', u'is', u'high', u'can', u'easily', u'be', u'attacked', u'robbed', u'or', u'sexually', u'assaulted']), ((124, [u'a', u'democracy', u'dangerous', u'the', u'East', u'dangerous', u'from', u'criticize', u'the', u'democracy', u'says', u'the', u'advertiser', u'ansgar', u'Long']), [u'dangerous', u'democracy', u'criticizing', u'democracy', u'can', u'be', u'very', u'dangerous', u'says', u'publicist', u'ansgar', u'lange']), ((125, [u'the', u'development', u'and', u'the', u'preservation', u'from', u'we', u'means', u'from', u'subsistence', u'require', u'of the', u'solutions', u'durables']), [u'development', u'and', u'the', u'preservation', u'of', u'our', u'livelihoods', u'require', u'sustainable', u'solutions']), ((126, [u'millennium', u'environmental', u'n', u'\\xb0', u'4', u'-', u'risk', u'management', u'people', u'maria', u'noel', u'estrada', u'ortiz']), [u'milenio', u'ambiental', u'n', u'\\xb0', u'4', u'-', u'risk', u'management', u'people', u'maria', u'noel', u'estrada', u'ortiz']), ((127, [u'the', u'degree', u'from', u'precision', u'East', u'acceptable', u'in', u'the', u'book', u'd', u'&quot', u'establishment', u'of the', u'price', u'from', u'come back']), [u'acceptable', u'level', u'of', u'accuracy', u'in', u'costing', u'records', u'maintained']), ((128, [u'this', u'reasoning', u'worth', u'also', u'in', u'big', u'part', u'for', u'l&apos', u'accusation', u'relative', u'at', u'a', u'manipulation', u'of the', u'items', u'from', u'evidence']), [u'these', u'allegations', u'were', u'based', u'on', u'the', u'following', u'claims', u'made', u'by', u'the', u'complainant']), ((129, [u'the', u'plan', u'East', u'structure', u'around', u'from', u'three', u'themes', u'strategic', u'at', u'know', u'the', u'research', u'the', u'formation', u'and', u'l&apos', u'information']), [u'the', u'plan', u'revolved', u'around', u'three', u'strategic', u'areas', u'namely', u'research', u'training', u'and', u'information']), ((130, [u'after', u'East', u'the', u'first', u'time', u'what', u'the', u'theme', u'from', u'star', u'trek', u'a', u'summer', u'play', u'so']), [u'this', u'sign', u'was', u'later', u'placed', u'next', u'to', u'the', u'jefferies', u'tube', u'in', u'season', u'two']), ((131, [u'm.', u'felipe', u'calder\\xf3n', u'who', u'succeeds', u'at', u'm.', u'vicente', u'fox', u'exercise', u'a', u'mandate', u'unique', u'from', u'six', u'years']), [u'felipe', u'calder\\xf3n', u'will', u'serve', u'for', u'a', u'single', u'six-year', u'term', u'succeeding', u'president', u'vicente', u'fox']), ((132, [u'\\u2022', u'teacher', u'constantin', u'chef', u'after', u'unit']), [u'\\u2022', u'daskalakis', u'constantin', u'head', u'of', u'unit']), ((133, [u'two', u'rules', u'empirical', u'have', u'summer', u'used', u'at', u'tour', u'from', u'role', u'for', u'validate', u'this', u'postulate', u'1']), [u'alternatively', u'two', u'rules', u'of', u'thumb', u'were', u'used', u'to', u'validate', u'this', u'assumption', u'1']), ((134, [u'after', u'after', u'the', u'analysts', u'l&apos', u'economy', u'World', u'n&apos', u'would have', u'not', u'again', u'touch', u'the', u'fond']), [u'according', u'to', u'analysts', u'the', u'global', u'economic', u'downturn', u'has', u'not', u'yet', u'reached', u'bottom']), ((135, [u'booking.com', u'art', u'deco', u'hotel', u'montana', u'lucerne', u'suisse', u'-', u'41', u'comments', u'clients']), [u'booking.com', u'art', u'deco', u'hotel', u'montana', u'lucerne', u'switzerland', u'-', u'42', u'guest', u'reviews']), ((136, [u'cut', u'rolls', u'horizontally', u'again', u'wrapped', u'in', u'of', u'plastic', u'formant', u'pivots']), [u'cut', u'rolls', u'horizontally', u'still', u'wrapped', u'in', u'plastic', u'forming', u'of', u'the', u'walker']), ((137, [u'exposition']), [u'exhibit']), ((138, [u'line', u'312', u'-', u'the', u'production', u'is she', u'a', u'coproduction', u'expected', u'by', u'a', u'accord', u'?']), [u'business', u'number', u'enter', u'the', u'business', u'number', u'of', u'the', u'qc']), ((139, [u'm.', u'embleton', u'East', u'came', u'and', u'a', u'got out', u'the', u'pelures', u'from', u'apples', u'from', u'terre']), [u'mr.', u'embleton', u'came', u'in', u'and', u'took', u'out', u'the', u'potato', u'peelings']), ((140, [u'the', u'leaders', u'from', u'unions', u'should', u'HE', u'learn', u'with', u'the', u'world', u'from', u'the', u'finance', u'rather', u'what', u'from', u'the', u'condemn']), [u'union', u'leaders', u'must', u'study', u'finance', u'rather', u'than', u'condemn', u'it', u'as', u'evil']), ((141, [u'dre', u'sarah', u'stobo', u'prichard', u'Professor', u'university', u'mcgill']), [u'dr.', u'stephanie', u'atkinson', u'professor', u'mcmaster', u'university']), ((142, [u'the', u'barrage', u'from', u'montreuil']), [u'citing', u'online', u'sources', u'advice', u'on', u'online', u'citation', u'formats', u'&#91', u'online', u'&#93']), ((143, [u'kodjovi', u'East', u'falls', u'and', u'they', u'have', u'play', u'with', u'his', u'as', u'a', u'ballon']), [u'two', u'soldiers', u'wearing', u'red', u'berets', u'hit', u'people', u'with', u'their', u'truncheons']), ((144, [u'the', u'East', u'time', u'from', u'to put', u'the', u'things', u'the', u'clair']), [u'it', u'&aposs', u'time', u'to', u'set', u'the', u'record', u'straight']), ((145, [u'criterion', u'after', u'origin', u'read', u'the', u'instructions', u'who', u'follow', u'9']), [u'origin', u'criterion', u'see', u'the', u'instruction', u'that', u'follow', u'9']), ((146, [u'more', u'on', u'born', u'you can', u'not', u'very', u'good', u'Why', u'after', u'East', u'the', u'fsb', u'who', u'should', u'think', u'this', u'process']), [u'but', u'why', u'the', u'fsb', u'should', u'head', u'up', u'this', u'process', u'is', u'far', u'from', u'clear']), ((147, [u'modifier', u'as', u'suit', u'the', u'two', u'first', u'phrases', u'of', u'paragraph', u'2.4.2.3.2.2']), [u'amend', u'the', u'first', u'two', u'sentences', u'of', u'2.4.2.3.2.2', u'to', u'read']), ((148, [u'in', u'fact', u'the', u'song', u's&apos', u'inserts', u'good', u'in', u'What', u'presentation']), [u'it', u'works', u'in', u'my', u'presentation', u'pretty', u'good', u'actually']), ((149, [u'loiselle', u'represented', u'the', u'patron', u'from', u'the', u'Party', u'st', u'Jean Baptiste']), [u'loiselle', u'represented', u'the', u'patron', u'saint', u'of', u'the', u'celebration', u'st.', u'jean-baptiste']), ((150, [u'\\u2022', u'comment', u'invite', u'the', u'Governor', u'General', u'at', u'your', u'activity']), [u'\\u2022', u'inviting', u'the', u'governor', u'general', u'to', u'your', u'event']), ((151, [u'education', u'relative', u'the', u'job', u'from', u'parent', u'and', u'aide', u'domestic']), [u'parenting', u'education', u'and', u'family', u'support']), ((152, [u'citybug', u'assists', u'perhaps', u'at', u'rodrigo', u'Y', u'gabriela', u'at', u'radio', u'city', u'music', u'hall']), [u'hello', u'_', u'didi', u'is', u'attending', u'show', u'da', u'virada', u'at', u'radio', u'city', u'music', u'hall']), ((153, [u'&quot', u'now', u'what', u'j & apos', u'to', u'in use', u'your', u'site', u'web', u'It is', u'foresee', u'Y', u'to have', u'recourse', u'plus', u'often']), [u'&quot', u'now', u'that', u'i', u'have', u'used', u'your', u'web', u'site', u'i', u'plan', u'to', u'use', u'it', u'more']), ((154, [u'l&apos', u'intensity', u'relatively', u'low', u'from', u'these', u'rainfall', u'East', u'compensated', u'by', u'their', u'persistence']), [u'what', u'these', u'storms', u'lack', u'in', u'rainfall', u'intensity', u'they', u'make', u'up', u'in', u'storm', u'duration']), ((155, [u'.', u'radio canada', u'HE', u'prepare', u'at', u'attack', u'the', u'subtitles']), [u'.', u'cbc', u'plans', u'attack', u'on', u'captioning']), ((156, [u'l', u'&quot', u'eternal', u'inflation', u'Russian', u'by', u'brigitte', u'granville', u'brigitte', u'granville']), [u'russia', u'&aposs', u'eternal', u'inflation', u'by', u'brigitte', u'granville', u'brigitte', u'granville']), ((157, [u'j & apos', u'to', u'it', u'pendant', u'all', u'What', u'life', u'EXCEPT', u'when', u'j', u'&quot', u'was', u'in', u'prison']), [u'i', u'drank', u'for', u'all', u'of', u'my', u'life', u'except', u'when', u'i', u'was', u'in', u'jail']), ((158, [u're', u'complaint', u'trademark', u'by', u'ibm', u'canada', u'lt\\xe9e', u'5', u'November', u'1999', u'pr-99-020', u'tce', u'&#91', u'ibm', u'&#93', u'at', u'the', u'p.']), [u're', u'complaint', u'filed', u'by', u'ibm', u'canada', u'ltd']), ((159, [u'after', u'other', u'avow', u'what', u'their', u'parents', u'were', u'the', u'taken', u'with', u'of the', u'problems', u'from', u'disease', u'mental', u'and', u'from', u'substance addiction']), [u'others', u'said', u'their', u'parents', u'had', u'problems', u'such', u'as', u'mental', u'illness', u'and', u'substance', u'abuse']), ((160, [u'the', u'farmers', u'local', u'were', u'surely', u'contents']), [u'i', u'&aposm', u'sure', u'the', u'local', u'farmers', u'will', u'be', u'happy']), ((161, [u'&quot', u'j & apos', u'love', u'the', u'job', u'what', u'we', u'accomplish', u'at', u'the', u'SRSA']), [u'&quot', u'i', u'love', u'the', u'work', u'we', u'do', u'at', u'srdc']), ((162, [u'bel', u'apartment', u'entirely', u'renovated', u'in', u'a', u'style', u'modern']), [u'one', u'bedroom', u'apartment', u'in', u'the', u'charming', u'little', u'streets', u'of', u'the', u'rock']), ((163, [u'\\u2022', u't5018', u'state', u'of the', u'payments', u'contractual']), [u'\\u2022', u't5018', u'slip', u'statement', u'of', u'contract', u'payments']), ((164, [u'for', u'l&apos', u'aviation', u'commercial', u'and', u'after', u'business']), [u'for', u'commercial', u'and', u'business', u'aviation']), ((165, [u'\\u2022', u'rather', u'ambitious', u'with', u'from', u'strong', u'trends', u'at', u'lead']), [u'\\u2022', u'quite', u'ambitious', u'with', u'strong', u'leadership', u'tendencies']), ((166, [u'the', u'aides', u'functional', u'at', u'your', u'service', u':']), [u'promising', u'pathways']), ((167, [u'1.2.23', u'settlement', u'no', u'87', u'fires', u'from', u'circulation', u'daily', u'117']), [u'devices', u'on', u'tractors', u'-', u'supplement', u'2', u'116']), ((168, [u'site', u'web', u'www.act-nl.ca', u'www.speakupnow.ca', u'contacts']), [u'phase', u'one', u'of', u'the', u'project', u'featured', u'two', u'ads']), ((169, [u'alberta', u'app.', u'ant', u'appellation', u'previous', u'&#91', u'can', u'&#93', u'canada', u'c.-b.']), [u'manitoba', u'n', u'noun', u'n.b.']), ((170, [u'and', u'these', u'questions', u'born', u'are', u'not', u'adjusted', u'from', u'way', u'specific', u'a', u'rule', u'implicit', u'could', u'be', u'deducted']), [u'if', u'these', u'issues', u'are', u'not', u'dealt', u'with', u'specifically', u'an', u'implicit', u'rule', u'might', u'be', u'drawn']), ((171, [u'the', u'users', u'from', u'superh', u'can', u'from now on', u'use', u'n&apos', u'imported', u'that', u'core', u'recent', u'without', u'corrective', u'additional']), [u'superh', u'users', u'can', u'now', u'run', u'any', u'recent', u'kernel', u'with', u'no', u'need', u'for', u'extra', u'patches']), ((172, [u'summary', u'established', u'by', u'this', u'beaumont']), [u'abstract', u'prepared', u'by', u'ben', u'beaumont']), ((173, [u'or', u'buy', u'the', u'&quot', u'guide', u'from', u'l&apos', u'auto', u'&quot', u'from', u'1990', u'a', u'1998', u'?']), [u'1992', u'buick', u'regal', u'limited', u'-', u'current', u'value', u'?']), ((174, [u'the', u'ratio', u'after', u'ebitda', u'reported', u'the', u'figure', u'after', u'business', u'achieved', u'106', u'%', u'in', u'2008']), [u'the', u'group', u'&aposs', u'ebitda', u'margin', u'was', u'10.6', u'%', u'in', u'2008']), ((175, [u'these', u'hotels', u'have', u'a', u'capacity', u'total', u'after', u'about', u'240', u'000', u'beds']), [u'these', u'hotels', u'have', u'a', u'total', u'capacity', u'of', u'approximately', u'240', u'000', u'beds']), ((176, [u'jhangi', u'syedan', u'abbottabad', u'pakistan', u'name', u'from', u'l&apos', u'observer', u'accredited', u'having', u'designed', u'the', u'candidate']), [u'jhangi', u'syedan', u'abbottabad', u'pakistan', u'name', u'of', u'the', u'accredited', u'observer', u'which', u'nomintates', u'the', u'candidate']), ((177, [u'a', u'guide', u'to', u'the', u'birds', u'of', u'mexico', u'and', u'northern', u'central', u'america']), [u'yellow', u'rail', u'again', u'found', u'in', u'becker', u'county', u'minnesota']), ((178, [u'after', u'l&apos', u'to have', u'deposit', u'sure', u'a', u'litter', u'they', u'l&apos', u'have', u'transported', u'up & apos', u'at', u'l&apos', u'helicopter']), [u'after', u'placing', u'him', u'on', u'a', u'stretcher', u'they', u'carried', u'him', u'back', u'to', u'the', u'waiting', u'helicopter']), ((179, [u'the', u'ceiling', u'was', u'low', u'and', u'the', u'maneuvers', u'were', u'difficult', u'for', u'the', u'pilot']), [u'our', u'ceiling', u'was', u'low', u'and', u'it', u'was', u'touch', u'and', u'go', u'getting', u'him', u'out', u'by', u'chopper']), ((180, [u'in', u'the', u'category', u'of', u'muesli', u'l&apos', u'offer', u'comprises', u'typically', u'a', u'Mark', u'House', u'and', u'many', u'other', u'brands']), [u'in', u'mueslis', u'the', u'offer', u'typically', u'incorporates', u'a', u'house', u'brand', u'and', u'several', u'other', u'museli', u'brands']), ((181, [u'less', u'from', u'1', u'%', u'of the', u'deliveries', u'HE', u'font', u'by', u'caesarean']), [u'less', u'than', u'1', u'per', u'cent', u'of', u'deliveries', u'are', u'by', u'caesarean', u'section']), ((182, [u'tim', u'guimond', u'park', u'view', u'education', u'centre', u'bridgewater', u'new', u'Scotland']), [u'tim', u'guimond', u'park', u'view', u'education', u'centre', u'bridgewater', u'nova', u'scotia']), ((183, [u'done', u'of the', u'call', u'unlimited', u'the', u'United States', u'and', u'towards', u'l&apos', u'international']), [u'place', u'unlimited', u'calls', u'to', u'usa', u'and', u'overseas']), ((184, [u'28', u'June', u'2005', u'team', u'canada', u'Atlantic', u'ready', u'at', u'return', u'at', u'chicago', u'halifax', u'new Scotland']), [u'28', u'june', u'2005', u'team', u'canada', u'atlantic', u'set', u'to', u'return', u'to', u'chicago', u'halifax', u'nova', u'scotia']), ((185, [u'pause', u'this', u'button', u'will', u'breaks', u'the', u'music', u'what', u'you', u'were', u'in', u'train', u'after', u'listen']), [u'pause', u'tap', u'this', u'button', u'to', u'pause', u'the', u'music', u'tap', u'again', u'to', u'resume']), ((186, [u'&quot', u'for', u'm.', u'chr\\xe9tien', u'it', u'means e', u'that after', u'the', u'must', u'be', u'&quot', u'a', u'little', u'plus', u'bold']), [u'for', u'mr.', u'chr\\xe9tien', u'being', u'an', u'ambassador', u'meant', u'&quot', u'being', u'a', u'bit', u'more', u'daring']), ((187, [u'l&apos', u'learning', u'HE', u'place', u'in', u'two', u'variants-a', u'the', u'variant', u'c.']), [u'learning', u'takes', u'place', u'in', u'two', u'variants-a', u'-c', u'variant']), ((188, [u'without', u'make', u'It is', u'born', u'thought', u'not', u'what', u'we', u'would', u'known', u'a', u'growth', u'also', u'lightning']), [u'without', u'fcc', u'i', u'don', u'&apost', u'think', u'we', u'could', u'have', u'grown', u'so', u'big', u'so', u'quickly']), ((189, [u'after', u'East', u'really', u'pity']), [u'and', u'that', u'is', u'a', u'real', u'shame']), ((190, [u'the', u'children', u'disabled', u'are', u'often', u'ignored', u'by', u'the', u'system', u'school']), [u'children', u'with', u'disabilities', u'are', u'often', u'neglected', u'by', u'the', u'school', u'system']), ((191, [u'more', u'nothing', u'born', u'you', u'stop', u'from', u'we', u'provide', u'of the', u'informations', u'at', u'add', u'at', u'we', u'bases', u'from', u'data']), [u'but', u'don', u'&apost', u'hesitate', u'to', u'send', u'us', u'information', u'to', u'enhance', u'our', u'databases']), ((192, [u'the', u'structure', u'and', u'dynamics', u'of', u'canada & apos;', u's', u'health', u'care', u'system']), [u'flood', u'colleen', u'm.', u'1999']), ((193, [u'category', u'ii', u'6-3']), [u'category', u'ii', u'6-3']), ((194, [u'\\u2022', u'the & apos;', u'brecht', u'm.', u'1991']), [u'ottawa', u'author']), ((195, [u'paragraph', u'44', u'second', u'line']), [u'paragraph', u'44', u'lines', u'2', u'and', u'3']), ((196, [u'the', u'sex', u'HE', u'reports', u'the', u'sex', u'of', u'worker']), [u'gender', u'relates', u'to', u'male', u'and', u'female']), ((197, [u'\\u2022', u'choose', u'of the', u'costumes', u'the', u'colors', u'bright', u'from', u'kind', u'that after', u'they', u'are', u'good', u'visible', u'for', u'the', u'motorists']), [u'let', u'children', u'draw', u'a', u'face', u'on', u'the', u'pumpkin', u'which', u'you', u'can', u'carve']), ((198, [u'the', u'only', u'informations', u'known', u'sure', u'this', u'handcar', u'are', u'those', u'from', u'the', u'press', u'from', u'l&apos', u'time']), [u'information', u'about', u'this', u'rail', u'track', u'is', u'only', u'known', u'from', u'press', u'articles', u'of', u'the', u'time']), ((199, [u'anucha', u'Skin to hire him', u'year', u'now', u'with', u'his', u'Grand parents']), [u'anucha', u'phoupinta', u'now', u'lives', u'with', u'his', u'grandparents'])]\n"
     ]
    }
   ],
   "source": [
    "print zip(sorted(BM_translated), raw_t_test)\n",
    "#zip(*BM_translated)[143]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Evaluation metric:     BLEU Score\n",
    "\n",
    "Here I use the NLTK implementation of BLEU score to measure how successful the machine translation was."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU1 score test is 0.282160574964.\n",
      "BLEU2 score test is 0.218560641558.\n"
     ]
    }
   ],
   "source": [
    "from nltk.translate import bleu_score\n",
    "from utils import remove_EOS_PAD\n",
    "\n",
    "p_phrase1 = [4,5,4,5,4,5, 1, 0]\n",
    "t_phrase = [4,5,6,34,8,76, 87, 1]\n",
    "# Truncate sequences at [1]\n",
    "t_phrase = remove_EOS_PAD(t_phrase)\n",
    "p_phrase1 = remove_EOS_PAD(p_phrase1)\n",
    "\n",
    "print \"BLEU1 score test is {}.\".format(\n",
    "    bleu_score.corpus_bleu([[t_phrase]], [p_phrase1], weights=([1])))\n",
    "print \"BLEU2 score test is {}.\".format(\n",
    "    bleu_score.corpus_bleu([[t_phrase]], [p_phrase1], weights=([0.5,0.5])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual: \n",
      "the company is also considering new interconnection with the yamal pipeline\n",
      "Prediction: \n",
      "the envisage also a new connection the pipeline yamal\n",
      "Unigram BLEU score is 0.342098104996.\n",
      "Bigram BLEU score is 0.195312929275.\n",
      "4-Gram BLEU: 0.0904845328422\n"
     ]
    }
   ],
   "source": [
    "test_targets = [[phrase] for phrase in raw_t_test]\n",
    "BM_BLEU4 = bleu_score.corpus_bleu(test_targets[0:1000], BM_trans_1, weights=(\n",
    "                                                            0.25,0.25, 0.25,0.25))\n",
    "BM_BLEU2 = bleu_score.corpus_bleu(test_targets[0:1000], BM_trans_1, weights=(0.5,0.5))\n",
    "BM_BLEU1 = bleu_score.corpus_bleu(test_targets[0:1000], BM_trans_1, weights=([1]))\n",
    "\n",
    "print \"Actual: \\n\", (\" \".join(test_targets[10][0])).encode('utf-8')\n",
    "print \"Prediction: \\n\", (\" \".join(p[10])).encode('utf-8')\n",
    "print \"Unigram BLEU score is {}.\".format(BM_BLEU1)\n",
    "print \"Bigram BLEU score is {}.\".format(BM_BLEU2)\n",
    "print \"4-Gram BLEU: {}\".format(BM_BLEU4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# The Neural Network \n",
    "\n",
    "For development reasons I will use a much smaller dataset, using only 10% of the available data to test functionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "testing_only = False\n",
    "load_embeddings = True # Do we want to load in the embeddings?\n",
    "plot_name = ''\n",
    "feed_previous_probability = 0.7\n",
    "anneal_feed_previous = False\n",
    "encoder_hidden_units = 512\n",
    "epochs =  51 # How many times we loop over the whole training data\n",
    "\n",
    "GPU = False\n",
    "\n",
    "prepend = \"short_nmt/\"\n",
    "device_1 = \"gpu:0\"\n",
    "device_2 = device_1\n",
    "data_path =prep_path\n",
    "if not GPU:\n",
    "    #prepend = ''\n",
    "    \n",
    "    device_1 = \"cpu:0\"\n",
    "    device_1 = \"cpu:1\"\n",
    "    data_path = \"DATA/\"\n",
    "\n",
    "\n",
    "dev_fraction = 0.1\n",
    "test_fraction = 0.05\n",
    "\n",
    "log_dir = prepend+plot_name\n",
    "logging.basicConfig(level=logging.DEBUG, filename=prepend+'logfile'+plot_name, filemode=\"a+\",\n",
    "                        format=\"%(asctime)-15s %(levelname)-8s %(message)s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Loading pretrained embeddings\n",
    "\n",
    "Go through each word in the vocabulary and find the pretrained word embedding in the polyglot pickle file. If one doesn't exist, initialise to a random distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def get_embeddings(id_to_word, lang):\n",
    "    # We load pretrained word2vec embeddings from polyglot to save on training time\n",
    "    filename =data_path+'polyglot-'+lang+'.pkl'\n",
    "    pretrain_vocab, pretrain_embed = pickle.load(open(filename, 'rb'))\n",
    "    # Embeddings for <PAD> and <EOS> already exist  - find them first\n",
    "    embed_vocab = [pretrain_embed[pretrain_vocab.index('<PAD>')], pretrain_embed[pretrain_vocab.index('</S>')]]\n",
    "    skip_count = 0\n",
    "    skipped_words = []\n",
    "    metadata = u'<PAD>\\n<EOS>\\n' # For tensorboard embeddings\n",
    "    for idx, word in sorted(id_to_word.items()[2::]):\n",
    "        metadata += word+r\"\\n\"\n",
    "        try:\n",
    "            pretrain_idx = pretrain_vocab.index(word)\n",
    "            embed_vocab.append(pretrain_embed[pretrain_idx])\n",
    "        except ValueError:\n",
    "            try:\n",
    "                # it could be that the word is a name which needs to\n",
    "                # be capitalized. Try this...\n",
    "                pretrain_idx = pretrain_vocab.index(str(word.title()))\n",
    "                embed_vocab.append(pretrain_embed[pretrain_idx])\n",
    "            except ValueError:\n",
    "                try:\n",
    "                    # it could be that the word is an achronym which needs to\n",
    "                    # be upper case. Try this...\n",
    "                    pretrain_idx = pretrain_vocab.index(word.upper())\n",
    "                    embed_vocab.append(pretrain_embed[pretrain_idx])\n",
    "                except ValueError:\n",
    "                    # Give up trying to find an embedding.\n",
    "                    # How many words are skipped? Which ones?\n",
    "                    skip_count +=1\n",
    "                    skipped_words.append(word)\n",
    "                    # Let's just initialise the embedding to a random normal distribution\n",
    "                    embed_vocab.append(np.random.normal(loc=0.0, scale=np.sqrt(2)/5, size=64))\n",
    "\n",
    "    embed_vocab = np.array(embed_vocab, dtype=np.float32)\n",
    "    print \"The embedding matrix for {} has {} columns and {} rows.\".format(lang,\n",
    "                                                embed_vocab.shape[0], embed_vocab.shape[1])\n",
    "    print \"{} vocab words were not in the {} embeddings file.\".format(skip_count, lang)\n",
    "    return embed_vocab, skipped_words, metadata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def variable_summaries(var):\n",
    "  \"\"\"Attach a lot of summaries to a Tensor (for TensorBoard visualization).\n",
    "  I'll just get as much data as I can.\"\"\"\n",
    "  with tf.name_scope('summaries'):\n",
    "    mean = tf.reduce_mean(var)\n",
    "    tf.summary.scalar('mean', mean)\n",
    "    with tf.name_scope('stddev'):\n",
    "      stddev = tf.sqrt(tf.reduce_mean(tf.square(var - mean)))\n",
    "    tf.summary.scalar('stddev', stddev)\n",
    "    tf.summary.scalar('max', tf.reduce_max(var))\n",
    "    tf.summary.scalar('min', tf.reduce_min(var))\n",
    "    tf.summary.histogram('histogram', var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# the ith word in words corresponds to the ith embedding\n",
    "embed_vocab_s = np.array(np.random.normal(loc=0.0, scale=np.sqrt(2)/5, size=(vocab_size_s, 64)), dtype=np.float32)\n",
    "embed_vocab_t = np.array(np.random.normal(loc=0.0, scale=np.sqrt(2)/5, size=(vocab_size_t, 64)), dtype=np.float32)\n",
    "metadata_s = ''\n",
    "metadata_t = ''\n",
    "# We only want to load in the embeddings, running this with test_only=True \n",
    "# takes a while with the full dataset\n",
    "\n",
    "if load_embeddings:\n",
    "    embed_vocab_s, skipped_s, metadata_s = get_embeddings(id2word_s, lang=lang_s)\n",
    "    embed_vocab_t, skipped_t, metadata_t = get_embeddings(id2word_t, lang=lang_t)\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "with tf.device(device_1):\n",
    "    with tf.name_scope(\"source_embeddings\"):\n",
    "        # Load encoder embeddings into trainable tensors\n",
    "        source_embeddings = tf.Variable(embed_vocab_s, trainable=True, name=\"source_embeddings\")\n",
    "        variable_summaries(source_embeddings)\n",
    "    with tf.name_scope(\"target_embeddings\"):\n",
    "        # Load decoder embeddings into trainable tensors\n",
    "        target_embeddings = tf.Variable(embed_vocab_t, trainable=True, name=\"target_embeddings\")\n",
    "        variable_summaries(target_embeddings)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Building the encoder layer\n",
    "With each forward pass a batch of phrases is fed through the neural network, one word at a time, so for the purposes of building the sequence-to-sequence model it helps to think of just a single batch.  The encoder inputs are going to be in the form of a tensor filled with word indices, of dimension `(encoder_max_time, batch size)` where maximum time is the length of the longest sequence in the batch. The batch size (though unusual) and maximum time step can change between batches so can be designated as `None` in the Tensorflow placeholder dimension. Similarly, the decoder inputs are of dimension `(decoder_max_time, batch_size)` where `decoder_max_time` does not need to equal `encoder_max_time` but must be the dimension of both the inputs and targets of the decoder. This is because at each timestep during training we must assess the quality of a single output slice (in time) of the decoder given a decoder input slice and some target sequence, therefore there must be valid tokens to compare at each time-step. If an output sequence is shorter than the target it is padded with zeros until it is the same length. Time will run down the columns of the input matrices which is called \"time-major\" format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "with tf.device(device_1):\n",
    "    with tf.name_scope('encoder_inputs'):\n",
    "        encoder_inputs = tf.placeholder(shape=(None, None), dtype=tf.int32, name='encoder_inputs')\n",
    "        encoder_inputs_length = tf.placeholder(shape=(None,), dtype=tf.int32, name='encoder_inputs_length')\n",
    "\n",
    "\n",
    "    with tf.name_scope('decoder_targets'):\n",
    "        decoder_targets = tf.placeholder(shape=(None, None), dtype=tf.int32, name='decoder_targets')\n",
    "    with tf.name_scope('decoder_inputs'):\n",
    "        decoder_inputs = tf.placeholder(shape=(None, None), dtype=tf.int32, name='decoder_inputs')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Next we find the embeddings which correspond to the words at each timestep. The words which were previously index integers for each sample in a batch/timestep, are used to index the columns of an embedding matrix. Using these column vectors as representations of the words means that the input matrices become tensors of dimension `(max_time_step, batch_size, embedding_hidden_dimension)'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "with tf.device(device_1):    \n",
    "    with tf.name_scope('encoder_inputs_embed'):\n",
    "        encoder_inputs_embedded = tf.nn.embedding_lookup(source_embeddings,\n",
    "                                                encoder_inputs, name='encoder_inputs_embed')\n",
    "    with tf.name_scope('decoder_inputs_embed'):\n",
    "        decoder_inputs_embedded = tf.nn.embedding_lookup(target_embeddings,\n",
    "                                                decoder_inputs, name='decoder_inputs_embed')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Now the encoder RNN is finally constructed, using an LSTM which is unrolled over the encoder time-steps dynamically using `tf.nn.dynamic_rnn`. Notive that the keyword argument `time_major = True`  accounts for the fact that time-steps were defined along the columns of the input matrices.\n",
    "\n",
    "The encoder RNN returns the encoder outputs - which are not used at all in sequence-to-sequence learning - and the final hidden state. This hidden state eventually becomes the first hidden state of the decoder layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "with tf.device(device_1):     \n",
    "    with tf.name_scope('encoder_rnn'):\n",
    "        encoder_cell = tf.contrib.rnn.LSTMCell(encoder_hidden_units)\n",
    "\n",
    "        encoder_outputs, encoder_final_state = tf.nn.dynamic_rnn(encoder_cell, \n",
    "                                        encoder_inputs_embedded, dtype=tf.float32, \n",
    "                                        time_major=True, scope='encoder_rnn')\n",
    "        variable_summaries(encoder_outputs)\n",
    "        variable_summaries(encoder_final_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "decoder_hidden_units = encoder_hidden_units # Set these to be the same at the moment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## The decoder layer: `raw_rnn`\n",
    "\n",
    "Now for the subtle part. Ideally we would like to have control over precisely what the decoder inputs are at each time-step, however `dynamic_rnn` has a relatively constrained API, so all inputs must be specified at the initial time-step. This means that we cannot feed tokens generated at the current time-step in as inputs in the next timestep. This actually makes it impossible to make adequate precictions with the model, since a generative model must _see_ the data it has produced in order to react accordingly, in real-time. In order to implement this, I define a _loop function_ for a `raw_rnn` which replicates the functionality of `dynamic_rnn`, which allowing for the feeding of previously generated tokens into the decoder inputs. I also allow the user to define a probability with which the previously generated tokens are mixed in with the \"ground truth\" target data, so that the model can be conditioned on a statistical mixture of both inputs. Since the length of the decoder max timesteps is unknown at the beginning of training, this has to be defined somehow so I just set it to the length of the encoder inputs plus some extra timesteps to allow for some error. This could be set to the decoder targets but strictly speaking this length would not be known in a blind test.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "reverse_encoder_inputs = True\n",
    "additional_decode_steps = 3 # Includes the extra step for the leading EOS token\n",
    "\n",
    "\n",
    "with tf.device(device_2):\n",
    "    encoder_max_time, batch_size = tf.unstack(tf.shape(encoder_inputs))\n",
    "    decoder_lengths = encoder_inputs_length + additional_decode_steps\n",
    "    # This is the projection layer, needed at every timestep because there is a possibility\n",
    "    # of feeding previous tokens in.\n",
    "    W = tf.Variable(tf.random_uniform([decoder_hidden_units, vocab_size_t], -1, 1), dtype=tf.float32)\n",
    "    #bias\n",
    "    b = tf.Variable(tf.zeros([vocab_size_t]), dtype=tf.float32)\n",
    "    \n",
    "    # The probability that we feed previous tokens in as decoder inputs\n",
    "    # 0 = use ground truth training examples as inputs\n",
    "    feed_previous_prob = tf.placeholder(tf.float32, shape=(), name='feed_previous_prob')\n",
    "    \n",
    "    # Create a slice in time of PAD - for padding entire batch once all the sequences have\n",
    "    # terminated. Also slice for EOS which is used to initialise the loop_function\n",
    "    eos_time_slice = tf.ones([batch_size], dtype=tf.int32, name='EOS')\n",
    "    pad_time_slice = tf.zeros([batch_size], dtype=tf.int32, name='PAD')\n",
    "\n",
    "    #retrieves columns of the embedding matrix. Dim= (batch_size, hidden_dim)\n",
    "    eos_step_embedded = tf.nn.embedding_lookup(embed_vocab_t, eos_time_slice)\n",
    "    pad_step_embedded = tf.nn.embedding_lookup(embed_vocab_t, pad_time_slice)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "\n",
    "The loop function tells the RNN what to do and which quantities to manipulate at each timestep. If the model is feeding previously generated tokens in as decoder inputs it will have to pass the RNN output through a linear layer and find the argmax. Intially the hidden state will be set to the final state of the encoder and the initial input will be the `<EOS>` token. These are then mapped onto the inputs for the next timestep within `loop_fn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "with tf.device(device_2):\n",
    "    def loop_fn_initial():\n",
    "        initial_elements_finished = (0 >= decoder_lengths)  # Returns false unless something is wrong\n",
    "        \n",
    "        initial_input = eos_step_embedded\n",
    "        # Self explanatory...\n",
    "        initial_cell_state = encoder_final_state\n",
    "        # Not sure what these \n",
    "        initial_cell_output = None\n",
    "        #none\n",
    "        initial_loop_state = None  # we don't need to pass any additional information\n",
    "        return (initial_elements_finished, # Boolean\n",
    "                initial_input, # EOS\n",
    "                initial_cell_state, # encoder state\n",
    "                initial_cell_output, # The output to store for this state\n",
    "                initial_loop_state)\n",
    "\n",
    "    def loop_fn_transition(time, previous_output, previous_state, previous_loop_state):\n",
    "        # What to do when moving from one time-step to the next\n",
    "        def feed_previous():\n",
    "             # We take the previous output word vectors and apply the linear layer\n",
    "             # to each output word in the batch\n",
    "            output_logits = tf.add(tf.matmul(previous_output, W), b)\n",
    "            # Greedily gives the index of the word with the highest probability\n",
    "            prediction = tf.argmax(output_logits, axis=1)\n",
    "            # Find embedding for the predicted word\n",
    "            return tf.nn.embedding_lookup(source_embeddings, prediction)\n",
    "\n",
    "        def feed_ground_truth():\n",
    "            # Find the current word in the shifted ground truth decoder targets\n",
    "            # At initialisation, time=0. Therefore, decoder inputs are passed\n",
    "            # here with a leading <EOS> token as usual.\n",
    "            ground_truth = tf.gather(decoder_inputs, time)\n",
    "            return tf.nn.embedding_lookup(target_embeddings, ground_truth)\n",
    "\n",
    "        def get_next_input():\n",
    "            # if uniform random number < fpp, feed_previous. If not feed decoder target.\n",
    "            return tf.cond(tf.constant(np.random.uniform())<feed_previous_prob, \n",
    "                            feed_previous, feed_ground_truth)\n",
    "\n",
    "        # boolean tensor of [batch_size] indicating if all of the sequences have finished\n",
    "        sequences_finished = (time >= decoder_lengths)\n",
    "        #Computes the \"logical and\" of elements to produce scalar\n",
    "        finished = tf.reduce_all(sequences_finished)\n",
    "        # If sequences are finished PAD, if not get next input\n",
    "        input = tf.cond(finished, lambda: pad_step_embedded, get_next_input)\n",
    "\n",
    "        # states and outputs are passed through \n",
    "        state = previous_state\n",
    "        output = previous_output\n",
    "        loop_state = None\n",
    "\n",
    "        return (sequences_finished,\n",
    "                input,\n",
    "                state,\n",
    "                output,\n",
    "                loop_state)\n",
    "\n",
    "    def loop_fn(time, previous_output, previous_state, previous_loop_state):\n",
    "        if previous_state is None:    # time == 0\n",
    "            assert previous_output is None and previous_state is None\n",
    "            return loop_fn_initial()\n",
    "        else:\n",
    "            # time >0\n",
    "            return loop_fn_transition(time, previous_output, previous_state, previous_loop_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Now the loop function has been defined, we can create the `raw_rnn`. Within the loop function we found word predictions at each timestep, which required projecting onto the vocabulary space to find a word (embedding). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "with tf.device(device_2):\n",
    "    with tf.name_scope('decoder_rnn'):\n",
    "        decoder_cell = tf.contrib.rnn.LSTMCell(decoder_hidden_units)\n",
    "        decoder_outputs_, decoder_final_state, _ = tf.nn.raw_rnn(decoder_cell, loop_fn, scope='decoder_rnn')\n",
    "        # Turn the output matrices dims=(batch_size, dec_hidden_layer_dim)\n",
    "        # at each timestep into a tensor\n",
    "        decoder_outputs = decoder_outputs_.stack()\n",
    "        variable_summaries(decoder_outputs)\n",
    "        variable_summaries(decoder_final_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Forward and backward steps\n",
    "\n",
    "In the previous cell, outputs from the `raw_rnn` were seen to form a tensor of dimension `(max_decoder_time, batch_size, dec_hidden_dim` since the outputs are for each sequence in the batch at each timestep are word embeddings. These need to be turned into sequences of word IDs, so in order to do so we flatten the tensor to have dimension  `(max_decoder_time*batch_size, hidden_dim)` so it can be passed through the projection layer to discriminate which word it respresents, ending up with dimension `(max_decoder_time*batch_size, vocab_site_t)`. Then after reshaping this to a tensor of shape `(max_decoder_time, batch_size, vocab_site_t)` gives us the logits/scores for each word and an argmax is performed over the vocabulary words to generate the predictions. Note it is not necessary to perform softmax because the this function preserves ordering of the elements, so `max(softmax(v)) = max(v)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "with tf.device(device_2):  \n",
    "    with tf.name_scope('projection_layer'):\n",
    "        # Get dimension information for the batch\n",
    "        decoder_max_steps, decoder_batch_size, decoder_dim = tf.unstack(tf.shape(decoder_outputs))\n",
    "        # flatten output tensor to pass through fully connected layer\n",
    "        decoder_outputs_flat = tf.reshape(decoder_outputs, (-1, decoder_dim))\n",
    "        # output is a vector of dimension: vocab_size_t\n",
    "        decoder_logits_flat = tf.add(tf.matmul(decoder_outputs_flat, W), b)\n",
    "        #prediction vals\n",
    "        decoder_logits = tf.reshape(decoder_logits_flat, (decoder_max_steps, decoder_batch_size, vocab_size_t))\n",
    "\n",
    "    with tf.name_scope('prediction'):\n",
    "        decoder_prediction = tf.argmax(decoder_logits, axis=2)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Now we have the likelihood scores for each word in `decoder_logits` we calculate the probability distribution via a softmax and then find the cross-entropy, which calculates how well the predictions correlate with the targets and sum over all the timesteps. The mean of cross-entropy is then taken over the batch. That is the end of one forward step.\n",
    "\n",
    "A backward step is then made by attempting to minimize the average cross-entropy (same as maximizing the log likelihood) using AdaM optimiser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"timestep_cross_entropy/Reshape_2:0\", shape=(?, ?), dtype=float32, device=/device:GPU:0)\n"
     ]
    }
   ],
   "source": [
    "with tf.device(device_2):     \n",
    "    with tf.name_scope('timestep_cross_entropy'):\n",
    "        timestep_cross_entropy = tf.nn.softmax_cross_entropy_with_logits(\n",
    "                                            labels=tf.one_hot(decoder_targets,\n",
    "                                            depth=vocab_size_t, dtype=tf.float32),\n",
    "                                            logits=decoder_logits)\n",
    "        variable_summaries(timestep_cross_entropy)\n",
    "    print timestep_cross_entropy\n",
    "    # loss is the mean of the cross entropy\n",
    "    with tf.name_scope('loss'):\n",
    "        loss = tf.reduce_mean(timestep_cross_entropy)\n",
    "        variable_summaries(loss)\n",
    "        tf.summary.scalar('loss', loss)\n",
    "    # We use AdaM which combines AdaGrad (parameters updated less often get updated more \tstrongly)\n",
    "    # and momentum (updates depend on the slope of previous updates - avoiding local minima)\n",
    "    with tf.name_scope('Optimizer'):\n",
    "        train_op = tf.train.AdamOptimizer().minimize(loss)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Feeding data into the model\n",
    "\n",
    "A few functions are needed to help pass data efficiently to the sequence-to-sequence model. Firstly the source and target data needs to be efficiently split up into batches. Secondly this data needs to be formatted (another function in utils called `format_batch`) and fed into the model. Since $1)$ the lengths of decoder_inputs are being generated dynamically depending on the `encoder_input_lengths` and $2)$ the length decoder_inputs must be equal to the that of decoder_outputs, the formatting of these matrices must be done carefully to make sure the time axes are match in length. The `decoder_inputs` should also be shifted one timestep to the right, since the initial input is an `<EOS>` embedding. `encoder_input_lengths` changes between batches as well, so we feed the placeholders with these values too. Finally, the `feed_previous_probability` if free to change between batches too, since it could be useful for this number to grow or shrink over time - something that I will explore in the future.\n",
    "\n",
    "** The encoder inputs were also reversed, as this has been shown to speed up training time substantially in language translation models.** For example, rather than translating from $[a, b, c] \\to [\\alpha, \\beta, \\gamma]$ the source sequences are reversed: $[c, b, a] \\to [\\alpha, \\beta, \\gamma]$ so that $a$ and $\\alpha$ are in close proximity in time. This is a main theoretical contribution of [this paper](https://papers.nips.cc/paper/5346-sequence-to-sequence-learning-with-neural-networks.pdf)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from utils import format_batch\n",
    "\"\"\"\n",
    "format_batch() takes inputs with the number of cols as sequence length and \n",
    "num of rows as batch size to the number of rows being the max sequence \n",
    "length/ num cols being batch size\n",
    "Essentially like a padding and then transpose\"\"\"\n",
    "\n",
    "def batch_source_target(source, target, batch_size):\n",
    "    assert len(source) == len(target)\n",
    "    for start in range(0, len(source), batch_size):\n",
    "        end = min(start + batch_size, len(source))\n",
    "        #print type(source[start:end])\n",
    "        #print len(target[start:end])\n",
    "        yield source[start:end], target[start:end]\n",
    "\n",
    "def make_feed_dict(fd_keys, s_batch, t_batch, reverse_encoder_inputs= False, feed_previous_prob_=1):\n",
    "    encoder_inputs_, encoder_input_lengths_  = format_batch(s_batch)\n",
    "    if reverse_encoder_inputs:\n",
    "        encoder_inputs_, encoder_input_lengths_ = format_batch([sequence[-2::-1]+[1] for sequence in s_batch])\n",
    "    dec_seq_length = max(encoder_input_lengths_)+additional_decode_steps\n",
    "    # enforce max length to equal the generated data (enc length + some margin of error)\n",
    "    decoder_targets_, _ = format_batch([sequence +[1] for sequence in t_batch], max_length=dec_seq_length)\n",
    "    decoder_inputs_, _ = format_batch([[1]+sequence[0:-1] for sequence in t_batch], max_length=dec_seq_length)\n",
    "    return {\n",
    "        fd_keys[0]: encoder_inputs_,\n",
    "        fd_keys[1]: encoder_input_lengths_,\n",
    "        fd_keys[2]: decoder_inputs_,\n",
    "        fd_keys[3]: decoder_targets_,\n",
    "        fd_keys[4]: feed_previous_prob_\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Training the model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_length' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-0e8b16086b25>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmerged\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Tensorboard stuff\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtotal_batches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_length\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0msamples_in_final\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_length\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[0;31m# number of samples in final batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_length' is not defined"
     ]
    }
   ],
   "source": [
    "batch_size = 100 # After how many sequences do we update the weights?\n",
    "epochs = 50\n",
    "merged = tf.summary.merge_all() # Tensorboard stuff\n",
    "train_length = len(s_train)\n",
    "total_batches = train_length/batch_size \n",
    "samples_in_final = train_length%batch_size # number of samples in final batch\n",
    "\n",
    "print \"there will be {} batches and {} samples in the final batch\".format(total_batches, samples_in_final)\n",
    "fd_keys = [encoder_inputs, encoder_inputs_length, decoder_inputs, decoder_targets, feed_previous_prob]\n",
    "loss_list = []\n",
    "print('Training...')\n",
    "#with tf.Session(config=tf.ConfigProto(\n",
    "#  intra_op_parallelism_threads=NUM_CORES)) as sess:\n",
    "print make_feed_dict(fd_keys, [[2,3,3],[4,4,5]], [[2,3,3],[4,4,5]])\n",
    "\n",
    "def save_metadata(metadata, filename):\n",
    "    with open(filename, 'w') as f:\n",
    "        f.write(metadata.encode('utf-8'))\n",
    "\n",
    "def get_fp_prob(feed_previous_prob, epochs, anneal_fp=True):\n",
    "    # This implements the growing/decaying feed previous prob\n",
    "    if anneal_fp:\n",
    "        for i in np.linspace(0.2,0.5,epochs):\n",
    "            yield i\n",
    "    else:\n",
    "        while True:\n",
    "            yield feed_previous_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.contrib.tensorboard.plugins import projector\n",
    "import time\n",
    "from utils import format_idx, ids_to_phrases, save_obj\n",
    "with tf.Session(config=tf.ConfigProto(log_device_placement=True,\n",
    "                                    allow_soft_placement=True)) as sess:\n",
    "    # Initializing the variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    # Many tensorboard things\n",
    "    train_writer = tf.summary.FileWriter(log_dir+'/train',\n",
    "                                        sess.graph)\n",
    "    summary_writer = tf.summary.FileWriter(log_dir,\n",
    "                                        sess.graph)\n",
    "    # This is for saving word embeddings\n",
    "    config = projector.ProjectorConfig()\n",
    "    embedding_enc = config.embeddings.add()\n",
    "    embedding_enc.tensor_name = source_embeddings.name\n",
    "    # Link this tensor to its metadata file (e.g. labels).\n",
    "    meta_s_filename = os.path.join(log_dir, 'metadata_s.tsv')\n",
    "    save_metadata(metadata_s, meta_s_filename)\n",
    "    embedding_enc.metadata_path = meta_s_filename\n",
    "\n",
    "    embedding_dec = config.embeddings.add()\n",
    "    embedding_dec.tensor_name = target_embeddings.name\n",
    "    # Link this tensor to its metadata file (e.g. labels).\n",
    "    meta_t_filename = os.path.join(log_dir, 'metadata_t.tsv')\n",
    "    save_metadata(metadata_t, meta_t_filename)\n",
    "    embedding_dec.metadata_path = meta_t_filename\n",
    "\n",
    "    # Saves a configuration file that TensorBoard will read during startup.\n",
    "    projector.visualize_embeddings(summary_writer, config)\n",
    "    # Training cycle\n",
    "    # call the generator for fp_probs\n",
    "    feed_previous_prob = get_fp_prob(feed_previous_probability, epochs, anneal_fp=anneal_feed_previous)\n",
    "    try:\n",
    "        batch_n = 0\n",
    "        ti = time.time()\n",
    "        print \"training has begun...\"\n",
    "        epoch_losses = []\n",
    "        for epoch in range(1, epochs+1):\n",
    "            fp_prob = feed_previous_prob.next()\n",
    "            logging.info(\"fp_prob = {}\".format(fp_prob))\n",
    "            ti = time.time()\n",
    "            saver = tf.train.Saver()\n",
    "            epoch_loss = []\n",
    "            if epoch%20==0:\n",
    "                save_path = saver.save(sess, log_dir+\"/model.ckpt\", epoch)\n",
    "            for s_batch, t_batch in batch_source_target(s_train,\n",
    "                                                        t_train, batch_size):\n",
    "                feed_dict = make_feed_dict(fd_keys,s_batch, t_batch,\n",
    "                                reverse_encoder_inputs=reverse_encoder_inputs,\n",
    "                                feed_previous_prob_= fp_prob)\n",
    "                _, l = sess.run([train_op, loss], feed_dict)\n",
    "                epoch_loss.append(l)\n",
    "                if (batch_n==0) or (batch_n%400) == 0:\n",
    "                    loss_list.append(l)\n",
    "                    logging.info(\"epoch {}\".format(epoch))\n",
    "                    logging.info('batch {}'.format(batch_n-(epoch-1)*total_batches))\n",
    "                    logging.info('loss: {}'.format(sess.run(loss, feed_dict)))\n",
    "                    print \"**********************************************\"*5\n",
    "                    print \"$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\"*5\n",
    "                    print (\"epoch {}\".format(epoch))\n",
    "                    print ('batch {}'.format(batch_n-(epoch-1)*total_batches))\n",
    "                    print ('loss: {}'.format(sess.run(loss, feed_dict)))\n",
    "                    summary_, predict_ = sess.run([merged, decoder_prediction], feed_dict)\n",
    "                    summary_writer.add_summary(summary_, batch_n)\n",
    "                    i = 1\n",
    "                    rand_sample = np.random.randint(0,batch_size-10)\n",
    "                    for (inp, act, pred) in zip(feed_dict[encoder_inputs].T,\n",
    "                                                 feed_dict[decoder_targets].T,\n",
    "                                                 predict_.T)[rand_sample:rand_sample+2]:\n",
    "                        logging.info('  sample {}:'.format(i))\n",
    "                        logging.info('    input     : {} \\n {}'.format(\n",
    "                                         format_idx(inp), ids_to_phrases(inp, id2word_s)))\n",
    "                        logging.info('    actual     : {} \\n {}'.format(\n",
    "                                         format_idx(act), ids_to_phrases(act, id2word_t)))\n",
    "                        logging.info('    predicted     : {} \\n {}'.format(\n",
    "                                         format_idx(pred), ids_to_phrases(pred, id2word_t)))\n",
    "                        print ('  sample {}:'.format(i))\n",
    "                        print ('    input     : {} \\n {}'.format(\n",
    "                                         format_idx(inp), ids_to_phrases(inp, id2word_s)))\n",
    "                        print ('    actual     : {} \\n {}'.format(\n",
    "                                         format_idx(act), ids_to_phrases(act, id2word_t)))\n",
    "                        print ('    predicted     : {} \\n {}'.format(\n",
    "                                         format_idx(pred), ids_to_phrases(pred, id2word_t)))\n",
    "                        i+=1\n",
    "                batch_n += 1\n",
    "            logging.info(\"Epoch {} took {} seconds to complete.\".format(epoch, time.time()-ti))\n",
    "            print (\"Epoch {} took {} seconds to complete, with average loss of {}.\".format(epoch\n",
    "                                                    ,time.time()-ti, np.mean(epoch_loss)))\n",
    "            logging.info(\"Epoch {} took {} seconds to complete, with average loss of {}.\".format(epoch\n",
    "                                                    ,time.time()-ti, np.mean(epoch_loss)))\n",
    "            save_obj(loss_list, prepend+\"loss_track\")\n",
    "            actuals = []\n",
    "            predictions = []\n",
    "            if epoch%5==0:\n",
    "                for s_batch, t_batch in batch_source_target(s_test, t_test, batch_size):\n",
    "                    feed_dict = make_feed_dict(fd_keys, s_batch, t_batch,\n",
    "                                                    reverse_encoder_inputs= True,\n",
    "                                                    feed_previous_prob_= 1)\n",
    "                    predict_ = sess.run(decoder_prediction, feed_dict)\n",
    "                    for (act, pred) in zip(feed_dict[decoder_targets].T, predict_.T):\n",
    "                        actuals.append(act)\n",
    "                        predictions.append(pred)\n",
    "                save_obj([actuals, predictions], prepend+\"predictions{}\".format(epoch))\n",
    "                print \"Made {} predictions.\".format(len(actuals))\n",
    "            if np.mean(epoch_loss) < 0.5:\n",
    "                save_path = saver.save(sess, log_dir+\"/model.ckpt\", epoch)\n",
    "                break\n",
    "        print ('Training is complete')\n",
    "        logging.info('Training is complete')\n",
    "    except KeyboardInterrupt:\n",
    "        print 'training interrupted'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24911\n"
     ]
    }
   ],
   "source": [
    "#preds_BM, targs_BM = load_obj(\"DATA/BM_translated_test\"), load_obj(\"DATA/BM_target\")\n",
    "#print len(preds_BM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEZCAYAAACEkhK6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x128fab7d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEZCAYAAACEkhK6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x128db20d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from utils import ids_to_phrases, format_idx, load_obj\n",
    "\n",
    "def bleu_over_time(data, ax, title=''):\n",
    "    actuals = raw_t_test\n",
    "    targs_form = []\n",
    "    for a in actuals:\n",
    "            targs_form.append([a])\n",
    "    data_path = 'short_data/'+data+'/predictions'\n",
    "    b1, b2, b4 = [], [], []\n",
    "    for n in range(5,35,5):\n",
    "        preds = load_obj(data_path+str(n))\n",
    "        preds = [(ids_to_phrases(format_idx(p), id2word_t)).split(' ') for p in preds[1]]\n",
    "        BLEU4 = bleu_score.corpus_bleu(targs_form, preds, weights=(0.25,0.25, 0.25,0.25))\n",
    "        BLEU2 = bleu_score.corpus_bleu(targs_form, preds, weights=(0.5,0.5))\n",
    "        BLEU1 = bleu_score.corpus_bleu(targs_form, preds, weights=([1]))\n",
    "        b1.append(BLEU1)\n",
    "        b2.append(BLEU2)\n",
    "        b4.append(BLEU4)\n",
    "    ax.plot(range(5,35,5),b1,label='BLEU1' )\n",
    "    ax.plot(range(5,35,5),b2,label='BLEU2' )\n",
    "    ax.plot(range(5,35,5),b4,label='BLEU4' )\n",
    "    ax.set_xlabel(\"Epoch\")\n",
    "    ax.set_ylabel(\"N-gram BLEU score\")\n",
    "    ax.set_title(title)\n",
    "    return b1, b2, b4\n",
    "fig = plt.figure()\n",
    "ax1 = fig.add_subplot(111)\n",
    "bleu_over_time('Predictions_70_noembed', ax1, title='Feed previous prob = 0.7')\n",
    "fig = plt.figure()\n",
    "ax2 = fig.add_subplot(111)\n",
    "bleu_over_time('Predictions_50_embed', ax2, title='Feed previous prob = 0.5')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.translate import bleu_score\n",
    "import numpy as np\n",
    "from utils import load_obj, format_idx, ids_to_phrases\n",
    "import time\n",
    "\n",
    "def BLEU_analysis(preds, targs, Ngram_len = 2, lab=\"NMT\", titl_suf=''):\n",
    "    bleu_d = dict()\n",
    "    targs_form = []\n",
    "    preds_form = []\n",
    "    results = []\n",
    "    for p, a in zip(preds, targs):\n",
    "        if p[-1] == '':\n",
    "            p = p[0:-1] #get rid of phantom whitespace at the end\n",
    "        BLEU4 = bleu_score.sentence_bleu( [a], p, weights=(0.25,0.25, 0.25,0.25))\n",
    "        BLEU2 = bleu_score.sentence_bleu( [a],p, weights=(0.5,0.5))\n",
    "        BLEU1 = bleu_score.sentence_bleu( [a], p,weights=([1]))\n",
    "        l = len(p)\n",
    "        if l not in bleu_d.keys():\n",
    "            bleu_d[l] = []\n",
    "        bleu_d[l].append(eval(\"BLEU\"+str(Ngram_len)))\n",
    "        targs_form.append([a])\n",
    "        preds_form.append(p)\n",
    "        results.append((a, p, BLEU1, BLEU2, BLEU4))\n",
    "    BLEU4 = bleu_score.corpus_bleu(targs_form, preds, weights=(0.25,0.25, 0.25,0.25))\n",
    "    BLEU2 = bleu_score.corpus_bleu(targs_form, preds, weights=(0.5,0.5))\n",
    "    BLEU1 = bleu_score.corpus_bleu(targs_form, preds, weights=([1]))\n",
    "    bleu_mean = [np.mean(v) for v in bleu_d.values()]\n",
    "    bleu_median = [np.median(v) for v in bleu_d.values()]\n",
    "    plt.figure()\n",
    "    #print max(bleu.keys())+1, len(bleu_mean)\n",
    "    #X = range(1,max(bleu.keys())+1)\n",
    "    plt.plot(bleu_d.keys(), bleu_mean, label='Mean')\n",
    "    plt.scatter(bleu_d.keys(), bleu_median, label='Median')\n",
    "    #print zip(bleu_d.keys(),bleu_mean)\n",
    "    plt.ylabel(\"Average BLEU\"+str(Ngram_len))\n",
    "    plt.xlabel(\"Sequence Length\")\n",
    "    plt.title(titl_suf)\n",
    "    plt.legend()\n",
    "    plt.xlim(0,20)\n",
    "    plt.ylim(0,1)\n",
    "    plt.show()\n",
    "    print'{} Corpus BLEU4: {:.5f} \\t BLEU2: {:.5f} \\t BLEU1: {:.5f}\\n'.format(lab, BLEU4, BLEU2, BLEU1)\n",
    "    return results\n",
    "\n",
    "\n",
    "\n",
    "# mean = 0.27129"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAEZCAYAAACTsIJzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x12860ad10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NMT Corpus BLEU4: 0.05259 \t BLEU2: 0.14169 \t BLEU1: 0.27739\n",
      "\n",
      "[18227 16806  5728  6331  5916  5916  5916     1     1     1     1     0\n",
      "     0     0     0     0     0     0     0     0     0     0]\n",
      "video projection\n",
      "video projection\n",
      "projections video 1.0 1.0 1.0 \n",
      "\n",
      "slow growth\n",
      "slow growth\n",
      "growth spring 1.0 1.0 1.0 \n",
      "\n",
      "launch of the international year of freshwater 2003\n",
      "launch of the year year the freshwater 2003\n",
      "launching from l&apos year international from l&apos water fresh 2003 0.75 0.566946709514 0.481097729098 \n",
      "\n",
      "it accurately portrays the agency &aposs plans and priorities\n",
      "it accurately portrays the organisation &aposs plans and priorities\n",
      "the described faithfully the plans and the priorities from l&apos organisation 0.888888888889 0.816496580928 0.596949179202 \n",
      "\n",
      "home &gt the canadian encyclopedia &gt biography &gt playwrights &gt deverell rex print version\n",
      "home &gt the canadian encyclopedia &gt biography &gt <UNK> &gt <UNK> <UNK> print version\n",
      "Home &gt l&apos encyclopedia Canadian &gt biography &gt dramaturges &gt deverell rex for to print 0.785714285714 0.695353495365 0.57575756362 \n",
      "\n",
      "annex xi\n",
      "annex xi\n",
      "Annex like 1.0 1.0 1.0 \n",
      "\n",
      "policy development or modification\n",
      "development or modification\n",
      "elaboration or modification from policies 0.716531310574 0.716531310574 0.716531310574 \n",
      "\n",
      "that is another characteristic of my candidacy\n",
      "that is a another consequence of my candidacy\n",
      "after East was a other signification from What candidature 0.75 0.566946709514 0.481097729098 \n",
      "\n",
      "preventive measures\n",
      "preventive measures\n",
      "measures preventive 1.0 1.0 1.0 \n",
      "\n",
      "exhibit\n",
      "exhibit\n",
      "exposition 1.0 1.0 1.0 \n",
      "\n",
      "if these issues are not dealt with specifically an implicit rule might be drawn\n",
      "if these issues are not dealt with a implicit implicit would be drawn\n",
      "and these questions born are not adjusted from way specific a rule implicit could be deducted 0.712277752802 0.620268109634 0.494874892252 \n",
      "\n",
      "abstract prepared by ben beaumont\n",
      "abstract prepared by ben beaumont\n",
      "summary established by this beaumont 1.0 1.0 1.0 \n",
      "\n",
      "when would you like to stay at the limerick strand hotel ?\n",
      "when would you like to stay at the strand strand hotel\n",
      "at those period You want stay in l&apos establishment following limerick strand hotel ? 0.830091560257 0.778694907265 0.677470202987 \n",
      "\n",
      "emerging consensus\n",
      "emerging consensus\n",
      "consensus emergent 1.0 1.0 1.0 \n",
      "\n",
      "mcguffin m kartesz jt leung ay tucker ao\n",
      "mcguffin hickey kartesz jt leung ay tucker ao\n",
      "mcguffin m. j.t. Kartz a. Y. leung to. tucker 0.875 0.790569415042 0.707106781187 \n",
      "\n",
      "see corfu channel i.c.j.\n",
      "see corfu channel case i.c.j.\n",
      "see case of strait from corf c.i.j. 0.8 0.632455532034 0.604275079471 \n",
      "\n",
      "66th plenary meeting 3 december 2004\n",
      "66th plenary meeting 3 december 2004\n",
      "66th meeting plenary 3 December 2004 1.0 1.0 1.0 \n",
      "\n",
      "institutional publications\n",
      "institutional publications\n",
      "publications institutional 1.0 1.0 1.0 \n",
      "\n",
      "possibly\n",
      "possibly\n",
      "after East possible 1.0 1.0 1.0 \n",
      "\n",
      "south pacific\n",
      "south pacific\n",
      "peaceful South 1.0 1.0 1.0 \n",
      "\n",
      "decision of the tribunal the appeals are dismissed\n",
      "the of the the appeals dismissed are dismissed\n",
      "decision of tribunal the call are rejected 0.75 0.566946709514 0.752958637319 \n",
      "\n",
      "internal oversight\n",
      "internal oversight\n",
      "control internal 1.0 1.0 1.0 \n",
      "\n",
      "sharon watts president and chief executive officer\n",
      "chief <UNK> executive president and executive officer\n",
      "sharon watts headmistress General and first Management 0.714285714286 0.487950036474 0.698534205658 \n",
      "\n",
      "guilty pleas reduce the length of trials\n",
      "guilty pleas reduce the length trials trials\n",
      "the pleas from guilt shorten the duration of the trial 0.857142857143 0.755928946018 0.643458884161 \n",
      "\n",
      "rate group ii 16 cents per mile or 10 cents per kilometre\n",
      "rate group ii 16 cents per mile or 10 cents per kilometre\n",
      "group ii 10 cents by kilometer or 16 cents by mile 1.0 1.0 1.0 \n",
      "\n",
      "click thumbnail to see a larger photo of le méridien beach plaza\n",
      "click thumbnail to see a larger photo of the plaza beach\n",
      "click sure a vignette for get a photo plus big from the méridien beach plaza 0.830091560257 0.728402387953 0.655227643641 \n",
      "\n",
      "b conditions for the illumination of stop lamps\n",
      "b conditions of the stop lamps lamps\n",
      "b conditions relatives at l&apos illumination of the fires stop 0.743038199786 0.463365728147 0.633783487662 \n",
      "\n",
      "coles fisheries limited contact\n",
      "coles fisheries limited contact\n",
      "coles fisheries limited contact after business 1.0 1.0 1.0 \n",
      "\n",
      "c evidence gathering and cooperation issues in hard-core cartel investigations and\n",
      "c technical gathering in cooperation investigations hard-core cartel cartels and\n",
      "c information and cooperation in the investigations sure the agreements unjustifiable 0.723869934429 0.269770396709 0.494063102468 \n",
      "\n",
      "f pressure receptacles are transported in an outer packaging\n",
      "f pressure receptacles are transported in operating packaging\n",
      "f transporter of the containers at pression in of the packaging Outside 0.772184789762 0.697675060053 0.624019544194 \n",
      "\n",
      "stewart l. coffin address\n",
      "stewart l. coffin address\n",
      "stewart l. coffin address 1.0 1.0 1.0 \n",
      "\n",
      "h.e. ms. margaret beckett\n",
      "ms. margaret beckett\n",
      "ms margaret beckett 0.716531310574 0.716531310574 0.716531310574 \n",
      "\n",
      "co-operation with non-governmental organisations\n",
      "co-operation with non-governmental organizations\n",
      "cooperation with the organisations non government 0.75 0.707106781187 0.707106781187 \n",
      "\n",
      "it is the bastion of our democracy\n",
      "it is the fight of our democracy\n",
      "after East the rampart from our democracy 0.857142857143 0.755928946018 0.691441569284 \n",
      "\n",
      "the guest reviews are submitted by our customers after their stay at classical egnatia grand\n",
      "the guest reviews are submitted by our customers after their stay at <UNK> <UNK>\n",
      "here is the comments done by we clients after their stay in this establishment classical egnatia grand 0.798053811175 0.792921579091 0.780767533659 \n",
      "\n",
      "poverty is widespread\n",
      "poverty is widespread\n",
      "the poverty East widely widespread 1.0 1.0 1.0 \n",
      "\n",
      "• international relations\n",
      "• international relations\n",
      "• relations international 1.0 1.0 1.0 \n",
      "\n",
      "policing issues\n",
      "policing issues\n",
      "at. retention from l&apos order 1.0 1.0 1.0 \n",
      "\n",
      "that was unavoidable\n",
      "that was unavoidable\n",
      "it was inevitable 1.0 1.0 1.0 \n",
      "\n",
      "steven d &aposarcy of\n",
      "steven d &aposarcy\n",
      "steven after arcy cabinet 0.716531310574 0.716531310574 0.716531310574 \n",
      "\n",
      "cocaine\n",
      "cocaine\n",
      "cocaine 1.0 1.0 1.0 \n",
      "\n",
      "problem\n",
      "problem\n",
      "problem 1.0 1.0 1.0 \n",
      "\n",
      "11-13 chemin des anémones\n",
      "11-13 chemin des anémones\n",
      "11-13 path of the anemones 1.0 1.0 1.0 \n",
      "\n",
      "birth registration\n",
      "birth registration\n",
      "recording of the births 1.0 1.0 1.0 \n",
      "\n",
      "42nd plenary meeting\n",
      "42nd plenary meeting\n",
      "42e meeting plenary 1.0 1.0 1.0 \n",
      "\n",
      "ms. olivia chibanda third secretary\n",
      "ms. olivia <UNK> third secretary\n",
      "Mrs olivia skin third secretary 0.8 0.632455532034 0.795270728767 \n",
      "\n",
      "the stratospheric ozone layer prevents most ultraviolet radiation from reaching the earth\n",
      "the ozone ozone layer prevents ultraviolet ultraviolet radiation reaching reaching the earth\n",
      "the layer after ozone stratospheric stop l&apos essential of influence ultraviolet after reach the terre 0.75 0.583874208121 0.510995581129 \n",
      "\n",
      "loud applause\n",
      "loud applause\n",
      "bright applause 1.0 1.0 1.0 \n",
      "\n",
      "tripoli 16 july 2007\n",
      "26 16 july 2007\n",
      "tripoli the 16 July 2007 0.75 0.707106781187 0.707106781187 \n",
      "\n",
      "• gallagher kelly director of regional affairs\n",
      "• gallagher kelly director of of affairs\n",
      "• gallagher kelly headmistress of the business regional 0.857142857143 0.755928946018 0.643458884161 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds = load_obj('short_data/Predictions_70_noembed/predictions30')\n",
    "#BM_translated = zip(*load_obj('short_data/BM_translated'))[1]\n",
    "actuals, preds = raw_t_test, [unicode(ids_to_phrases(format_idx(p), id2word_t), 'utf-8').split(' ') for p in preds[1]]\n",
    "\n",
    "r1 = BLEU_analysis(preds, raw_t_test, Ngram_len = 1, titl_suf='NMT: 30 epochs and FPP=0.7')\n",
    "#r4 = BLEU_analysis(predictions, raw_t_test, Ngram_len = 4, titl_suf=': 30 epochs and FPP=0.7')\n",
    "\n",
    "\"\"\"\n",
    "preds = load_obj('short_data/Predictions_70_noembed/predictions35')\n",
    "actuals, preds = raw_t_test, [unicode(ids_to_phrases(format_idx(p), id2word_t), 'utf-8').split(' ') for p in preds[1]]\n",
    "\n",
    "\n",
    "r1 = BLEU_analysis(predictions, raw_t_test, Ngram_len = 1, titl_suf='NMT: 30 epochs and FPP=0.7')\n",
    "\n",
    "\n",
    "b1_nmt = [b1 for a, p, b1, b2, b4 in r1]\n",
    "\"\"\"\n",
    "bm = p\n",
    "print bm\n",
    "#np.random.shuffle(r1)\n",
    "for i, dat in enumerate(r1[0:1000]):\n",
    "    a, pred, b1, b2, b4 = dat\n",
    "    if b1> 0.7:\n",
    "        print  u' '.join(a)\n",
    "        print  u' '.join(pred)\n",
    "        print u' '.join(BM_trans_1[i]), b1, b2, b4, '\\n'\n",
    "    #if u'it accurately portrays' in u' '.join(a):\n",
    "    #    print a, p, b1, b2, b4\n",
    "    \"\"\"\n",
    "    try:\n",
    "        print u\"Target: {} \\nPrediction: {} \\n b1: {:.3f} b2: {:.3f} b4: {:.3f}\\n\".format(\n",
    "                                                            u' '.join(a), \n",
    "                                                            unicode(u' '.join(p).encode('utf-8)', 'utf-8')), \n",
    "                                                            b1, b2, b4)\n",
    "    except Exception as err:\n",
    "        print a\n",
    "        print p\n",
    "        print err\n",
    "    \"\"\"\n",
    "\n",
    "#print b1_nmt.count(0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAEZCAYAAACTsIJzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEkeJQURE4igxiIhInP8P64IYIIAXW1sAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11e4dec90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BM Corpus BLEU4: 0.09048 \t BLEU2: 0.19531 \t BLEU1: 0.34210\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nfor a, p, b1, b2, b4 in r_bm[0:200]:\\n    try:\\n        print u\"Target: {} \\nPrediction: {} \\n b1: {:.3f} b2: {:.3f} b4: {:.3f}\\n\".format(\\n                                                            u\\' \\'.join(a), \\n                                                            unicode(u\\' \\'.join(p).encode(\\'utf-8)\\', \\'utf-8\\')), \\n                                                            b1, b2, b4)\\n    except Exception as err:\\n        print err\\n        print a\\n        print p\\n'"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#BM_translated = load_obj('short_data/BM_translated')\n",
    "#preds_BM = BM_translated\n",
    "#print preds_BM\n",
    "\n",
    "r_bm = BLEU_analysis(p, raw_t_test[0:1000], Ngram_len=1, titl_suf='Benchmark Model', lab=\"BM\")\n",
    "#b1_bm = [b1 for a, p, b1, b2, b4 in r_bm]\n",
    "#print b1_bm.count(0.)\n",
    "\"\"\"\n",
    "for a, p, b1, b2, b4 in r_bm[0:200]:\n",
    "    try:\n",
    "        print u\"Target: {} \\nPrediction: {} \\n b1: {:.3f} b2: {:.3f} b4: {:.3f}\\n\".format(\n",
    "                                                            u' '.join(a), \n",
    "                                                            unicode(u' '.join(p).encode('utf-8)', 'utf-8')), \n",
    "                                                            b1, b2, b4)\n",
    "    except Exception as err:\n",
    "        print err\n",
    "        print a\n",
    "        print p\n",
    "\"\"\"\n",
    "#BLEU_analysis(preds_BM, raw_t_test, Ngram_len=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ibid pp. 198 and 199 ibid p. 198 and 199\n",
      "communications &amp public relations communications and relations public\n",
      "mr. raymond leigh mills m. raymond leigh mills\n",
      "measurement and possible adverse effects &quot hhs publication fda 81-8163 may 1981 measurement and possible adverse effects &quot hhs publication fda 81-8163 May 1981\n",
      "national and transnational differences differences national and international\n",
      "gosden t torgerson dj maynard a. what is to be done about fundholding ? 16 gosden t torgerson dj maynard a. what is to be done about fundholding ?\n",
      "learning from the suffolk system &quot journal of money credit and banking vol learning from the suffolk system journal of money credit and banking vol.\n",
      "guerin m.r. r.a. jenkins and b.a. tomkins guerin M.R. r.a. jenkins and b.a. tomkins\n",
      "preventive measures measures preventive\n",
      "milenio ambiental n ° 4 - risk management people maria noel estrada ortiz millennium environmental n ° 4 - risk management people maria noel estrada ortiz\n",
      "22027\n",
      "63.9487901212\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "flat = []\n",
    "flat_a = []\n",
    "for a, p, b1, b2, b4 in r_bm:\n",
    "    flat += p\n",
    "    flat_a += a\n",
    "    try:\n",
    "        if b1 > 0.7:\n",
    "            print ' '.join(a), ' '.join(p)\n",
    "            #try:\n",
    "            #    print \"Target: {} \\nPrediction: {} \\n b1: {:.3f} b2: {:.3f} b4: {:.3f}\\n\".format(\n",
    "        #                                                      ' '.join(a), ' '.join(p), b1, b2, b4)\n",
    "    except Exception as err:\n",
    "        print a\n",
    "        print p\n",
    "        print err\n",
    "fd = nltk.FreqDist(flat)\n",
    "fd_keys = fd.keys()\n",
    "fd_a = nltk.FreqDist(flat_a)\n",
    "fd_keys_a = fd_a.keys()\n",
    "print len(fd_keys)\n",
    "counts = 0\n",
    "for k in fd_keys:\n",
    "    if k in fd_a.keys():\n",
    "        counts += 1\n",
    "print \"Percentage of benchmark vocabulary within the target corpus vocabulary: {:0.3f}\".format(\n",
    "                                                                100*(counts/float(len(fd_keys))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ground truth\n",
      "Min: 1  Max: 15  Mean: 9.36   Median: 10.0   Mode: 10   1st Quart.: 7.0   IQR: 5.0   3rd Quart.: 12.0\n",
      "Dictionary method\n",
      "Min: 1  Max: 18  Mean: 11.03   Median: 11.0   Mode: 12   1st Quart.: 8.0   IQR: 7.0   3rd Quart.: 15.0\n"
     ]
    }
   ],
   "source": [
    "from utils import sequence_stats\n",
    "print \"Ground truth\"\n",
    "sequence_stats(raw_t_test)\n",
    "#print \"NMT\"\n",
    "#from utils import sequence_stats\n",
    "#sequence_stats(predictions)\n",
    "print \"Dictionary method\"\n",
    "sequence_stats(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1112 1045\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEACAYAAACj0I2EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nyew5lDgBgfoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1301a9b10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'\\nl_a= load_obj(\"DATA/loss_track_a\")\\nl_b= load_obj(\"DATA/loss_track_b\")\\nl_c= load_obj(\"DATA/loss_track_c\")\\nl_58= load_obj(\"DATA/loss_track_58\")\\nl_59= load_obj(\"DATA/loss_track_59\")\\nl_61= load_obj(\"DATA/loss_track_61\")\\nl_62= load_obj(\"DATA/loss_track_62\")\\nwhile len(l_c)< len(l_b):\\n    l_c.append(0)\\n#l_128\\nbatches = 35000/51\\nticks = [(batches*i, i) for i in range(1,51)]\\nfig = plt.figure()\\n\\nplt.plot(30*np.arange(0,len(l_c)),l_c, label=\\'$P_f=0$\\')\\n#plt.\\nfig = plt.figure()\\nT = 100*np.arange(0,len(l_58))\\nplt.plot(30*np.arange(0,len(l_a)),l_a, label=\\'$P_f=1$\\' )\\nplt.plot(30*np.arange(0,len(l_b)),l_b, label=\\'$P_f=0.5$\\')\\nplt.plot(T,l_62, label=r\"$P_f=0.2$\")\\nplt.plot(30*np.arange(0,len(l_c)),l_c, label=\\'$P_f=0$\\')\\nplt.plot(T,l_58, label=r\"$N_h=512$ annealed\")\\nplt.plot(T,l_59, label=r\"$N_h=256$ annealed\")\\n\\n#plt.plot(T,l_61, label=r\"$N_h=256$, $P_f=0.2$\")\\n\\nplt.legend(loc=\\'upper center\\', bbox_to_anchor=(0.5, 1.25),\\n          ncol=3, fancybox=True, shadow=True)\\nplt.ylabel(\\'Batch Loss\\')\\nplt.xlabel(\\'Batch Number\\')\\nplt.xlim(0,35000)\\nplt.ylim(0,6)\\nplt.show()\\n'"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.font_manager import FontProperties\n",
    "from utils import *\n",
    "plt.figure()\n",
    "l_a= load_obj(\"fp_06_data/loss_track8\")\n",
    "l_b= load_obj(\"fp_02_data/loss_track8\")\n",
    "print len(l_a), len(l_b)\n",
    "plt.plot(l_a)\n",
    "plt.plot(l_b)\n",
    "plt.ylim(0,6)\n",
    "plt.show()\n",
    "#l_c= load_obj(\"DATA/loss_track_c\")\n",
    "\"\"\"\n",
    "l_a= load_obj(\"DATA/loss_track_a\")\n",
    "l_b= load_obj(\"DATA/loss_track_b\")\n",
    "l_c= load_obj(\"DATA/loss_track_c\")\n",
    "l_58= load_obj(\"DATA/loss_track_58\")\n",
    "l_59= load_obj(\"DATA/loss_track_59\")\n",
    "l_61= load_obj(\"DATA/loss_track_61\")\n",
    "l_62= load_obj(\"DATA/loss_track_62\")\n",
    "while len(l_c)< len(l_b):\n",
    "    l_c.append(0)\n",
    "#l_128\n",
    "batches = 35000/51\n",
    "ticks = [(batches*i, i) for i in range(1,51)]\n",
    "fig = plt.figure()\n",
    "\n",
    "plt.plot(30*np.arange(0,len(l_c)),l_c, label='$P_f=0$')\n",
    "#plt.\n",
    "fig = plt.figure()\n",
    "T = 100*np.arange(0,len(l_58))\n",
    "plt.plot(30*np.arange(0,len(l_a)),l_a, label='$P_f=1$' )\n",
    "plt.plot(30*np.arange(0,len(l_b)),l_b, label='$P_f=0.5$')\n",
    "plt.plot(T,l_62, label=r\"$P_f=0.2$\")\n",
    "plt.plot(30*np.arange(0,len(l_c)),l_c, label='$P_f=0$')\n",
    "plt.plot(T,l_58, label=r\"$N_h=512$ annealed\")\n",
    "plt.plot(T,l_59, label=r\"$N_h=256$ annealed\")\n",
    "\n",
    "#plt.plot(T,l_61, label=r\"$N_h=256$, $P_f=0.2$\")\n",
    "\n",
    "plt.legend(loc='upper center', bbox_to_anchor=(0.5, 1.25),\n",
    "          ncol=3, fancybox=True, shadow=True)\n",
    "plt.ylabel('Batch Loss')\n",
    "plt.xlabel('Batch Number')\n",
    "plt.xlim(0,35000)\n",
    "plt.ylim(0,6)\n",
    "plt.show()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "ename": "NotFoundError",
     "evalue": "Unsuccessful TensorSliceReader constructor: Failed to find any matching files for fp_06_data/nmt_8/\n\t [[Node: save_39/RestoreV2_12 = RestoreV2[dtypes=[DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/cpu:0\"](_recv_save_39/Const_0, save_39/RestoreV2_12/tensor_names, save_39/RestoreV2_12/shape_and_slices)]]\n\nCaused by op u'save_39/RestoreV2_12', defined at:\n  File \"/usr/local/Cellar/python/2.7.12_2/Frameworks/Python.framework/Versions/2.7/lib/python2.7/runpy.py\", line 174, in _run_module_as_main\n    \"__main__\", fname, loader, pkg_name)\n  File \"/usr/local/Cellar/python/2.7.12_2/Frameworks/Python.framework/Versions/2.7/lib/python2.7/runpy.py\", line 72, in _run_code\n    exec code in run_globals\n  File \"/usr/local/lib/python2.7/site-packages/ipykernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python2.7/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python2.7/site-packages/ipykernel/kernelapp.py\", line 474, in start\n    ioloop.IOLoop.instance().start()\n  File \"/usr/local/lib/python2.7/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/usr/local/lib/python2.7/site-packages/tornado/ioloop.py\", line 887, in start\n    handler_func(fd_obj, events)\n  File \"/usr/local/lib/python2.7/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/usr/local/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/local/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/local/lib/python2.7/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 276, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/local/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 228, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/local/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 390, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/local/lib/python2.7/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python2.7/site-packages/ipykernel/zmqshell.py\", line 501, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2827, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/local/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-24-a6fb770cd285>\", line 76, in <module>\n    test_model()\n  File \"<ipython-input-24-a6fb770cd285>\", line 15, in test_model\n    loader = tf.train.import_meta_graph(log_dir+'model.ckpt-40'+ '.meta')\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/python/training/saver.py\", line 1595, in import_meta_graph\n    **kwargs)\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/python/framework/meta_graph.py\", line 499, in import_scoped_meta_graph\n    producer_op_list=producer_op_list)\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/python/framework/importer.py\", line 308, in import_graph_def\n    op_def=op_def)\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 2336, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 1228, in __init__\n    self._traceback = _extract_stack()\n\nNotFoundError (see above for traceback): Unsuccessful TensorSliceReader constructor: Failed to find any matching files for fp_06_data/nmt_8/\n\t [[Node: save_39/RestoreV2_12 = RestoreV2[dtypes=[DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/cpu:0\"](_recv_save_39/Const_0, save_39/RestoreV2_12/tensor_names, save_39/RestoreV2_12/shape_and_slices)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-a6fb770cd285>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     74\u001b[0m \"\"\"\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m \u001b[0mtest_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-24-a6fb770cd285>\u001b[0m in \u001b[0;36mtest_model\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtesting_only\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0mloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_meta_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_dir\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'model.ckpt-40'\u001b[0m\u001b[0;34m+\u001b[0m \u001b[0;34m'.meta'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m             \u001b[0mloader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactuals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mfd_keys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mencoder_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_targets\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/tensorflow/python/training/saver.pyc\u001b[0m in \u001b[0;36mrestore\u001b[0;34m(self, sess, save_path)\u001b[0m\n\u001b[1;32m   1455\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Restoring parameters from %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1456\u001b[0m     sess.run(self.saver_def.restore_op_name,\n\u001b[0;32m-> 1457\u001b[0;31m              {self.saver_def.filename_tensor_name: save_path})\n\u001b[0m\u001b[1;32m   1458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1459\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    776\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 778\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    779\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    980\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 982\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    983\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1030\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1032\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1033\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1050\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1051\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1052\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1053\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1054\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotFoundError\u001b[0m: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for fp_06_data/nmt_8/\n\t [[Node: save_39/RestoreV2_12 = RestoreV2[dtypes=[DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/cpu:0\"](_recv_save_39/Const_0, save_39/RestoreV2_12/tensor_names, save_39/RestoreV2_12/shape_and_slices)]]\n\nCaused by op u'save_39/RestoreV2_12', defined at:\n  File \"/usr/local/Cellar/python/2.7.12_2/Frameworks/Python.framework/Versions/2.7/lib/python2.7/runpy.py\", line 174, in _run_module_as_main\n    \"__main__\", fname, loader, pkg_name)\n  File \"/usr/local/Cellar/python/2.7.12_2/Frameworks/Python.framework/Versions/2.7/lib/python2.7/runpy.py\", line 72, in _run_code\n    exec code in run_globals\n  File \"/usr/local/lib/python2.7/site-packages/ipykernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python2.7/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python2.7/site-packages/ipykernel/kernelapp.py\", line 474, in start\n    ioloop.IOLoop.instance().start()\n  File \"/usr/local/lib/python2.7/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/usr/local/lib/python2.7/site-packages/tornado/ioloop.py\", line 887, in start\n    handler_func(fd_obj, events)\n  File \"/usr/local/lib/python2.7/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/usr/local/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/local/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/local/lib/python2.7/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 276, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/local/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 228, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/local/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 390, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/local/lib/python2.7/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python2.7/site-packages/ipykernel/zmqshell.py\", line 501, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2827, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/local/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-24-a6fb770cd285>\", line 76, in <module>\n    test_model()\n  File \"<ipython-input-24-a6fb770cd285>\", line 15, in test_model\n    loader = tf.train.import_meta_graph(log_dir+'model.ckpt-40'+ '.meta')\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/python/training/saver.py\", line 1595, in import_meta_graph\n    **kwargs)\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/python/framework/meta_graph.py\", line 499, in import_scoped_meta_graph\n    producer_op_list=producer_op_list)\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/python/framework/importer.py\", line 308, in import_graph_def\n    op_def=op_def)\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 2336, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 1228, in __init__\n    self._traceback = _extract_stack()\n\nNotFoundError (see above for traceback): Unsuccessful TensorSliceReader constructor: Failed to find any matching files for fp_06_data/nmt_8/\n\t [[Node: save_39/RestoreV2_12 = RestoreV2[dtypes=[DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/cpu:0\"](_recv_save_39/Const_0, save_39/RestoreV2_12/tensor_names, save_39/RestoreV2_12/shape_and_slices)]]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "This was not used at all in getting the solution as in the report.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import tensorflow as tf\n",
    "def test_model():\n",
    "    \"\"\"\n",
    "    Test the saved model against the test dataset\n",
    "    \"\"\"\n",
    "    \n",
    "    #raw_s_test = load_obj(\"DATA/source_test\") # Data for benchmark model \n",
    "    #raw_t_test = load_obj(\"DATA/target_test\") # Data for benchmark model \n",
    "    loaded_graph = tf.Graph()\n",
    "    \n",
    "    with tf.Session(graph=loaded_graph, config=tf.ConfigProto(log_device_placement=True,\n",
    "                                    allow_soft_placement=True)) as sess:\n",
    "        # Load model\n",
    "        if testing_only:\n",
    "            loader = tf.train.import_meta_graph(log_dir+'model.ckpt-40'+ '.meta')\n",
    "            loader.restore(sess, log_dir)\n",
    "        predictions, actuals = [], []\n",
    "        fd_keys = [encoder_inputs, decoder_inputs, decoder_targets]\n",
    "        try:\n",
    "            batch_n = 0\n",
    "            print \"testing has begun...\"\n",
    "            for s_batch, t_batch in batch_source_target(s_test, t_test, batch_size):\n",
    "                feed_dict = make_feed_dict(fd_keys, s_batch, t_batch,\n",
    "                                                reverse_encoder_inputs= True,\n",
    "                                                feed_previous_prob_= 1)\n",
    "                predict_ = sess.run(decoder_prediction, feed_dict)\n",
    "                for i, (inp, act, pred) in enumerate(zip(feed_dict[encoder_inputs].T,\n",
    "                                                         feed_dict[decoder_targets].T,\n",
    "                                                         predict_.T)):\n",
    "                    actuals.append([remove_EOS_PAD(act)])\n",
    "                    predictions.append(remove_EOS_PAD(pred))\n",
    "                    \n",
    "                    print \"batch number: \", batch_n\n",
    "                    print ('    actual     : {} \\n \\t {}'.format(\n",
    "                                     format_idx(act), ids_to_phrases(act, id2word_t)))\n",
    "                    print ('    predicted     : {} \\n \\t {}'.format(\n",
    "                                     format_idx(pred), ids_to_phrases(pred, id2word_t)))\n",
    "                    logging.info('    actual     : {} \\n \\t {}'.format(\n",
    "                                     format_idx(act), ids_to_phrases(act, id2word_t)))\n",
    "                    logging.info('    predicted     : {} \\n \\t {}'.format(\n",
    "                                     format_idx(pred), ids_to_phrases(pred, id2word_t)))\n",
    "                    if i >3:\n",
    "                        break\n",
    "\n",
    "            batch_n+=1\n",
    "        except KeyboardInterrupt:\n",
    "            print 'testing interrupted'\n",
    "\"\"\"\n",
    "# Get Tensors from loaded model\n",
    "loaded_x = loaded_graph.get_tensor_by_name('x:0')\n",
    "loaded_y = loaded_graph.get_tensor_by_name('y:0')\n",
    "loaded_keep_prob = loaded_graph.get_tensor_by_name('keep_prob:0')\n",
    "loaded_logits = loaded_graph.get_tensor_by_name('logits:0')\n",
    "loaded_acc = loaded_graph.get_tensor_by_name('accuracy:0')\n",
    "\n",
    "# Get accuracy in batches for memory limitations\n",
    "test_batch_acc_total = 0\n",
    "test_batch_count = 0\n",
    "\n",
    "for train_feature_batch, train_label_batch in helper.batch_features_labels(test_features, test_labels, batch_size):\n",
    "    test_batch_acc_total += sess.run(\n",
    "        loaded_acc,\n",
    "        feed_dict={loaded_x: train_feature_batch, loaded_y: train_label_batch, loaded_keep_prob: 1.0})\n",
    "    test_batch_count += 1\n",
    "\n",
    "print('Testing Accuracy: {}\\n'.format(test_batch_acc_total/test_batch_count))\n",
    "\n",
    "# Print Random Samples\n",
    "random_test_features, random_test_labels = tuple(zip(*random.sample(list(zip(test_features, test_labels)), n_samples)))\n",
    "random_test_predictions = sess.run(\n",
    "    tf.nn.top_k(tf.nn.softmax(loaded_logits), top_n_predictions),\n",
    "    feed_dict={loaded_x: random_test_features, loaded_y: random_test_labels, loaded_keep_prob: 1.0})\n",
    "helper.display_image_predictions(random_test_features, random_test_labels, random_test_predictions)\n",
    "\"\"\"\n",
    "\n",
    "test_model()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
