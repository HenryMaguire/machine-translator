{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The dataset\n",
    "\n",
    "Here I will introduce the dataset, experiment with it, tokenize it, preprocess it and save it to a new set of files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It was Nov . 10 of last year when stagehand Kevin Monk , his kindergarten-teacher wife , Roseanna , and Genevieve were getting ready to go on a family trip .\n",
      "The beginning of a new era means a problem for all Christian democracy , including Angela Merkel as well .\n",
      "Obama ? The first anti-American President . Here is why ?\n",
      "While villages report a sharp decline in interest in driver &apos;s license renewal , the authorities in the city are overloaded with applications and the interest in the license renewal has grown this week .\n",
      "Internet use is extremely limited on the island .\n",
      "On November 4th the lophoscopist of Cali CTI passed into history as the man who confirmed the identity of the FARC top leader , &quot; Alfonso Cano , through the comparison of his fingerprints .\n",
      "Both teams found it difficult to join in the combination ; the game remained around the mid-field line most of the time .\n",
      "The researchers put a small bucket with a moth larva in a vertical cylinder .\n",
      "&quot; It &apos;s like \n",
      "5001\n",
      "5001\n"
     ]
    }
   ],
   "source": [
    "import codecs\n",
    "import numpy as np\n",
    "f_fr = codecs.open(\"DATA/en-fr_paropt/dev.tok.fr\", encoding='utf-8')\n",
    "f_en = codecs.open(\"DATA/en-fr_paropt/dev.tok.en\", encoding='utf-8')\n",
    "text_fr = f_fr.read()\n",
    "text_en = f_en.read()\n",
    "print text_en[0:1000]\n",
    "print len(text_en.split('\\n'))\n",
    "print len(text_fr.split('\\n'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenizing and preprocessing\n",
    "Here we can see that sentences are not really split over lines since \"Here is why ?\" is technically it's own sentence - however, splitting these cases up will lead to misalignment between the english and french corpora so it's too risky. What I will do then is just tokenize each line, remove capitalisation and then replace the final punctuation with `<EOS` and unknown characters with `<UNK>` or `1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "still aligned: True\n"
     ]
    }
   ],
   "source": [
    "# Fix a small pathology with the datasets, whereby spaces are put between words\n",
    "# and end of sentence tokens\n",
    "def format_eos(text):\n",
    "    #text = text.replace(' .', '.')\n",
    "    text = text.replace('?', '.')\n",
    "    text = text.replace('!', '.')\n",
    "    text = text.replace(\"didn't\", 'did not')\n",
    "    text = text.replace(\"shouldn't\", 'should not')\n",
    "    return text\n",
    "\n",
    "text_fr = format_eos(text_fr)\n",
    "text_en = format_eos(text_en)\n",
    "print \"still aligned:\", len(text_en.split('\\n')) == len(text_fr.split('\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corpora still aligned: True \n",
      "\n",
      "It was Nov . 10 of last year when stagehand Kevin Monk , his kindergarten-teacher wife , Roseanna , and Genevieve were getting ready to go on a family trip .\n",
      "--------\n",
      "The beginning of a new era means a problem for all Christian democracy , including Angela Merkel as well .\n",
      "--------\n",
      "Obama . The first anti-American President . Here is why .\n",
      "--------\n",
      "While villages report a sharp decline in interest in driver &apos;s license renewal , the authorities in the city are overloaded with applications and the interest in the license renewal has grown this week .\n",
      "--------\n",
      "Internet use is extremely limited on the island .\n"
     ]
    }
   ],
   "source": [
    "# First split up into lines using the Punkt tokenizer\n",
    "import nltk.data\n",
    "#fr_sent_detector = nltk.data.load('tokenizers/punkt/french.pickle')\n",
    "#en_sent_detector = nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "#fr_sents = fr_sent_detector.tokenize(text_fr)\n",
    "#en_sents = en_sent_detector.tokenize(text_en)\n",
    "\n",
    "# First split the text up into lines\n",
    "en_sents = text_en.split('\\n')\n",
    "fr_sents = text_fr.split('\\n')\n",
    "print \"corpora still aligned:\", len(en_sents)== len(fr_sents), '\\n'\n",
    "print \"\\n--------\\n\".join(en_sents[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[u'it', u'was', u'nov', u'.', u'10', u'of', u'last', u'year', u'when', u'stagehand', u'kevin', u'monk', u',', u'his', u'kindergarten-teacher', u'wife', u',', u'roseanna', u',', u'and', u'genevieve', u'were', u'getting', u'ready', u'to', u'go', u'on', u'a', u'family', u'trip', u'<EOS>'], [u'the', u'beginning', u'of', u'a', u'new', u'era', u'means', u'a', u'problem', u'for', u'all', u'christian', u'democracy', u',', u'including', u'angela', u'merkel', u'as', u'well', u'<EOS>'], [u'obama', u'.', u'the', u'first', u'anti-american', u'president', u'.', u'here', u'is', u'why', u'<EOS>'], [u'while', u'villages', u'report', u'a', u'sharp', u'decline', u'in', u'interest', u'in', u'driver', u'&apos', u';', u's', u'license', u'renewal', u',', u'the', u'authorities', u'in', u'the', u'city', u'are', u'overloaded', u'with', u'applications', u'and', u'the', u'interest', u'in', u'the', u'license', u'renewal', u'has', u'grown', u'this', u'week', u'<EOS>'], [u'internet', u'use', u'is', u'extremely', u'limited', u'on', u'the', u'island', u'<EOS>'], [u'on', u'november', u'4th', u'the', u'lophoscopist', u'of', u'cali', u'cti', u'passed', u'into', u'history', u'as', u'the', u'man', u'who', u'confirmed', u'the', u'identity', u'of', u'the', u'farc', u'top', u'leader', u',', u'&quot', u';', u'alfonso', u'cano', u',', u'through', u'the', u'comparison', u'of', u'his', u'fingerprints', u'<EOS>']]\n"
     ]
    }
   ],
   "source": [
    "# Next split up into tokens using the toktok tokenizer\n",
    "from nltk.tokenize import toktok\n",
    "tok_tokenizer = toktok.ToktokTokenizer()\n",
    "\n",
    "def tokenize_sentences(text):\n",
    "    new_text = []\n",
    "    for sentence in text:\n",
    "        # This splits up tokens within a sentence\n",
    "        tok_sent = tok_tokenizer.tokenize(sentence.lower())\n",
    "        # Will be more efficient to replace final punctuation with <EOS> now\n",
    "        new_text.append(tok_sent[0:-1]+[u'<EOS>'])\n",
    "    return new_text\n",
    "print tokenize_sentences(en_sents[0:6])\n",
    "tokenized_en = tokenize_sentences(en_sents)\n",
    "tokenized_fr = tokenize_sentences(fr_sents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vocabularies, Sequences and Word frequencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I need to:\n",
    "- Find the frequencies of words, limiting the vocabulary size to some number of the most common words and replacing out of vocabulary words with `<UNK>`\n",
    "- Give each token an ID, where `<EOS>` =0, `<UNK>` =1 and the remaining tokens are assigned numbers from 2 to vocab_size+1 at random\n",
    "- Make each sequence the same length by padding the end of sequences with zeros until their length matches the longest sequence. Given the long-tailed distribution of sequence length and the limited capacity of LSTMs we may be able to truncate max sequence length substantially.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYMAAAEZCAYAAAB1mUk3AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3Xt83HWd7/HXp20uQ9O0FAPILeFWWhewDRRZwEOKrQfh\ncazCas3xthhdaxW1Xguec1oXdYFdtlbY2oIVkIdNq3IRz3YtVBo8XqC1Fwq2BVxMSlGaINClNfTG\n5/zx+03ySzIz+SWZycxk3s/HYx6d+c1vZj6/zPT3+X3v5u6IiEhpG5XvAEREJP+UDERERMlARESU\nDEREBCUDERFByUBERFAyEMk6M6s1szfMbFT4eI2ZfTjG694ws9NyH6FIX2PyHYBIPplZK3AscBgw\nwIG73P2zQ3zrrgE87n7FQF8jMtyUDKTUOXClu6/PdyAEyUgkL1RNJJLiJGxmHzWz/2dm/2xmL5vZ\nf5rZ5ZHn68zsUTPba2YPmdltZnZPyjc3W29mHwvvn25mLWb2qpm1m1lzr91nmdkzZvYXM7stq0cp\nkoGSgUh6FwA7gGOAfwZWRJ5bCTwWPvd14MPEq+a5AVjr7hOAk4Bbez1/JXAeMBV4v5m9cygHIBKX\nkoEIPBBe/b8S/tsUbm9z9+97MIHX3cCbzexYMzsZOB9Y6O6H3f3XwIMxP+sQUGtmJ7r7QXf/Ta/n\n/8ndX3P354H1BElBJOeUDERgtrtPdPejw3+TJYAXkzu4e2d4two4AXjZ3V+PvMfzMT/rywT/7zaY\n2ZNmdk2v5/dE7v81/DyRnFMDssjAG27/DEw0s8pIQjiZGNVE7t4O/AOAmV0MrDOzR939uQHGIJJV\nKhmIDJC77wJ+BywyszIz+1vgf/TaLWWCMbO/M7MTw4evAm8AR3IWrEhMKhmIwM/M7Ajd4wweBn6a\nYr/olf8HCdoRXgI2AKuA0Wn2jd6fDnzbzKoJqoQ+6+5tKfZL9VgkZ0yL24gMnZmtAna4+9fzHYvI\nYKiaSGQQzOx8MzvNApcD7wYeyHdcIoOlaiKRwTkeuA+YCOwG5rr7E/kNSWTwVE0kIiKqJhIRkSKt\nJjIzFWdERAbB3VN2ey7akoG7F8ytvb2dRGIi8ARBb8AnSCQm0t7envY1CxcuzHvcQ73pGArjpmPI\n/61Y4s+kaJNBIampqWHFiqUkEjOorq4nkZjBihVLqampyXdoIiKxFGU1USFqbJzDzJmX0draSl1d\nnRKBiBQVJYMsqqmpiZ0EGhoachvMMNAxFAYdQ/4Ve/xQpF1LzcyLMW4RkXwyM3ykNSCLiEj2KBlk\nQUdHBxs3bqSjoyPfoYiIDIqSwRA1N6+mtnYys2bNpbZ2Ms3Nq9Puq6QhIoVKbQZD0NHRQW3tZDo7\n1wPnAttIJGbQ1razT0Nyc/NqmprmUV5ex8GDraxYsZTGxjl5iVtESpPaDHKktbWV8vI6gkQAcC5l\nZbW0trb22K+jo4Ompnl0dq5n795NdHaup6lpnkoIIlIwlAyGoK4uuMqHbeGWbRw61EZdXV2P/eIm\nDRGRfFEyGIK4I4/jJg0RkXxRm0EWdHR09DvyONlmUFZWy6FDbWozEJFhl6nNQMlgGMVJGiIiuaJk\nICIi6k0kIiKZKRmIiIiSgYiIKBmIiAhKBnmhOYpEpNAoGQyzgUxsJyIyXNS1dJAGM2ZgIBPbiYhk\nm7qWZtlgr+41R5GIFCqVDAYo7tV9qpKDSgYikk8qGWRRnKv7dCWHuBPbiYgMN5UMBqi/q/s4V/+a\no0hE8kElgyzq7+o+TsmhpqaG6dOnKxGISMFQyWCQ0l3dq11ARApVppLBmOEOZqSoqalJeXJPlhya\nmmb0WLtAiUBECplKBjmidgERKTRaz0BERNSAnE2aV0hERiIlgwHQvEIiMlKpmigm9RISkWKnaqIs\n0LxCIjKSKRnEVFdXx8GDrcC2cMs2Dh1qo66uLqufozYJEckHJYMMoifm4ZhXSG0SIpIvajNIo7l5\nNU1N8ygvD0oEK1YspbFxTs7GD6hNQkRyTSOQB6ijo4Ompnl0dq6nszM4MTc1zWDmzMvSjjweqi1b\ntjBq1MmkapNQMhCRXFM1UQqpGotHjz6BNWvW5KQuv7l5NbNnz2H//mfJdZuEiEgqSgYp9G0svpl9\n+/6Ta69dMuC6/P4ahHfs2ME118zl9dcfBb4PNABnaK0DERle7l50tyDs3Fq5cpUnEhO9qupsh4TD\nEw7u8IQnEhO9vb099nuMH1/vicREX7lyVZ/nKyqqHSaF7+0O7T527CRfu3Ztrg5NREpUeO5MeV5V\nA3IGHR0drFmzhmuvXcJrr23u2l5dXc+6dcuZPn16xtfGWwTnXuBqQA3HIpJbGnQ2SDU1NVxxxRUc\nPtzGQOvy+xuk1v18A7AUmAFMoqLiUlUPiciwU2+ifgx2fYKe7Q7BFX80ifR8fg5wHBUVs9my5TGm\nTJmSwyMSEekrpyUDM1thZnvMbFtk20Iz221mm8Pb5ZHnrjOzZ81sh5m9M5exDURj4xza2naybt1y\n2tp20tg4p9/X9DdIre/zV3PnnbcrEYhIXuS0zcDMLgH2AT9w93PDbQuB19z9X3vtOwVYCUwHTgLW\nAWemahwopvUM+hukpkVwRGS45G3Qmbv/ysxqU8WUYttsYJW7HwZazexZ4ALg8VzGmJSrk3J/g9Ry\nNYhNRGQg8tWA/Gkz22pm3zOz8eG2E4HnI/u8EG7LOc0JJCKlLh8NyEuBf3R3N7NvALcAHyd1aSFt\nXdCiRYu67jc0NNDQ0DCoYPqbekJEpFi1tLTQ0tISa9+cjzMIq4l+lmwzSPecmS0gGBBxU/jcz4GF\n7t6nmiibbQYbN25k1qy57N27qWtbnHEEIiLFJt/jDIzIVb+ZHR957irgqfD+g8AHzKzczE4FzgA2\n5Dq44VqnIFu03oGI5EKuu5auBH4DTDKzXWZ2DXCzmW0zs63ApcB8AHffDvwI2A6sAeYNR5eh4Vin\nIFvUtiEiuaLpKEKF3sVT6x2IyFBpPYMYCr2LZ3L6iqCRG7TegYhkk+YmKhLF1rYhIsVFyaBIFFPb\nhogUH7UZpFDI7QeFHJuIFLZMbQZKBr00N6+mqWke5eVBtcyKFUtjTUwnIlLolAxiUo8dERnJ8j3o\nrGj0tyDNcNMAMxEZLkoGEYXUY0cDzERkOKmaqJdkm0F0VbPhbjNQdZWI5IIGnQ1AY+McZs68LK89\ndjTATESGm5JBCvkejdzf+skiItmmNoMCpAFmIjLc1GZQwDTATESySeMMRERE4wxERCQzJQMREVEy\nEBERJQMREUHJQEREUDIoCpqwTkRyTcmgwGnCOhEZDhpnUMA0YZ2IZJPGGRSpQltfQURGLiWDAlZI\n6yuIyMimZFDANGGdiAwXtRkUAU1YJyLZoInqMtCJVkRKhRqQ01C3TRGRQMmWDNRtU0RKjUoGKajb\npohIt5JNBuq2KSLSrWSTgbptioh0i9VmYGZnu/tTwxBPLOpNJCIycEPuWmpmvwLKgbuAle7+alYj\nHKBSG2cgIpINQ25AdvdLgA8CJwO/M7OVZjYrizGKiEgeDahrqZmNBt4DfAf4L8CA6939vtyElzaO\nki8ZpKreUpWXiGSSjWqic4FrgCuBh4EV7r7ZzE4AfuvutdkMOEY8JZ0MmptX09Q0j/LyoEfUihVL\nAfpsa2yck+dIRaSQZCMZ/BK4A/iJu3f2eu7D7n5PViKNqZSTQarBchUVbwdGceDAo2gAnYikkykZ\njIn5HlcAne5+JHzDUUClu/91uBNBqUsOluvsTA6W28GBAweAWlINoFMyEJE44o4zWAckIo+PCrfJ\nMOs5WK4D+BTwc+AlNIBORAYrbjKodPd9yQfh/aNyE5JkEh0sN3bsJcAxQAOwFJgBTKKi4lINoBOR\nAYmbDPabWX3ygZmdB3Rm2F9yqLFxDm1tO7nvvltJJF4mKBHMAe6lomIPW7b8Ro3HIjIgcRuQpwOr\ngD+Fm94MzHH3TTmMLVM8JduA3FuyZ1FZWS2HDrWpF5GIpJWVxW3MrAw4i2BswU53P5S9EAdGyaAn\njS8QkTiylQwuAuqI9EBy9x9kI8CBUjIQERm4IXctNbN7gNOBrcCRcLMDeUkG0j+VFkRkIOKOMzgf\neIsux4tDqhHKakcQkUziNiD/GPisu/859yH1T9VE6Wk5TxFJJxvLXr4J2G5ma83sweQtxgevMLM9\nZrYtsu1oM3vIzJ4O32985LnvmNmzZrbVzKbGjE0itJyniAxG3GqiRYN8/zuBW+nZtrAAWOfuN5vZ\nV4HrgAVm9i7gdHc/08zeBiwDLhzk55asniOUg5KBRiOLSH/irmfwKNAKlIX3NwKbY7zuV8ArvTbP\nBu4O798dPk5u/0H4useB8WZ2XJz4pJuW8xSRwYjbm+gTwD8AEwl6FZ1IcOX+jkF85rHuvgfA3V80\ns2PD7ScCz0f2eyHctmcQn1HSGhvnMHPmZepNJCKxxa0m+jRwAfA4gLs/GzmJZ0uqRg21Eg9STU2N\nkoCIxBY3GRxw94NmwfnazMYw+BP1HjM7zt33mNnxQHu4fTfBsppJJ9E9/UUfixYt6rrf0NBAQ0PD\nIMMRERmZWlpaaGlpibVv3K6lNwOvAh8BrgXmAdvd/WsxXlsH/Mzdzwkf3wS87O43mdkCYIK7LzCz\nK4BPu/uVZnYh8G13T9mArK6lIiIDl42VzkYBTcA7Capz1gLf6++MbGYrCeZXPoag7n8h8ADwY4JS\nwC7gfe7+arj/bcDlwH7gGndP2UitZCAiMnBZmZuokCgZxKdpKUQkaciDzszsj2b2XO9bdsOUbGtu\nXk1t7WRmzZpLbe1kmptX5zskESlQcauJjok8rATeB0x09/+Tq8D6iUclg35oWgoR6W3IJQN3/0vk\n9oK7fxu4MqtRSlZpWgoRGYi4g87qIw9HEcxiGrdbquSBpqUQkYGIe0K/JXL/MMHUFO/PejSSNclp\nKZqaZvRYEjNaRaTGZRFJUm+iES7dCV9rHoiUnmyMM/hCpufd/V8HGdugKBkMjRqXRUpTNtYzOB/4\nFMHEcScCc4F6YFx4kwLX0dHBxo0bu0oKalwWkai4bQYnAfXu/hqAmS0C/t3dP5SrwCR7elcJLV58\noxqXRaSHuCWD44CDkccHw21S4Do6Omhqmkdn53r27t1EZ+d65s9fwOLFN2rNAxHpErdk8ANgg5nd\nTzBb6XvpXqBGCliySqizs2eVUH39VNradqo3kYgAA+hNFI41eHv48JfuviVnUfUfixqQY1JjsYgk\nZaMBGeAo4L/cfQmw28xOzUp0klNaBlNE4ojbtXQhQY+is9x9kpmdAPzY3S/OdYBp4lHJYIA0wExE\nsjHOYCswDdjs7tPCbdvc/dzMr8wNJQMRkYHLRjXRwfDs6+Ebjs1WcCIikn9xk8GPzGw5MMHMPgGs\nA+7IXViSS9EBaCIiMLDeRLOILHvp7g/nMrB+YlE10SBpTiKR0jWkNgMzGw2sc/cZuQhuMJQMBkfd\nTEVKW6Zk0O+gM3c/YmZvmNl4d9+b/fCGT7JHTVVVFfv27Su5njXpBqC1traW1N9BRPqKOwJ5H/Ck\nmT0M7E9udPfP5iSqHEhWj8AEOjv/TCJxBvBCSVWTaMEbEUknbtfSj6ba7u55mZJioNVE3dUj9wJX\nA6VbTZJMitEFb0olGYqUukFXE5nZKe6+K18n/Wzprh4ZC9SRaurmUkkGjY1zmDnzMg1AE5Ee+uta\n+kDyjpndm+NYcqa7emQ/wYqd28JnSrOapKamhunTpysRiEiX/pJBtDhxWi4DyaXu+XmuprKyGriQ\nROIczdMjIhLK2GZgZpvdvb73/XwbbNfSUu9NJCKlbdDjDMzsCEHdigEJ4K/JpwB39+osxxqLxhkM\nL01yJzIyDHpuIncf7e7V7j7O3ceE95OP85IIZHg1N6+mtnYys2bNpbZ2Ms3Nq/MdkojkQOzpKAqJ\nSgbDQyOWRUaWbC1uIyUm2SU3VVdcERlZlAwESD2Tac8Ry1CqXXFFSoGSgaRtF9CSmSKlQ20GJS5O\nu4B6E4mMDEOatVRGtjgzmdbU1CgJiIxwqiYqcWoXEBFQMih5ahcQEVCbgYQ0VYfIyKdxBtKvmpoa\n/vCH5zjvvEs02likBKlkIIBGG4uUApUMpF8abSxS2pQMBFCvIpFSp2QggHoViZQ6tRlID9HRxoBG\nHouMIGozkNiS6yOvW/dIyvmKUk1oJyLFTyUD6SNdz6LFi29k/vwFlJcH7QsrViylsXFOvsMVkZgG\nvexloVIyyK2NGzcya9Zc9u7d1LWtquocDh3azYEDjxIkiBYqKmbzi1+soby8XFVJIkVA1UQyIKl7\nFu2ivPxUgkSwGriaAwequOSSWVx6aZMGqYkUOSUD6SNVz6IlS/6Fw4fbgBZgHnAv8DrwGJ2d2+js\nXE9T0zy1JYgUKU1hLSk1Ns5h5szLevQmqq6u5pprZnPgwPHAWKCOVIPUVF0kUnzy1mZgZq3AXuAN\n4JC7X2BmRxPUQdQCrcD73X1viteqzSBPduzYwbRpF3HgwP3A1YCmrxApFoXaZvAG0ODu09z9gnDb\nAmCdu58FPAJcl7foJKUpU6Zw553LSCSuprKyGriQROIcDVITKXL5LBn8ETjf3f8S2bYTuNTd95jZ\n8UCLu09O8VqVDPJMU16LFJ+C7FpqZs8BLwMOLHf375nZK+5+dGSfv7j7MSleq2QgIjJAhboG8kXu\n/qKZ1QAPmdnTBIkhlkWLFnXdb2hooKGhIeV+WsxdREpVS0sLLS0tsfYtiEFnZrYQ2Ad8nKAdIVlN\ntN7dp6TYP1bJoLl5NU1N8zRiVkSEAqwmMrOjgFHuvs/MxgIPAV8H3gG87O43mdlXgaPdfUGK1/eb\nDLRYi4hIT4VYTXQccL+ZeRjDD939ITP7HfAjM/sYsAt432A/ILlYS2en+sGLiPQnL8nA3f8ITE2x\n/WVgZjY+o+eUCkHJQIu1iIikNmKno9BiLSIi8RVEA/JADaRrqXoTiYgECq4Beag0zkBEZOAKdToK\nEREpEEoGIiKiZCAiIkoGIiKCkoGIiKBkICIiKBmIiAhKBpJFHR0dbNy4kY6OjozbRKTwKBlIVjQ3\nr6a2djKzZs3llFMm8Y1vfIvly+/o2lZbO5nm5tWAEoRIIdIIZBmyntOF7wA+BUwAXgQeIzqF+OLF\nNzJ//gKtMSGSByU5HYXmJBo+GzduZNasuezd+3NgMrAeOAB8AtjatV9V1TkcOrSbAwcepfcaE4C+\nL5EcK7npKKJVFtHqCcmN7unCHwbqCE70dcDzBFOIQzCF+C7Ky08Nn4fkGhPpqpNEZBi5e9HdgrBT\na29v90RiosMTDu7whCcSE729vT3ta2ToVq5c5ZWVExyOivztb3JI+LhxUz2RmOjLlt3e57uprJyg\n70tkmITnzpTn1RFXMkiucNb76rO1tTV/QZWAxsY57Nr1DDfc8LXIGhI3sWzZEn7xi9tpa9vJJz/5\niT5rTHzta1/u9X29mVGj3sSWLVvyeDQipWfEtRlo7eP866+9Jvo8kKLx+RgSiZfVuCySZSXXgNzc\nvJqmpnmUldVy6FCbTioFKpkUNm/eyuc//xVef/0g8FuUxEVyo+SSAag3UaFLJuxkF9PPfW4ut976\n7+zf3937qLq6nnXrljN9+vQ8RioycpRkMpDClaoqr7LyUsxGRba1UFExmy1bHmPKlCn5DVhkhCi5\nrqVS2FI18peXn8r113+RRGIGlZWnAVcwalQt5513CcuX36ERyyI5ppKBDLtMjfwvvfQS06ZdFBmY\ndjOwiHHjJnP4sNp/RIZCJQMpKDU1NX26mK5YsZSamhr27dsXlgzOBTqAm4DHeO21zXR2rqepaZ5K\nCCI5oJKB5E2qRv6epYa+U1pkalRWpwGRzFQykIJUU1PD9OnTe5y4o6WGqqqPAc/Qc0qLtq7xCVGa\ngkRkaFQykIIUHYMwf/6CjGNGNNBQJJ5MJYMxwx2MSBw1NTVdJYerrnpPxuqfZO+kzs6+U5AoGYjE\nMyKSgeqKR7ZkYkine9bUbSRLBumqk0QktaJvM1BdsWTqnSQi8RR1m4HqiotHtktv6XoiqYQokt6I\n7U2UaiTr6NEnsGbNGvVFLyDZLr2le79UvZOStO6ySD/SLXRQyDfCxW36LmSTXExlmicSE33lylUD\nWPZBciHbiw0N5v1WrlzlicREHz++Xr8LKWmM1MVtevZJPwdYhEarFpZsLjbU0dHBmjVrGDOmNuP7\nRUsBHR0dNDXNo7NzPXv3btLvQiSNok4GEKyw1da2k9tu+xLjxk1GK5wVlp49fWCwPX2SVUPXXnsL\nr722M+379a5CWr78Dq18JxJHuiJDId9IsQay1j4uXMlqmurqwVXfpa8OnNrj/VL9BrTGskg3MlQT\njYhxBtBdZdTUNKPHaFX1Ksm/xsY5zJx52aB7+vQdVPYVqqru4dZbP88FF1zAvn37unoS9dzvzYwe\nfSzXXns1S5bodyGSyYhJBjD0k47kTn8DxzJJNajsyJE/8frrBznvvEu6VktbvPjGyH7Besr79x/D\nkiXLWbz4Rurrp/b7u1D3VClZ6YoMhXwjRTWRjGy9q5qWLbs9ZfXPsmW3e2XlBIejBlw1pF5HMtKR\noZqoqAedSWmJXrW3trYya9Zc9u7d1PV8cnrrV155hauu+krK9ZSTr+195a8BjFIKRuygMykt0UFl\nmXopTZs2jTfeeL7Pc5s3b007+C2bXWBFilFRJwONKi1dmeYjSvXc4sU3Mn/+grTjDbLVBVakaKWr\nPyrkG6D6XXH3oDvphg0bUrYHRJ/bsGGDjx9fH7YhBLfq6mm+YcOGrv2j7RKVlRP8hhu+qS6oMqIw\nEtsMEomJqt+V2FK1CVRWXspPf7qak08+mX379nWVApYvv4NvfeuWrl5KqRbUyXZs6sEkwyFTm0He\nr/IHcwP6vcoT6S165V9WNs7Ly8d7InGaQ8ITiXMy9lLKVgmhd0lmqCXcTCUjkd7IUDLI+4l9MDdA\no0plUNrb233t2rXh72e9Q8/fUUVFtY8bN63HhUZV1dl+1113Dfj31d+JP07iyXSyV1WpDNSITAZD\nneJASld3+8EGh/o+J/6KiglDngk3zom/b+Jp97FjJ/natWu9vb3db7jhm2lP9pp+RQZjRCYDdxWR\nZXC6T6R9SwbRE3dV1dkOicjz672iotq3b9/e4716/wZTnajTlTi6E88qh6MdzvCysnFeVjYu48C5\nTA3ivWMayv8T/R8bWYouGQCXAzuBZ4Cvpng++38lKSnJK/fKyrqwzeDsPpPe3XXXXZET+KowcUzy\niooJvnLlqrTVNKlO1H1LHOlGTLeHSeGHfUot0XaxdCWDZCJLxvSZz3xu0FVJqoYaeYoqGRCMffgD\nUAuUAVuByb32ycXfaVitX78+3yEMWbEfQ3t7u3/3u9/17du3p7z6TV+CWO/l5VVeWXl0ylLD9u3b\n+5z4Kysn+IIF1/WZUmPDhg2+evVqHzv2reG+yaqr9j6llsrKCb527dqueJMn/qOOOiNNVdT9vUo2\nmauSoqWAONVQcUsNcfYrhN/SUEpBhRB/f9rb24suGVwI/Efk8YLepYORkAwWLlyY7xCGrBSOYeXK\nVV5RUe0wqVcJ4RSHM/qUGkaPHhv2Ujq1q8SR7Lk0fnx91/iF6BV8ZeUELy8f36tkEK06Oj1j76eP\nf/zjKcZSrHKodjgzbemi93FGSwE33PDNjD324pYa4u6X79/SUEtB+Y6/P8njK7ZkcDVwe+Txh4Dv\n9Non+3+tYVboP544SuUYuq/0oyWE5Ek71bZMJYjUayyUlVVFur1WeXn5+K7BbwsWXJ+xjeNLX/qS\nu6cqyaTeP30JKN46EHEbrwfSyJ3P31I2GuML+f9Cz+NLnwwKcTqKVAMifNijEAlNmTKFO+9cRkXF\nbOBNBIPWaoDvEjRvJbe1AqfSPb9RA2VlJzB69ClE5zwaPfpYRo06uce2ROJMHnigmXXrlvPCC8+x\ne/ezrFu3nF27nuGqq94Tzps0Fqij9/xJr776KtA9RUd3nA3AUmAGMImKiktTruWQal6m8vJTuf76\nL6ac7iPuPE7FMt9TscQ5WH2PL7WCG4FsZhcCi9z98vDxAoJsdlNkn8IKWkSkSHiaEciFmAxGA08D\n7wD+DGwAGt19R14DExEZwQpupTN3P2JmnwEeIuhZtEKJQEQktwquZCAiIsOvEBuQMzKzy81sp5k9\nY2ZfzXc8cZjZSWb2iJltN7Mnzeyz4fajzewhM3vazNaa2fh8x5qJmY0ys81m9mD4uM7MHgvjbzaz\ngitpRpnZeDP7sZntMLPfm9nbivA7mG9mT5nZNjP7oZmVF/r3YGYrzGyPmW2LbEv7dzez75jZs2a2\n1cym5ifqntIcw83hb2mrmd1rZtWR564Lj2GHmb0zP1EPTFElAzMbBdwG/Hfgb4BGM5uc36hiOQx8\nwd3fAvwt8Okw7gXAOnc/C3gEuC6PMcbxOWB75PFNwC1h/K8CTXmJKr4lwBp3nwK8lWCUe9F8B2Z2\nAnAtUO/u5xJU8zZS+N/DnQT/Z6NS/t3N7F3A6e5+JvBJYNlwBppBqmN4CPgbd58KPEv3MbwFeD8w\nBXgXsNTMUk8bXUCKKhkAFwDPunubux8CVgGz8xxTv9z9RXffGt7fB+wATiKI/e5wt7uB9+Qnwv6Z\n2UnAFcD3IpsvA+4N798NvHe444rLzMYBb3f3OwHc/bC776WIvoPQaGBsePWfAP5E0He0YL8Hd/8V\n8Eqvzb3/7rMj238Qvu5xYLyZHTcccWaS6hjcfZ27vxE+fIzg/zTAu4FV4W+slSBRXDBcsQ5WsSWD\nE4HnI493h9uKhpnVAVMJfjzHufseCBIGQef1QrUY+DLhmA8zOwZ4JfKfYTdwQp5ii+M04CUzuzOs\n6rrdzI6iiL4Dd/8TcAuwC3gB2AtsBl4tou8h6dhef/djw+29/4+/QHH8H/8YsCa8X5THUGzJoKgH\npJlZFfAT4HNhCaEoYjezK4E9Yekm+R0Yfb+PQj6eMUA98G/uXg/sJ6iqKOSYezCzCQRXzrUEJ/yx\nBNUQvRUZ6jpgAAAFNUlEQVTNMaVQdP/HzexrwCF3b05uSrFbQR8DFF8y2A2cEnl8EkExueCFxfqf\nAPe4+0/DzXuSRWAzOx5oz1d8/bgYeLeZPQc0E1QPfZugCJ/8DRX6d7EbeN7dfxc+vpcgORTLdwAw\nE3jO3V929yPA/cBFwIQi+h6S0v3ddwMnR/Yr6OMxs48SVJ/+z8jmojqGpGJLBhuBM8ys1szKgQ8A\nD+Y5pri+D2x39yWRbQ8Cfx/e/yjw094vKgTufr27n+LupxH8zR9x9w8B64H3hbsVbPwAYZXE82Y2\nKdz0DuD3FMl3ENoFXGhmlWGDZPIYiuF76F2SjP7d/57umB8EPgJdsxG8mqxOKgA9jsHMLge+Arzb\n3Q9E9nsQ+EDY0+tU4AyCwbOFLd2kRYV6I5gM5mmCRpkF+Y4nZswXA0cIpuPeQlDPezkwEVgXHs/D\nwIR8xxrjWC4FHgzvnwo8TrDuxGqgLN/x9RP7WwkuKLYC9wHji+07ABYSdEDYRtDwWlbo3wOwkuDK\n+ABBQrsGODrd352gx+AfgCcIek4V6jE8C7SF/583A0sj+18XHsMO4J35jj/OTYPORESk6KqJREQk\nB5QMREREyUBERJQMREQEJQMREUHJQEREUDKQImJmXwunb34inF9oer5jGopwnqSrcvC+10Xu15rZ\nk9n+DBl5lAykKISjUa8Aprr7WwmmZng+86tK1vW9HmswkfRLyUCKxZuBl9z9MIAH8/O8CGBm9WbW\nYmYbzew/InPenBcuPLIlXIjkyXD7R83s1uQbm9nPzOy/hfdnmdlvzOx3ZrY6nNkUM/ujmS0ys01h\nyWRSuH2smX0/XGxmq5m9N9P7pJPhGNab2Y1m9rgFizpdHG5PhO/7lJndZ8HiNvVm9k9AIiw53RO+\n/ZhwltanzOznZlaRpe9ERhAlAykWDwGnhCfEf4ucvMcAtwJXu/t0gkVIvhW+5vvAZ9x9Wvg4eoXc\n52o5nJb7fwHvcPfzgU3AFyK7tLv7eQQLrnwp3Pa/CebPOdeDRU4eSfM+X0x3YP0cA8Bod38bMB9Y\nFG6bB7zs7meHMdQDuPt1wF/dvd7dPxzueyZwa7jvXuDqdLFI6Sqo5fFE0nH3/WZWD7ydYNbUVWa2\ngOBEezbwcDh52yjgT+EShOM9WJQE4B6C+aAyuRB4C/Dr8L3KgN9Enr8//HcT3QvIzATmROLcG075\n3ft9fpvhc89KdQyR5++LfG5teP8SgpljcfffW2Q5xhSec/dku8EmoC7DvlKilAykaHgwkdYvgV+G\nVT4fIZgg7Cl3vzi6rwVr6qarKz9Mz1JxZfJlwEPu/sE0r0vOTHmE7v87luJz+nuf3owUxxDjc3u/\nR6r70dcn36MSkV5UTSRFwcwmmdkZkU1TCWaMfBqoCRuYMbMxZvYWD5a03GtmF4X7R0/MrcBUC5xM\n95KEjwEXm9np4XslzOzMfkJ7iGBd4mScEwbxPimPoZ/P/RVhiSTc95zIcwfNbHTkccGvvyv5p2Qg\nxaIKuDtsBN1KsNj4Ig/Wwv474KZw+xbgb8PXfIxgMfLN0Tdy918TJITfE1S1bAq3v0Qwt36zmT1B\nULVzVvJlaeL6BnC0mT1pZluAhn7ep0co4edmOoZ0n7sUeJOZPQX8I/AUQXsAwO3Ak5EGZPUmkn5p\nCmspCWZWC/xfdz+n352LgAUrm5W5+wEzO41gbYBJyd5WIgOlNgMpJSPpyucoYL2ZlYWP5yoRyFCo\nZCAiImozEBERJQMREUHJQEREUDIQERGUDEREBCUDEREB/j+h4pJv85DwkgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x185f10290>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYMAAAEZCAYAAAB1mUk3AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3XucXHV9//HXJ8ludshmk6wuILfdEC6BQmBDl6JQ2GAi\ntwpWW2NaK8L+rDRY/YG3gP09ErFa6E9/FLFI1JSCJZuoQUSblpCS1QdV3JgLF0O4FHYhINmlYErC\nSkLy+f1xzuyemczMzuzcZ9/Px2MfmTlzzsxnz07O53zv5u6IiMj4NqHcAYiISPkpGYiIiJKBiIgo\nGYiICEoGIiKCkoGIiKBkIFJ2ZnaHmd1Q7jhkfFMykHHPzPrM7A0z+x8zez389/ByxyVSSpPKHYBI\nBXDgEnffkG4HM5vo7vtLGJNISalkIBKwhCdmrWZ2wMyuNLN+4D/C7WeZ2X+a2WtmtsXMzoscs8HM\nbjCzh8LSxb+bWXPk9XMix/ab2UciH9lsZj8Jj/uFmc0s9i8sEqVkIJLZucBs4AIzOwL4CXCDu88A\nPgOsMbO3RfZfBFwOtACTw30ws2OAtcAtwNuB04GtkeM+BCwFpgP/BXy5iL+TyEGUDEQC95rZq+HP\nPZHtS919yN3fBD4M/Ku73w/g7v8B/Aq4OLL/He7+X+H+3yO46AP8GfCAu3/P3fe7+2vu/mjkuHvc\nfZO7HwDujhwnUhJqMxAJXBZtMzCzVoK2hB2RfVqBD5rZe+O7Efwf+o/IPi9HHr8BNIaPjya4408n\n3XEiJaFkIBKwNNuj0/q+ANzl7h8fw/u/AJw5huNESkLVRCLpJSeIfwHea2bvMbMJZtZgZueFbQmj\nuRt4t5n9iZlNNLNmMzut8CGLjI2SgUji3X/a7e6+A7gMuB4YBPoJGognpNo/6dgXCNoWPgO8CmwB\n5uQVtUgBmRa3ERERlQxERETJQERElAxERAQlAxERoUrHGZiZWr1FRMbA3VOOqanakoG7l+2nt7eX\nadPmEvQkDH6amtq5//77icWagUfC7Y8QizUzMDCAu7N06VLcnYGBgYz7VdpPPO5q+1HcirsWY84n\n7kyqNhmUU1tbG3v39gHxqWUeZd++ftrb21mx4jZisXk0Nc0lFpvHihW30dLSknB8S0tLVvuJiJRK\nVVYTlVv8Yt7VNY+6ulb27esfvpgvWrSQ+fPPp6+vj7a2trQX+Gz3ExEpBSWDMcp0MW9paUl5ce/s\n7Ex4nm6/SpMcd7VQ3KVVjXFXY8xQnLircgSymXk1xi0iUk5mhtdaA7KIiBSOkoGIiCgZFMLg4CAb\nN25kcHCw3KGIiIyJkkGeurtX09o6mwULrqK1dTbd3atT7pdNwlBSEZFyUTLIw+DgIF1dixka2sCu\nXZsYGtpAV9figy7m2SSMbJOKiEgxqDdRHjZu3MiCBVexa9em4W1NTXNZv345HR0dQJAwWltnMzS0\ngWAtk0eJxebR3799uFtpNvuIiORLvYmKJN1I5La2tuF9+vr6qK9vY2RRqznU1bXS19eX0z4iIsWk\nZJCHbKaVyCZhZLOPiEgxqZqoAAYHBzNOK9HdvZqursUJU1csWrQw531ERPKRqZpIyaBE4gmjsbGR\n3bt3p0wcoyUVEZF8qM2gArS0tPDMM89yxhnnpO0x1NLSQkdHhxKBiJScSgYloh5DIlJuKhkU0FgH\nhqnHkIhUMiWDHIw2MCxTolCPIRGpZEoGWRpttPFoiUKrm4lIJStqm4GZrQD+CNjp7nOSXvsM8PfA\n29391XDb14GLgD3AR919a5r3LXmbQabRxm1tbVm3B6jHkIiUSznbDO4ALkgR0FHAfKA/su0iYJa7\nHw98HLi9yLHlJFM1Ty7tAeoxJCKVqKjJwN0fAl5L8dLNwGeTtl0G3BUe90tgmpkdVsz4cpGpmkft\nASJS7Uq+BrKZvRd4wd0fM0sorRwJvBB5/mK4bWcJw8so3brH8UTR1TUvYQSx7v5FpFqUNBmYWQz4\nArAg1csptqVtGFi2bNnw487OzpItbJ1uEft0iUJEpFx6enro6enJat+iDzozs1bgx+4+x8xOAdYD\nbxBc/I8iKAGcCdwAbHD31eFx24Hz3P2gkkE1DjoTESm3cg86s/AHd3/c3Q9392PdfSawA2h39wHg\nPuAjYcBnAb9NlQhERKTwipoMzGwl8HPgBDN73syuSNrFGUkUa4HnzOwZYDmwuJixlUqhlrLUkpgi\nUkyam6iI4tNS19cHvY3GOi11od5HRMY3TWFdBoWamE4T3IlIoZS7zWBcymUgWqYqIE1wJyKloGRQ\nJNkORBttTiMNaBORUlAyKJJsJqYbbfK7bN9HRCRfajMoskwT02Wa/K6joyPr9xERyYYakCuUGodF\npJQyJYOSz01UbbJZyH6s8p3TSKUFESkUlQwyiPfvh+kMDf2GWOw44MWC9/Mfy0VdYw9EJFeqJhqD\nkSqcNcAHgPJU5aRKFKpeEpGx0DiDHA0ODrJ27VomTWoFpgBtlKOff7pupxp7ICKFppJBknj1y6RJ\nR/L6688AaylHySDT3T+gkoGI5EwlgyxF+/2//vqjwDLgYiZPbgLOIhY7tWT9/DPd/WvsgYgUmkoG\nEan6/Tc2nso3vvEZzjzzzIL3Jsokm3YB9SYSkVyoa2mWEqd+CC7A+/e/xMUXX1zyi2023U7Trbom\nIpIrlQySxNsMohfgcnbZ1N2/iBSKupbmSBdgEalFSgYiIqLeRCIikpmSgYiIFDcZmNkKM9tpZo9G\ntv29mT1hZlvNbI2ZNUVeu87Mng5ff08xYxMRkRHFLhncAVyQtG0d8HvufjrwNHAdgJmdDHwQOAm4\nCLjNzFLWbYmISGEVNRm4+0PAa0nb1rv7gfDpw8BR4eNLgVXu/pa79xEkijOLGZ+IiATK3WZwJcHk\nPwBHAi9EXnsx3CYiIkVWthHIZvYFYJ+7d8c3pdgtbf/RZcuWDT/u7Oyks7OzkOGJiFS9np4eenp6\nstq36OMMzKwV+LG7z4lsuxz4S+B8d38z3LYEcHe/KXz+78BSd/9livfUOAMRkRyVe5yBEbnrN7ML\ngc8Bl8YTQeg+4ENmVm9mM4HjgN4SxDdscHCQjRs3Mjg4WMqPFREpu2J3LV0J/Bw4wcyeN7MrgFuB\nRuABM9tsZrcBuPs24HvANoJ2hMWlvP1Pt5CMiMh4oOkoqK5lJDVvkoiMVbmriSpetSwjqdKLiBSL\nSgZUR8mgGmIUkcqmksEoqmEZyWopvYhIdVLJIKKS6+NVMhCRfGnZyyxV8jKS2SyDKSIyVioZVJlK\nLr2ISGXTSmciIqIGZBERyUzJoIZoOg0RGSslgxqhAWkikg+1GdQAdTsVkWyozaAK5VLlowFpIpIv\nJYMKlGuVT1tbG3v39gGPhlseZd++ftra2oocqYjUCiWDCjM4OEhX12KGhjawa9cmhoY20NW1eNQS\nwvXXf7qip9MQkcqmZFBhcq3yiZcivvrVNbgf4LOf/RP6+7ezaNHCEkUsIrVADcgVJpfGYDUci0gu\n1IBcRXKZQVUNxyJSKCoZVKhs5iBSyUBEcqFZS6tQNjOoaiZTESmUopYMzGwF8EfATnefE26bAawG\nWoE+4IPuvit87evARcAe4KPuvjXN+9Z8ySAXmslURLJRzjaDO4ALkrYtAda7+4nAg8B1AGZ2ETDL\n3Y8HPg7cXuTYakZLSwsdHR1KBCIyZkVNBu7+EPBa0ubLgDvDx3eGz+Pb7wqP+yUwzcwOK2Z8IiIS\nKEdvokPdfSeAu78MHBpuPxJ4IbLfi+E2GQPNYCoiuaikrqWp6rHUMDAGmsFURHJVjt5EO83sMHff\naWaHAwPh9h3A0ZH9jgJeSvcmy5YtG37c2dlJZ2dn4SOtQtHpLIaGgu6mXV3zmD//fLUpiIwzPT09\n9PT0ZLVv0ccZmFkb8GN3PzV8fhPwqrvfZGZLgOnuvsTMLgaudvdLzOws4B/c/aw076neRGls3LiR\nBQuuYteuTcPbmprmsn79cjo6OsoYmYiUW9l6E5nZSuDnwAlm9ryZXQHcCCwwsyeBd4fPcfe1wHNm\n9gywHFhczNhq1WgzmKotQURS0QjkGtTdvZqursUJA9EWLVo4vL2+PkgY8e0iMj5kKhkoGdSo5IFo\nmrpCRPKejsLMTnH3xwsblhRT8nQW8UntgkZliE5qp2QgItm2GdxuZr1mttjMphc1IikKrYYmIplk\nlQzc/Rzgzwm6fv7KzFaa2YKiRiYFlcvU2CIy/uTUZmBmE4H3AV8H/odgoNj17n5PccJLG4faDMZI\nk9qJjF95NyCb2RzgCuAS4AFghbtvNrMjgF+4e2shA84inoImA10gRWQ8KMQ4g28Am4HT3P1qd98M\n4O4vAX9TmDDLQ1M3iIhkXzJoBIbcfX/4fALQ4O5vFDm+dPEUpGSg7pYiMp4UomSwHohFnh8Sbqtq\nWkNYRCSQbTJocPfd8Sfh40OKE1LpjIfulpp+QkSykW0y2GNmc+NPzOwMYKg4IZVOrXe3VHuIiGQr\n2zaDDmAVI1NKvwNY6O6b0h9VPOpNNDq1h4hIsryno3D3jWY2GziRYGzBdnffV8AYyyp56oZaoOkn\nRCQXuSxu0wG0hce0hxnmrqJEJXlLbA8JSga11h4iIoWT7UR13wVmAVuB/eFmJ1zAXipPvD2kq2te\nwlTWKhWISCrZthk8AZxcKXNAaDqK7MXbQxobG9m9e3dNtYuISG4KMc7gceDwwoUkpdLS0sIzzzzL\nGWeco15FIpJWtiWDDcDpQC/wZny7u19avNAyxqOSQZbUq0hE4vLuTQQsK1w4Ukq59CqKdrGNH6tq\nJZHxIdv1DH4K9AF14eONBBPXjZmZXWNmj5vZo2Z2t5nVm1mbmT1sZk+aWbeZ5dLbSVLIdpR1dIDa\nkUfO4qijjle1ksg4km010ceAvwSa3X2WmR0P3O7u7x7ThwZTXz8EzHb3vWa2GlgLXAz8wN2/b2bf\nBLa6+/IUx6uaKAfd3avp6lqc0Kto0aKFw68nViW9g2A4SQ+qVhKpLYVoQL4aOJtgQRvc/Wng0Dzj\nmghMCe/+YwSjm+cBa8LX7wT+OM/PEGDRooX0929n/frl9PdvT0gEkDxhXx8wE03eJzK+ZFsN82Z4\nBw9AeAEf8625u79kZl8DngfeANYRVDv91t0PhLvtAI4Y62dIokyjrBOrktqA59BgNZHxJduSwU/N\n7HogFq59/H3gx2P9UDObDlwGtBJc8KcAF6XYVXVBJZA4Yd8F1NXto77+3JqcvE9EUsu2ZLAE6AIe\nAz5OUL//nTw+dz7wrLu/CmBmPwTeBUw3swlh6eAoRibGO8iyZcuGH3d2dtLZ2ZlHOONTtPfQokUL\nmT//fPUmEqkhPT099PT0ZLVvVg3IhWZmZwIrCOY7ehO4g6CH0rnAPe6+OmxAfsTdb09xvBqQ8xRv\nVK6vD6qIkhuVRaT2ZGpAzrY30XOkqLJx92PzCGop8CFgH7AF+F8EpYFVwIxw24dTzY6qZJAfDUQT\nGZ8KMejs9yOPG4A/BZrzCcrdvwh8MWnzc8Af5PO+MjpNby0iybIddPbfkZ8X3f0fgEuKHJsUyXhY\n7lNEcpPtFNZzI08nEJQUNDq4Sml6axFJlstEdXFvEYxM+qq7P1mkuEaLR20GBVCLy32KSHp5NyBX\nGiUDEZHc5d2AbGbXZnrd3f/fWAITEZHKkEtvog7gvvD5ewnWNni6GEGJiEhpZdtm8DPgEnd/PXw+\nFfhXdz+3yPGli0fVRCIiOSrErKWHAXsjz/eG20REpAZkW010F9AbziHkBFNL31m0qEREpKSy7k0U\njjX4w/Dpz9x9S9GiGj0WVROJiOSoENVEAIcA/+PutwA7zGxmQaKTqjM4OMjGjRsZHBwsdygiUiBZ\nJYNwUrnPA9eFm+qAfylWUMWkC1l+omsla31kkdqRbW+irUA7sNnd28Ntj7r7nMxHFsdYq4k0bXN+\nNNupSHUrRDXR3vDq6+EbTilUcKUyODhIV9dihoY2sGvXJoaGNtDVtVglBLIvLSWulQxaH1mkdmSb\nDL5nZssJViL7GLAe+Hbxwio8XchSy7baZ3BwkNdee02znYrUqFx6Ey0A3gMYcL+7P1DMwEaJJedq\nIlVxHCzbcxKtXnvjjacwm0hDw7HDs52qqk2kOuQ1N5GZTQTWu/s8oGwJIF+atvlg2SxyE61eC/Z7\nlIaG8/j+92+kvb19XJ8/kVoyajJw9/1mdsDMprn7rlIEVSzJi76P9wtZ4iI3wYU+udonVcKor5/J\njBkzxv35E6kl2Y5A3g08ZmYPAHviG939k0WJqohaWloS7nrHc2LIprSUTcIQkeqXbdfSy1Ntd/ey\nTElRiBHI6mY6YrSkGD9X0YQxXs+VSDUb8+I2ZnaMuz9fpKCmAd8BTgEOAFcCTwGrgVaC1dQ+mKpq\naqwNyPELHqDG5ByN91KUSC3IZ5zBvZE3WVPQqOAWYK27nwScBmwHlhA0Vp8IPMjIiOe8JHefXL78\n2+pmmqOWlhY6OjqUCERq1Gglgy2REcfDj/P+0GA9hK3uPitp+3bgPHffaWaHAz3uPjvF8VmXDFJ1\nn2xoOA+zCSoZFIhKDSLVIZ+Sgad5nK9jgVfM7A4z22xm3zKzQ4DD3H0ngLu/DOR9ZUk12Ky+fibX\nX/9pYrF5NDXNJRabN+67mY6V5ioSqQ2jlQz2E/QeMiAGvBF/CXB3bxrTh5qdATwMvNPdf2VmNwOv\nA59w9+bIfv/t7m9LcbwvXbp0+HlnZyednZ0pPyvTwCpAd7SjyHTXr4F8IpWtp6eHnp6e4edf/OIX\n05YMcPeS/xCskvZs5Pk5wE+AJwhKBwCHA0+kOd5zsXLlKo/Fmr2pqd1jsWZfuXJVTsePV/HzNm3a\n3JTnrbe316dNm+vgwz9NTe3e29tbpohFJJPw2pnyupz1dBSFZmY/BT7m7k+FU2QfEr70qrvfZGaf\nB2a4+5IUx3qucateOzfZ3PWrZCBSXfKajqKIPgncbWZ1wLPAFcBEgknxrgSeB/60UB8WHWwmo8tm\nqgpN8SFSO8pWMsiHlr0svlzu+lXqEqkOlVoykAqWy12/Sl0i1U8lA8lId/0itWPM01FUKiUDEZHc\nFWLZSxERqWFKBiIiomQgYzc4OMjGjRsZHBwsdygikiclAxkTzUkkUlvUgCw508hjkeqkBmQpqFQz\nwWo9CJHqpmQgOUtcFxm0LrJI9VMykJzFRydrPQiR2qE2AxkzjU4WqS4agSwiIpqoTkojWlIArSIn\nUk2UDKQgurtX09W1mPr6Nt5442nMJhCLzWLv3j5WrLiNRYsWljtEEclA1USSt8RxB+8ATgR60BgE\nkcqicQZSVInjDvqAmWgMgkh1UTKQvCWOO2gDnkNjEESqi5KB5C1x3MEF1NXto77+XI1BEKkiZW0z\nMLMJwK+AHe5+qZm1AauAGcBm4C/c/a0Ux6nNoAKNtTeRxiuIlEbFjjMws2uAM4CmMBmsBn7g7t83\ns28CW919eYrjlAxqRLQXknoeiRRXRSYDMzsKuAP4MnBtmAwGgcPc/YCZnQUsc/cLUxyrZFADNPup\nSGlVam+im4HPAg5gZm8DXnP3A+HrO4AjyhSbFFiqhXA0+6lI5SjLoDMzuwTY6e5bzawzvjn8iUp7\n+79s2bLhx52dnXR2dqbbVcosXVVQY2Mjv/vdswQ9j4KSgXoeiRROT08PPT09We1blmoiM/sK8GHg\nLSAGTAXuBd4DHB6pJlrq7helOF7VRFUiXVXQzTffyDXXLAGmMTT0MrHYLOAltRmIFFFFthkMB2B2\nHvDpSAPyPe6+OmxAfsTdb09xjJJBlVi3bh3vf//n2LNn6/C2xsZT2bdvB2+++VOCBNHD5MmXsWXL\nw5x00klli1Wk1lVqm0EqS4BrzewpoBlYUeZ4JA/d3au57LKF7NnzNNFBaHv39jFx4jGMtBV0Mnny\nLHbv3l2eQEWk/CWDsVDJoPIlVg89AfwV0Exd3QAA+/btB36BehGJlI6msJaSi/cUGhqaQ3DBP59D\nDjmL/fsnhtVDTwCdQDOx2GsapSxSZpVWTSQ14uB1kn/D/v2vUF8fn8RuIfAkU6ZM5N57u1m0aGHK\n7qeZ5Lq/iKRX88lAF4zySLVO8i23fJW33uonmiAOHHiF9vZ2urtX09o6mwULrqK1dTbLl387498t\nef/u7tUl+91EapK7V91PEPboVq5c5bFYs0+bNtdjsWZfuXJVVsdJ4QwMDHhvb68PDAy4+8jfpKmp\nffhvMjAw4LFYs8MjDu5wk0PMp05tT/l3O3j/RzwWax7+DBFJLbx2pryu1mwDsqY6qFzJE9Nt3LiR\nBQuuYteuTcAgMBtI/3dL3D/Q1DSX9euX09HRUYbfSKQ6VFPX0oLRVAeVq6WlhY6OjuGLe2L7Qh9w\nNJn+bge3R2jkski+ajYZ6IJRPaLtC42NVwJPkenvlqo9Qr2RRPJTs9VEMDInTl1dK/v29WuqgwoX\nrz7avHkr11yzZNS/m9ZBEMlNRU9HMRa5DDrTBaM66e8mUnjjOhmIiEhgXDYgi4hI9pQMREREyUBE\nRJQMREQEJQMREUHJQCqcJhoUKQ0lA6lY+cxMqiQikhuNM5CKlM9Eg/GR5/X1wZQkGnkuEtA4A6k6\nmSYazHTXPzg4SFfXYoaGNrBr1yaGhjbQ1bVYJQSRUZQlGZjZUWb2oJltM7PHzOyT4fYZZrbOzJ40\ns/vNbFo54pPySzfR4ObNWw+qOoomB81WKzI25SoZvAVc6+4nA+8Erjaz2cASYL27nwg8CFxXpvik\nzFLNTHrzzTdyzTVLEu76L7/8YwnJYfPmrZqtVmQMKqLNwMzuBb4R/pzn7jvN7HCgx91np9hfbQbj\nRHTCur6+vqRFbQaBNuAXRNsV4klDs9WKJMrUZjCp1MEkM7M24HTgYeAwd98J4O4vm9mYpqvUjJe1\no6WlJeFvOHLXPwd4ADiC5CqhuXNPp79/u74DIjkoawOymTUCPwA+5e67gbxv97VQem2KJ/ibb75x\nuOqooeFq6usHSVUllLyamohkVraSgZlNIkgE33X3H4Wbd5rZYZFqooF0xy9btmz4cWdnJ52dnQk9\nSYaGgmqDrq55zJ9/vi4KVSy5q+jNN9/I3Lmn09bWxvr1D9LVNS+hSkh/a5FAT08PPT09We1btjYD\nM7sLeMXdr41suwl41d1vMrPPAzPcfUmKY1O2Gaxbt473v/9z7NmzdXibFkqvbtmMN8hULagqQ5ER\nFTfOwMzOBv4cON/MtpjZZjO7ELgJWGBmTwLzgRuzfc/u7tVcdtlC9ux5GvUkqR3ZdBVNVyWkKkOR\n7FVEb6JcJZcMEu8enwD+CmgmFntNPUmq3FhHIuczglmkVlVcyaDQEu8eFwJPMmXKRO69t1uJoMql\nGm+QTbuABp+J5KYGSwa6C6xFudb951OiUBuD1KqaLxmM9e5RqkeuXUUzfSfSzW2Uqo1Bs5/KeFET\nJYM43dVJsuTvRLoZTVOVJOrqzmHSpDrNfio1I1PJoKaSgYxvo90MZKo6ynaqC1U9SjWr+WoiFeVl\ntG6kg4ODrF27lkmTWknVqHzwLKlrSDXVxWgN0PouStVy96r7CcIOrFy5ymOxZp82ba7HYs2+cuUq\nl/FlYGDAY7Fmh0cc3OERj8WafWBgwN1HviNTp57qEBt1v4aGmQ4NDoek3TcVfRel0oXXztTX1XQv\nVPJPPBmMdhGQ8aG3t9enTZsbfgeCn6amdu/t7U3xHbnJIeZTp54+fMEeGBgY3nfbtm0+efL0cP9V\nDjMcZo16cdd3UapBpmRQ1dVE6ksukH4hnPi014nfkc/R2DiLW2/93/T3bwdIqF5as+aHNDQcS65j\nVvRdlGpX1ckg00VAxo9M3UhTfUf273+Jiy++mFdeeYUrrrgqYbGcL3/5/ybt/xsOHHiF9vb2jDHo\nuyhVL12RoZJ/SNFm0NTUrnracS5a3ROV6juycuUqnzy5yeGEg6qXvvSlL4/pO6XvolQ6MlQT1UTX\nUo0vkNFEvyNA2MV0DfAB4OCupsCYZkJNfk3fTakkmbqWlv0ufyw/REoGIrlKbHBe5dDscLxPnjx9\n1Lv5aI+hhobp/qUvfTltI/FovYvSlWRGM9bjRKjV3kQiY3Fwz58NPnlyk2/bti2H4+I9jY5Le6HP\nprtrrt1Q1X1V8qFkIJIk1/r9gYEB/+d//mefOrXdYSAsTaRPJrl1dz24G2qqu391X5V8ZUoGVdub\nSCM9JR+LFi2kv38769cvp79/e8Zuo/HRzX/911/j9de3Aw8QTFUxB1gNfIA33zyc9vZ3DY98bmxs\n5He/e5bsursmdkNNN5r64OPewYQJb2fLli0FOisyrqXLEpX8A6ioLCWRetBafHTyhqQSQnCnfvvt\n3/JYrNljsZkOMY/FTkn4nma6w8/+tczVVCKpUIvVRCoqSymkqu5pbDzFr7rqr1J2TW1sPCUygjl1\nFZJ7+mqqgz9vwKdMOcHvv//+4eMaGqannSojXr20bds2NTLLQTIlg6qtJtJITymFdIPWbrjhi2zZ\n8jCTJw+QWBX0PPX1Mxn5fnYyefIsdu/enfC+0WqqTZse4rjjjmVwcDCpemk1cCJ79hzgfe9bxPLl\n3+a4447lzjuXM2XK8ST/H1i+/Nu0ts7mvPM+xMknn8F553VxzDEn8Ld/+5Wcq1PHWg2r6tsqli5L\nlPMHuBDYDjwFfD7F6yoZSMlkamxOfi1eRZT8/YzeqUcbh6O9g+rqpnp9/bSweil5orz4nErt3tAw\n3evrpyWUPurrG72hYUZS1VViVdLtt38rodSQ/G88tvigu1y7xI7W7bZQpZZMXWuL2e222ktdAwMD\n1VVNRDBFxjNAK1AHbAVmJ+1TlSM9N2zYUO4QxkRx53YBSk4Qn/jEpw664McvmCMX9YHwwv1IeEH/\npsNxw1VFyW0TdXWNkRlWYz558qxw/16HuSmOuSncL9i/ru6YhH9jsVO9rm6q19VNTVsFFf3dkhPF\nwMCA19dPTdueET8uFjt2+PPG8n83U9fasXS7zfY7Uqj4CyXX73Y8/mpLBmcB/xZ5viS5dABU5cCb\npUuXljtyimFMAAAKIElEQVSEMVHcuYveRY6UFKIXfHe4O3LBj1/E3WFpuG/8otzrcFpC20RTU7uv\nXr060j4Rf+94yeDuyPvFE8OGNP9Gj48eN/JZo3WJ7e3t9cmTD0+ZuBoapofHbTjotVxK9WNteM8k\nm+/IyHvnF38h5fLdTjw36ZNBJbYZHAm8EHm+I9yWINc1cUVKKf793L17d6Q7aB8QbU9YALxE0D7Q\nBjxHdIK8uroJxGLzaGy8kqDGNLGb6vTp0yMzrLYA3wQuob6+EegiqGl9NPzco4Ep4eck/xuNbUH4\nOLcusW1tbezf/1sSu90G+0yceCgTJhyd9HmJx2cj0+cXc9bYkffOL/5yOfjcpDapJNHkJtW8GV7y\nKEQKILEBuo2RC/4c4hf8SZPmUVfXytDQPszOBWJMnHgrK1Z8h/nzz6evr4/Nm7dyzTXBfvv29bNi\nxW20t7dH3nsOcBINDfX86Eff5uijj2bNmh/yla/MY+LEI9i9+7+APQQX+uR/o7H9BrgN6ASaicVe\nG54BFkj6vJFE0dLSwqWXXsLatVfzu9/tTdhn//4BzCYkfV7i8bmfy4OPz/RaPkY+N7/4y+XgThCp\nVdxEdWZ2FrDM3S8Mny8hKNrcFNmnsoIWEakSnmaiukpMBhOBJ4F3E9ym9AKL3P2JsgYmIlLDKq6a\nyN33m9kngHUEPYtWKBGIiBRXxZUMRESk9CqxN1FGZnahmW03s6fM7PPljicdMzvKzB40s21m9piZ\nfTLcPsPM1pnZk2Z2v5lNK3esycxsgpltNrP7wudtZvZwGHO3mVVcidLMppnZ983sCTP7tZn9QZWc\n62vM7HEze9TM7jaz+ko832a2wsx2mtmjkW1pz6+Zfd3MnjazrWZ2enmiThv334ffk61mtsbMmiKv\nXRfG/YSZvac8UaeOO/LaZ8zsgJk1R7blfb6rKhlY0CXhG8AFwO8Bi8xsdnmjSust4Fp3Pxl4J3B1\nGOsSYL27nwg8CFxXxhjT+RSwLfL8JuBrYcy/Jei3WGluAda6+0nAaQT9Kiv6XJvZEcBfA3PdfQ5B\nte0iKvN830Hw/y4q5fk1s4uAWe5+PPBx4PZSBpokVdzrgN9z99OBpxmJ+2Tgg8BJwEXAbWaWelWw\n4ksVN2Z2FDAf6I9sK8j5rqpkAJwJPO3u/e6+D1gFXFbmmFJy95fdfWv4eDfwBHAUQbx3hrvdCbyv\nPBGmFn7ZLga+E9l8PrAmfHwn8MeljisTM5sK/KG73wHg7m+5+y4q/FyHJgJTwrv/GMHAg3lU2Pl2\n94eA15I2J5/fyyLb7wqP+yUwzcwOK0WcyVLF7e7r3f1A+PRhgv+XAJcCq8LvTx9BojizVLFGpTnf\nADcDn03aVpDzXW3JIKsBaZXGzNqA0wm+eIe5+04IEgbBaKFKEv+yOYCZvQ14LfKfZwdwRJliS+dY\n4BUzuyOs3vqWmR1ChZ9rd38J+BrwPPAisAvYDPy2ws933KFJ5/fQcHvy/9MXqdz/p1cCa8PHFR23\nmb0XeMHdH0t6qSBxV1syqLoBaWbWCPwA+FRYQqjYeM3sEmBnWKKJn2vj4PNeab/DJGAu8I/uPpdg\ndNASKi/OBGY2neCurpXggj+FoHoiWUX/HilUxf9TM/sCsM/du+ObUuxWEXGbWQz4ArA01csptuUc\nd7Ulgx3AMZHnRxEUqytSWPT/AfBdd/9RuHlnvAhnZocDA+WKL4WzgUvN7Fmgm6B66B8Iip3x70ol\nnvMdBHdMvwqfryFIDpV8riGo+33W3V919/3AD4F3AdMr/HzHpTu/Owjmv4iruN/BzC4nqA79s8jm\nSo57FsEw8UfM7DmC2Dab2aEUKO5qSwYbgePMrNXM6oEPAfeVOaZM/gnY5u63RLbdB3w0fHw58KPk\ng8rF3a9392Pc/ViCc/ugu38Y2AD8abhbRcUMEFZVvGBmJ4Sb3g38mgo+16HngbPMrCFsqIzHXann\nO7mUGD2/H2UkzvuAj8DwjAK/jVcnlUlC3GZ2IfA54FJ3fzOy333Ah8IeXTOB4wgGvZbLcNzu/ri7\nH+7ux7r7TIIE0O7uAxTqfKebwa5SfwjWOniSoHFnSbnjyRDn2cB+gim4txDUBV8INAPrw9/hAWB6\nuWNNE/95wH3h45nALwlmS1sN1JU7vhTxnkZws7AVuAeYVg3nmqDY/wTBxDF3EkzbXnHnG1hJcLf5\nJkESuwKYke78EvT6ewZ4hKC3VCXF/TRBb5zN4c9tkf2vC+N+AnhPJcWd9PqzQHMhz7cGnYmISNVV\nE4mISBEoGYiIiJKBiIgoGYiICEoGIiKCkoGIiKBkIFXEzL4QTvf8SDgHUUe5Y8pHOJfS+4vwvtdF\nHreaWfJcNiIHUTKQqhCOrLwYON3dTyOYyuGFzEeNW9cnPddgIhmVkoFUi3cAr7j7WwAezOfzMoCZ\nzTWzHjPbaGb/Fpkv54xwsY8t4YImj4XbLzezW+NvbGY/NrNzw8cLzOznZvYrM1sdzn6KmT1nZsvM\nbFNYMjkh3D7FzP7JgsVptprZH2d6n3Qy/A4bzOxGM/ulBYs6nR1uj4Xv+7iZ3WPBYjhzzezvgFhY\ncvpu+PaTwplcHzezfzezyQX6m0gNUTKQarEOOCa8IP5j5OI9CbgV+IC7dxAsCvKV8Jh/Aj7h7u3h\n8+gd8kF3y+F03X8DvNvdfx/YBFwb2WXA3c8gWDzkM+G2/0MwF8wcDxZLeTDN+3w63S82yu8AMNHd\n/wC4BlgWblsMvOrup4QxzAVw9+uAN9x9rrv/Rbjv8cCt4b67gA+ki0XGr7IvpyeSDXffY2ZzgT8k\nmE11lZktIbjQngI8EE72NgF4yYKlDKd5sEgIwHcJ5obK5CzgZOA/w/eqA34eef2H4b+bGFlwZj6w\nMBLnrnAq8OT3+UWGzz0x1e8Qef2eyOe2ho/PIZhRFnf/taVYHjHiWR+ZA38TweyXIgmUDKRqeDCR\n1s+An4VVPh8hmGjscXc/O7qvBevxpqsrf4vEUnFD/DBgnbv/eZrj4jNc7mfk/46l+JzR3ieZkeJ3\nyOJzk98j1ePo8fH3aEAkiaqJpCqY2Qlmdlxk0+kEM08+CbSEDcyY2SQzO9mDZS93mdm7wv2jF+Y+\n4HQLHM3I0oYPA2eb2azwvWJmdvwooa0jWMc4Huf0MbxPyt9hlM99iLBEEu57auS1vWY2MfK8XOv4\nShVRMpBq0QjcGTaCbiVYtHyZB2th/wlwU7h9C/DO8JgrCRY13xx9I3f/T4KE8GuCqpZN4fZXCObl\n7zazRwiqdk6MH5Ymrr8FZpjZY2a2Begc5X0SQgk/N9PvkO5zbwPebmaPAzcAjxO0BwB8C3gs0oCs\n3kQyKk1hLeOCmbUCP3H3U0fduQpYsBJanbu/aWbHEqwrcEK8t5VIrtRmIONJLd35HAJsMLO68PlV\nSgSSD5UMREREbQYiIqJkICIiKBmIiAhKBiIigpKBiIigZCAiIsD/Bzdq4MNeoxqwAAAAAElFTkSu\nQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x18ba5ce10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English vocab size restricts to 7.34915852135 percent of total vocab.\n",
      "French vocab size restricts to 6.17093489664 percent of total vocab.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def unknown_word_replacer(tokenized_text, vocab_size, lang='English'):\n",
    "    ''' CURRENTLY UNUSED: This is the same as replace_with_word_id below \n",
    "    but without replacing tokens with ids.\n",
    "    We take the list of lists, find FreqDist, replace any\n",
    "    out of vocabulary words with <UNK>, return new list of lists'''\n",
    "    flat = [item for sublist in tokenized_text for item in sublist]\n",
    "    freq = nltk.FreqDist(flat)\n",
    "    print \"{} vocab size restricts to {} percent of total vocab.\".format(lang, 100*(float(vocab_size)/len(set(flat))))\n",
    "    vocab = dict(freq.most_common(vocab_size))\n",
    "    text = []\n",
    "    for sentence in tokenized_text:\n",
    "        new_sent = []\n",
    "        for token in sentence:\n",
    "            if token not in vocab.keys():\n",
    "                new_sent.append(u'<UNK>')\n",
    "            else:\n",
    "                new_sent.append(token)\n",
    "        text.append(new_sent)\n",
    "    return text, vocab\n",
    "\n",
    "def seq_length_stats(tokenized_text, lang='English'):\n",
    "    seq_data = dict()\n",
    "    for sublist in tokenized_text:\n",
    "        # Need to keep track of the longest sequence length to pad shorter ones with <EOS>\n",
    "        if len(sublist) not in seq_data.keys():\n",
    "            seq_data[len(sublist)] = 1\n",
    "        else:\n",
    "            seq_data[len(sublist)] += 1\n",
    "    \n",
    "    plt.scatter(seq_data.keys(), seq_data.values())\n",
    "    plt.ylim(0, max(seq_data.values()))\n",
    "    plt.xlim(0, max(seq_data.keys()))\n",
    "    plt.xlabel(\"Sequence length\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.title(lang)\n",
    "    plt.show()\n",
    "    \n",
    "    return seq_data, max(seq_data.values())\n",
    "\n",
    "def replace_with_word_id(tokenized_text, vocab_size, longest_sequence=1, lang='English'):\n",
    "    '''\n",
    "    take the list of lists, find FreqDist, replace any\n",
    "    out of vocabulary words with <UNK> whilst giving each\n",
    "    token a numerical ID, return new list of lists'''\n",
    "    flat = []\n",
    "    max_len = 0\n",
    "    for sublist in tokenized_text:\n",
    "        # Need to keep track of the longest sequence length to pad shorter ones with <EOS>\n",
    "        if len(sublist)>max_len:\n",
    "            max_len = len(sublist)\n",
    "        for item in sublist:\n",
    "            flat.append(item)\n",
    "    freq = nltk.FreqDist(flat)\n",
    "    print \"{} vocab size restricts to {} percent of total vocab.\".format(lang, 100*(float(vocab_size)/len(set(flat))))\n",
    "    vocab = dict(freq.most_common(vocab_size+1))\n",
    "    del vocab['<EOS>']\n",
    "    # The identities begin at 2, since <EOS>=1 and <UNK>=2\n",
    "    word_to_ids = dict([(word, i+2) for i, word in enumerate(vocab.keys())])\n",
    "    text = []\n",
    "    for sequence in tokenized_text:\n",
    "        # Make sure sequence is no longer than the maximum allowed\n",
    "        ids_sent = []\n",
    "        for token in sequence:\n",
    "            if token not in vocab.keys():\n",
    "                if token == '<EOS>':\n",
    "                    ids_sent.append(1)\n",
    "                else:\n",
    "                    ids_sent.append(2)\n",
    "            else:\n",
    "                ids_sent.append(word_to_ids[token])\n",
    "        # Then pad the rest of the sequence with zeros until matches longest_sequence\n",
    "        text.append(ids_sent)\n",
    "\n",
    "    word_to_ids[u'<UNK>'] = 2\n",
    "    word_to_ids[u'<EOS>'] = 1\n",
    "    word_to_ids[u'<PAD>'] = 0\n",
    "    id_to_words = {}\n",
    "    for word, idx in word_to_ids.items():\n",
    "        id_to_words[idx] = word\n",
    "    return text, word_to_ids, id_to_words\n",
    "\n",
    "en_vocab_size = 1000\n",
    "fr_vocab_size = 1000\n",
    "\n",
    "seq_data_en, en_max = seq_length_stats(tokenized_en, lang='English')\n",
    "seq_data_fr, fr_max = seq_length_stats(tokenized_fr, lang='French')\n",
    "\n",
    "\"\"\" For now, sequences form rows of the matrix, with the number of columns \n",
    "    equal to the maximum length of sequence (or timesteps)\"\"\"\n",
    "text_en, vocab_en, id_to_word_en = replace_with_word_id(tokenized_en, \n",
    "                                                        en_vocab_size, longest_sequence=en_max, lang='English')\n",
    "text_fr, vocab_fr, id_to_word_fr = replace_with_word_id(tokenized_fr, \n",
    "                                                        fr_vocab_size, longest_sequence=fr_max,  lang='French')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpora still aligned: True\n",
      "[u'<PAD>', u'<EOS>', u'<UNK>', u'all', u'chinese', u'issued', u'global', u'focus', u'month', u'four', u'manager', u'higher', u'go', u'children', u'whose', u'paris', u'white', u'young', u'thursday', u'created', u'to', u'spanish', u'present', u'under', u'women', u'worth', u'started', u'town', u'supported', u'risk', u'outside', u'very', u'regional', u'wave', u'every', u'fall', u'nieto', u'entire', u'school', u'provide', u'level', u'did', u'cause', u'companies', u'wednesday', u'large', u'red', u'team', u'small', u'study', u'shows', u'petersburg', u'application', u'revolution', u'says', u'leaders', u'ten', u'request', u'elections', u'past', u'located', u'second', u'street', u'quebec', u'further', u'quite', u'even', u'afghanistan', u'what', u'defence', u'adds', u'business', u'lead', u'near', u'current', u'above', u'capital', u'international', u';', u'increasing', u'ever', u'public', u'told', u'body', u'impact', u'full', u'led', u'exchange', u'never', u'here', u'hours', u'reported', u'protection', u'china', u'groups', u'others', u'alone', u'november', u'strong', u'change', u'great', u'canadian', u'institute', u'involved', u'employees', u'30', u'completely', u'experience', u'products', u'social', u'action', u'military', u'changes', u'via', u'love', u'family', u'extra', u'win', u'explained', u'africa', u'private', u'hamas', u'brought', u'ask', u'muslim', u'total', u'crisis', u'market', u'cost', u'use', u'from', u'takes', u'working', u'army', u'remains', u'positive', u'hospital', u'voters', u'visit', u'two', u'next', u'few', u'live', u'music', u'therefore', u'taken', u'themselves', u'campaign', u'markets', u'until', u'today', u'more', u'israel', u'evening', u'club', u'company', u'site', u'glass', u'particular', u'known', u'cases', u'potential', u'must', u'me', u'states', u'account', u'word', u'room', u'rights', u'this', u'car', u'work', u'london', u'remain', u'itself', u'nine', u'can', u'mr', u'following', u'making', u'my', u'example', u'history', u'control', u'citizens', u'tap', u'council', u'figure', u'give', u'process', u'december', u'sense', u'share', u'accept', u'high', u'professor', u'woman', u'caused', u'something', u'want', u'allowed', u'keep', u'association', u'worse', u'information', u'needs', u'united', u'end', u'goal', u'january', u'rather', u'travel', u'get', u'makes', u'how', u'interview', u'instead', u'explains', u'economy', u'criminal', u'building', u'huge', u'may', u'after', u'southern', u'confirmed', u'water', u'president', u'law', u'data', u'man', u'a', u'physical', u'remember', u'third', u'light', u'perhaps', u'ones', u'so', u'things', u'banks', u'looking', u'dream', u'order', u'talk', u'six', u'mexican', u'help', u'office', u'developed', u'over', u'soon', u'years', u'course', u'reached', u'through', u'committee', u'committed', u'still', u'its', u'before', u'1', u'group', u'21', u'la', u'personal', u'interesting', u'll', u',', u'actually', u'better', u'previously', u'pena', u'policy', u'weeks', u'main', u'2011', u'2010', u'2012', u'then', u'them', u'good', u'return', u'greater', u'3', u'food', u'material', u'cover', u'nation', u'band', u'they', u'half', u'not', u'now', u'day', u'bank', u'term', u'document', u'stated', u'name', u'lies', u'always', u'university', u'didn', u'--', u'each', u'found', u'went', u'european', u'side', u'mean', u'development', u'everyone', u'financial', u'telescope', u'doing', u'house', u'energy', u'hard', u'reduce', u'idea', u'society', u'oil', u'expect', u'year', u'eu', u'our', u'friday', u'saturday', u'special', u'out', u'living', u'funding', u'network', u'space', u'quality', u'tried', u'since', u'research', u'increase', u're', u'health', u'americans', u'internet', u'got', u'issue', u'announced', u'common', u'model', u'earlier', u'cars', u'u.s.', u'million', u'given', u'free', u'20', u'reason', u'york', u'members', u'put', u'wanted', u'beginning', u'card', u'care', u'hagman', u'language', u'ministry', u'could', u'days', u'british', u'times', u'thing', u'american', u'place', u'think', u'south', u'first', u'major', u'already', u'valentino', u'feel', u'legislation', u'meet', u'coming', u'number', u'one', u'done', u'fast', u'another', u'such', u'vote', u'force', u'wages', u'open', u'city', u'little', u'management', u'service', u'needed', u'top', u'girls', u'system', u'least', u'anyone', u'their', u'2', u'too', u'statement', u'majority', u'hundred', u'final', u'interests', u'eyes', u'lot', u'that', u'moscow', u'took', u'part', u'boredom', u'sulphur', u'believe', u'than', u'population', u'10', u'kind', u'bored', u'15', u'14', u'culture', u'18', u'rate', u'nations', u'project', u'matter', u'patients', u'future', u'attention', u'were', u'playing', u'russia', u'result', u'and', u'mountain', u'fashion', u'remained', u'modern', u'marijuana', u'say', u'have', u'need', u'seen', u'presidential', u'saw', u'any', u'sell', u'forced', u'documents', u'responsible', u'-', u'snow', u'also', u'mr.', u'costs', u'take', u'which', u'new', u'registered', u'play', u'added', u'though', u'price', u'who', u'reach', u'paid', u'leave', u'most', u'germany', u'plan', u'significant', u'nothing', u'america', u'why', u'constitution', u'so-called', u'democratic', u'don', u'especially', u'considered', u'industry', u'clear', u'later', u'm', u'face', u'points', u'effect', u'voting', u'fact', u'laws', u'sector', u'particularly', u'show', u'german', u'able', u'spain', u'sites', u'bring', u'carry', u'earth', u'fine', u'find', u'staff', u'&quot', u'access', u'based', u'rocket', u'student', u'(', u'enough', u'should', u'authority', u'only', u'going', u'black', u'money', u'obama', u'local', u'scientists', u'hope', u'palliative', u'do', u'his', u'favour', u'goes', u'hiv', u'means', u'contracts', u'de', u'stop', u'television', u'quickly', u'famous', u'cannot', u'nearly', u'despite', u'report', u'during', u'trade', u'event', u'him', u'areas', u'prime', u'appeal', u'tobacco', u'countries', u'16', u'morning', u'bad', u'she', u'forces', u'including', u'act', u'movement', u'where', u'view', u'available', u'declared', u'set', u'art', u'questions', u'national', u'st.', u'manning', u'see', u'officials', u'are', u'sea', u'close', u'news', u'labour', u'best', u'subject', u'success', u'instance', u'practice', u'said', u'federal', u'away', u'currently', u'electoral', u'representatives', u'weapons', u'state', u'won', u'various', u'between', u'probably', u'conditions', u'across', u'bought', u'europe', u'we', u'men', u'terms', u'25', u'court', u'however', u'job', u'french', u'opposition', u'police', u'cities', u'come', u'both', u'protect', u'last', u'signed', u'avoid', u'career', u'country', u'region', u'museum', u'according', u'against', u'foreign', u'players', u's', u'became', u'planned', u'let', u'whole', u'asked', u'comes', u'insurance', u'among', u'key', u'cancer', u'point', u'simple', u'seems', u'tuesday', u'period', u'community', u'simply', u'article', u'respect', u'100', u'speak', u'debt', u'union', u'west', u'create', u'political', u'three', u'been', u'.', u'commission', u'much', u'interest', u'expected', u'meeting', u'board', u'wants', u'life', u'flight', u'league', u'influence', u'thousand', u'gas', u'search', u'else', u'lives', u'minister', u'child', u'prices', u'worked', u'an', u'former', u'those', u'case', u'east', u'look', u'virtual', u'these', u'might', u'budget', u'air', u'will', u'while', u'many', u'situation', u'taking', u'seven', u've', u'mexico', u'almost', u'is', u'thus', u'it', u'helped', u'player', u'someone', u'experts', u'drug', u'in', u'march', u'activity', u'technology', u'seem', u'if', u'different', u'century', u')', u'pay', u'make', u'administration', u'same', u'clearly', u'member', u'read', u'parts', u'largest', u'party', u'several', u'events', u'accused', u'difficult', u'week', u'used', u'singapore', u'whom', u'published', u'yesterday', u'hand', u'director', u'average', u'moment', u'walmart', u'prague', u'opinion', u'along', u'opportunity', u'euro', u'dark', u'off', u'i', u'try', u'&apos', u'well', u'suffering', u'thought', u'person', u'without', u'position', u'the', u'drivers', u'left', u'agency', u'just', u'less', u'being', u'percent', u'arab', u'actions', u'thanks', u'human', u'behind', u'followed', u'october', u'yet', u'previous', u'death', u'$', u'candidate', u'euros', u'workers', u'had', u'killed', u'reasons', u'book', u'parents', u'treatment', u'republic', u'has', u'gave', u'real', u'...', u'tests', u'photo', u'around', u'decided', u'government', u'rules', u'big', u'possible', u'early', u'department', u'game', u'five', u'know', u'birth', u'press', u'world', u'usually', u'projects', u'd', u'artists', u'necessary', u'like', u'lost', u'achieve', u'50', u'true', u'continue', u't', u'night', u'popular', u'become', u'security', u'works', u'reduced', u'towards', u'italian', u'because', u'old', u'often', u'people', u'czech', u'some', u'back', u'metres', u'economic', u'election', u'home', u'voted', u'5', u'transport', u'provided', u'recently', u'for', u'legal', u'decision', u'centre', u'/', u'everything', u'does', u'leader', u'either', u'be', u'measures', u'run', u'scientific', u'power', u'agreement', u'pressure', u'although', u'volcano', u'chairman', u'post', u'by', u'on', u'about', u'quarter', u'central', u'would', u'anything', u'getting', u'of', u'dollars', u'months', u'thousands', u'likely', u'addition', u'range', u'illegal', u'eight', u'efforts', u'or', u'road', u'own', u'civil', u'into', u'within', u'usa', u'due', u'down', u'services', u'right', u'parties', u'roads', u'france', u'your', u'per', u'story', u'her', u'area', u'support', u'there', u'question', u'long', u'fight', u'start', u'low', u'way', u'series', u'forward', u'call', u':', u'was', u'war', u'billion', u'head', u'himself', u'north', u'form', u'offer', u'brand', u'but', u'construction', u'competition', u'russian', u'line', u'trying', u'with', u'he', u'made', u'places', u'whether', u'official', u'politics', u'up', u'us', u'tell', u'planet', u'played', u'problem', u'similar', u'called', u'nature', u'sometimes', u'certain', u'received', u'am', u'direction', u'doesn', u'general', u'as', u'held', u'at', u'aids', u'senate', u'families', u'education', u'film', u'ice', u'again', u'compared', u'%', u'no', u'image', u'when', u'40', u'reality', u'field', u'politicians', u'other', u'role', u'details', u'test', u'you', u'really', u'2007', u'poor', u'media', u'star', u'users', u'monday', u'students', u'problems', u'important', u'recent', u'authorities', u'friends', u'died', u'began', u'ago', u'land', u'longer', u'using', u'established', u'age', u'required', u'together', u'summit', u'came', u'time', u'far', u'understand', u'2008', u'12', u'starting', u'having', u'once']\n"
     ]
    }
   ],
   "source": [
    "print \"Corpora still aligned:\", len(text_en) == len(text_fr)\n",
    "#print text_en[100:104]\n",
    "#print \n",
    "#print text_fr[100:104]\n",
    "print id_to_word_en.values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word IDs and word-to-vec vectors\n",
    "\n",
    "[THis is](https://sites.google.com/site/rmyeid/projects/polyglot#TOC-Download-the-Embeddings) where the embeddings are from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The embedding matrix for en has 1002 columns and 64 rows.\n",
      "27 vocab words were not in the en embeddings file.\n",
      "The embedding matrix for fr has 1002 columns and 64 rows.\n",
      "59 vocab words were not in the fr embeddings file.\n"
     ]
    }
   ],
   "source": [
    "#from gensim.models.keyedvectors import KeyedVectors\n",
    "#model = KeyedVectors.load_word2vec_format('DATA/GoogleNews-vectors-negative300.bin', binary=True)\n",
    "# Here we have loaded the pretrained Google Word2Vec representations of words\n",
    "\n",
    "import pickle\n",
    "def get_embeddings(id_to_word, lang='en'):\n",
    "    filename ='DATA/polyglot-'+lang+'.pkl'\n",
    "    pretrain_vocab, pretrain_embed = pickle.load(open(filename, 'rb'))\n",
    "    embed_vocab = [pretrain_embed[pretrain_vocab.index('<PAD>')], pretrain_embed[pretrain_vocab.index('</S>')]]\n",
    "    skip_count = 0\n",
    "    skipped_words = []\n",
    "    for idx, word in sorted(id_to_word.items()[2::]):\n",
    "        try:\n",
    "            pretrain_idx = pretrain_vocab.index(word)\n",
    "            embed_vocab.append(pretrain_embed[pretrain_idx])\n",
    "        except ValueError:\n",
    "            try:\n",
    "                # it could be that the word is a name which needs to \n",
    "                # be capitalized. Try this...\n",
    "                pretrain_idx = pretrain_vocab.index(str(word.title()))\n",
    "                embed_vocab.append(pretrain_embed[pretrain_idx])\n",
    "            except ValueError:\n",
    "                try:\n",
    "                    # it could be that the word is an achronym which needs to \n",
    "                    # be upper case. Try this...\n",
    "                    pretrain_idx = pretrain_vocab.index(word.upper())\n",
    "                    embed_vocab.append(pretrain_embed[pretrain_idx])\n",
    "                except ValueError:\n",
    "                    # Give up trying to find an embedding.\n",
    "                    # How many words are skipped? Which ones?\n",
    "                    skip_count +=1\n",
    "                    skipped_words.append(word)\n",
    "                    # Let's just initialise the embedding to a random normal distribution\n",
    "                    embed_vocab.append(np.random.normal(loc=0.0, scale=np.sqrt(2)/4, size=64))\n",
    "    embed_vocab = np.array(embed_vocab, dtype=np.float32)\n",
    "    print \"The embedding matrix for {} has {} columns and {} rows.\".format(lang, \n",
    "                                                embed_vocab.shape[0], embed_vocab.shape[1])\n",
    "    print \"{} vocab words were not in the {} embeddings file.\".format(skip_count, lang)\n",
    "    return embed_vocab, skipped_words\n",
    "# the ith word in words corresponds to the ith embedding \n",
    "\n",
    "embed_vocab_en, skipped_en = get_embeddings(id_to_word_en, lang='en')\n",
    "embed_vocab_fr, skipped_fr = get_embeddings(id_to_word_fr, lang='fr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note: to find a word given an index we use `id_to_word_en` and vice-versa we use `vocab_en`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1 2\n",
      "[u'30', u'1', u'21', u'2011', u'2010', u'2012', u'didn', u'--', u'20', u'2', u'10', u'15', u'14', u'18', u'so-called', u'&quot', u'16', u'25', u'100', u'&apos', u'50', u'5', u'doesn', u'40', u'2007', u'2008', u'12']\n"
     ]
    }
   ],
   "source": [
    "print vocab_en['<PAD>'], vocab_en['<EOS>'], vocab_en['<UNK>']\n",
    "print skipped_en"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** We can see above ** that the 127 English words which were not in the embedding files are fairly specialist words or numerical values (which are the same in French) so hopefully they won't be too much of a problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[697, 907, 2, 654, 423, 866, 614, 324, 959, 2, 2, 2, 268, 530, 2, 2, 268, 2, 268, 441, 2, 437, 865, 2, 20, 12, 859, 231, 115, 2, 1], [753, 361, 866, 231, 465, 2, 534, 231, 934, 838, 3, 2, 2, 268, 559, 2, 2, 945, 747, 1], [524, 654, 753, 376, 2, 227, 654, 89, 695, 481, 1], [687, 2, 544, 231, 2, 2, 703, 657, 703, 2, 746, 78, 625, 2, 2, 268, 753, 980, 703, 753, 394, 574, 2, 922, 2, 441, 753, 657, 703, 753, 2, 2, 782, 2, 169, 726, 1], [343, 129, 695, 2, 2, 859, 753, 2, 1], [859, 97, 2, 753, 2, 866, 2, 2, 2, 880, 182, 945, 753, 230, 471, 225, 753, 2, 866, 753, 2, 399, 845, 268, 511, 78, 2, 2, 268, 255, 753, 2, 866, 530, 2, 1], [612, 2, 306, 697, 725, 20, 2, 703, 753, 2, 78, 753, 796, 444, 788, 753, 2, 920, 475, 866, 753, 994, 1], [753, 2, 359, 231, 48, 2, 922, 231, 2, 2, 703, 231, 2, 2, 1], [511, 78, 697, 746, 78, 625, 807, 438, 703, 231, 289, 268, 511, 78, 54, 2, 1], [838, 582, 268, 753, 4, 790, 292, 520, 2, 753, 2, 20, 501, 2, 866, 753, 2, 2, 2, 268, 231, 109, 2, 78, 621, 20, 577, 2, 511, 78, 2, 2, 268, 511, 78, 697, 460, 2, 753, 483, 2, 2, 594, 753, 139, 553, 511, 78, 591, 2, 1]]\n"
     ]
    }
   ],
   "source": [
    "print text_en[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see a couple of things:\n",
    "- The list of lists above does not have consistent lengths of rows (it's not a matrix)\n",
    "- In order to process large amounts of data we need to break data up into batches of sequences\n",
    "\n",
    "The format that I need for the seq-to-seq model is a matrix - we do this by padding shorter sequences in a batch with the `<PAD>` token (represented already as the 0th column of the embedding matrix). the of dimension `(max sequence length in batch, batch size)`, so sequences are represented as the columns of the input matrix. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 573,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5 2 4 1]\n",
      " [2 0 2 2]\n",
      " [3 0 0 0]]\n",
      "[[697 753 524 687 343 859 612]\n",
      " [907 361 654   2 129  97   2]\n",
      " [  2 866 753 544 695   2 306]\n",
      " [654 231 376 231   2 753 697]\n",
      " [423 465   2   2   2   2 725]\n",
      " [866   2 227   2 859 866  20]\n",
      " [614 534 654 703 753   2   2]\n",
      " [324 231  89 657   2   2 703]\n",
      " [959 934 695 703   1   2 753]\n",
      " [  2 838 481   2   0 880   2]\n",
      " [  2   3   1 746   0 182  78]\n",
      " [  2   2   0  78   0 945 753]\n",
      " [268   2   0 625   0 753 796]\n",
      " [530 268   0   2   0 230 444]\n",
      " [  2 559   0   2   0 471 788]\n",
      " [  2   2   0 268   0 225 753]\n",
      " [268   2   0 753   0 753   2]\n",
      " [  2 945   0 980   0   2 920]\n",
      " [268 747   0 703   0 866 475]\n",
      " [441   1   0 753   0 753 866]\n",
      " [  2   0   0 394   0   2 753]\n",
      " [437   0   0 574   0 399 994]\n",
      " [865   0   0   2   0 845   1]\n",
      " [  2   0   0 922   0 268   0]\n",
      " [ 20   0   0   2   0 511   0]\n",
      " [ 12   0   0 441   0  78   0]\n",
      " [859   0   0 753   0   2   0]\n",
      " [231   0   0 657   0   2   0]\n",
      " [115   0   0 703   0 268   0]\n",
      " [  2   0   0 753   0 255   0]\n",
      " [  1   0   0   2   0 753   0]\n",
      " [  0   0   0   2   0   2   0]\n",
      " [  0   0   0 782   0 866   0]\n",
      " [  0   0   0   2   0 530   0]\n",
      " [  0   0   0 169   0   2   0]\n",
      " [  0   0   0 726   0   1   0]\n",
      " [  0   0   0   1   0   0   0]]\n"
     ]
    }
   ],
   "source": [
    "test_x = [[5,2,3],[2], [4,2], [1,2]]\n",
    "# it's going to go from the number of cols being the sequence length/ num of rows being batch size\n",
    "# to the number of rows being the max sequence length/ num cols being batch size\n",
    "# Essentially like a padding and then transpose\n",
    "def make_batch(x):\n",
    "    seq_lengths = [len(row) for row in x]\n",
    "    n_batches = len(x)\n",
    "    max_seq_length = max(seq_lengths)\n",
    "    outputs = np.zeros(shape=(max_seq_length, n_batches),dtype=np.int32)\n",
    "    for i in range(len(seq_lengths)):\n",
    "        for j in range(seq_lengths[i]):\n",
    "            outputs[j][i] = x[i][j]\n",
    "    return outputs\n",
    "\n",
    "print make_batch(test_x)\n",
    "print make_batch(text_en[0:7])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Very cool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 609,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.reset_default_graph()\n",
    "sess = tf.InteractiveSession()\n",
    "input_embedding_size = 64\n",
    "encoder_hidden_units = 200\n",
    "decoder_hidden_units = encoder_hidden_units\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `encoder_inputs` int32 tensor is shaped `[encoder_max_time, batch_size]`\n",
    "- `decoder_targets` int32 tensor is shaped `[decoder_max_time, batch_size]`\n",
    "- `decoder_inputs` int32 tensor is shaped `[decoder_max_time, batch_size]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 610,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encoder_inputs = tf.placeholder(shape=(None, None), dtype=tf.int32, name='encoder_inputs')\n",
    "decoder_targets = tf.placeholder(shape=(None, None), dtype=tf.int32, name='decoder_targets')\n",
    "decoder_inputs = tf.placeholder(shape=(None, None), dtype=tf.int32, name='decoder_inputs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 611,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "encoder_inputs_embedded = tf.nn.embedding_lookup(embed_vocab_en, encoder_inputs)\n",
    "decoder_inputs_embedded = tf.nn.embedding_lookup(embed_vocab_fr, decoder_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 612,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "encoder_cell = tf.contrib.rnn.LSTMCell(encoder_hidden_units)\n",
    "\n",
    "encoder_outputs, encoder_final_state = tf.nn.dynamic_rnn(encoder_cell, encoder_inputs_embedded,\n",
    "                                                         dtype=tf.float32, time_major=True)\n",
    "\n",
    "del encoder_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 613,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTMStateTuple(c=<tf.Tensor 'rnn/while/Exit_2:0' shape=(?, 200) dtype=float32>, h=<tf.Tensor 'rnn/while/Exit_3:0' shape=(?, 200) dtype=float32>)"
      ]
     },
     "execution_count": 613,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_final_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 614,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "decoder_cell = tf.contrib.rnn.LSTMCell(decoder_hidden_units)\n",
    "\n",
    "decoder_outputs, decoder_final_state = tf.nn.dynamic_rnn(\n",
    "                                decoder_cell, decoder_inputs_embedded,\n",
    "                                initial_state=encoder_final_state,\n",
    "                                dtype=tf.float32, time_major=True, \n",
    "                                scope=\"plain_decoder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 615,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"ArgMax:0\", shape=(?, ?), dtype=int64)\n",
      "Tensor(\"fully_connected/Reshape_1:0\", shape=(?, ?, 1000), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "decoder_logits = tf.contrib.layers.linear(decoder_outputs, fr_vocab_size)\n",
    "\n",
    "decoder_prediction = tf.argmax(decoder_logits, 2)\n",
    "print decoder_prediction\n",
    "print decoder_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 616,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stepwise_cross_entropy = tf.nn.softmax_cross_entropy_with_logits(\n",
    "    labels=tf.one_hot(decoder_targets, depth=fr_vocab_size, dtype=tf.float32),\n",
    "    logits=decoder_logits,\n",
    ")\n",
    "\n",
    "loss = tf.reduce_mean(stepwise_cross_entropy)\n",
    "train_op = tf.train.AdamOptimizer().minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 617,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 618,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_encoded:\n",
      "[[  2  24   9]\n",
      " [124 523  82]\n",
      " [243  23   0]]\n",
      "decoder inputs:\n",
      "[[1 1 1]\n",
      " [1 1 1]\n",
      " [1 1 1]\n",
      " [1 1 1]]\n",
      "decoder predictions:\n",
      "[[793 330 124]\n",
      " [793 968 124]\n",
      " [  6 968 124]\n",
      " [  6 968 124]]\n"
     ]
    }
   ],
   "source": [
    "batch_ = [[2,124,243], [24,523,23], [9, 82]]\n",
    "\n",
    "batch_ = make_batch(batch_)\n",
    "print('batch_encoded:\\n' + str(batch_))\n",
    "\n",
    "din_ = make_batch(np.ones(shape=(3, 4), dtype=np.int32))\n",
    "print('decoder inputs:\\n' + str(din_))\n",
    "\n",
    "pred_ = sess.run(decoder_prediction,\n",
    "    feed_dict={\n",
    "        encoder_inputs: batch_,\n",
    "        decoder_inputs: din_,\n",
    "    })\n",
    "print('decoder predictions:\\n' + str(pred_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 619,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def parallel_batches(text, batch_size):\n",
    "    num_remaining = len(text)\n",
    "    num_seqs = 0\n",
    "    while num_remaining>0:\n",
    "        b = 0\n",
    "        if num_remaining<batch_size:\n",
    "            b = text[num_seqs:num_seqs+num_remaining]\n",
    "            num_remaining -= num_remaining\n",
    "            num_seqs += num_remaining\n",
    "        else:\n",
    "            b = text[num_seqs:num_seqs+batch_size]\n",
    "            num_remaining -= batch_size\n",
    "            num_seqs += batch_size\n",
    "        yield b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 620,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5001\n"
     ]
    }
   ],
   "source": [
    "batch_size = 100\n",
    "print len(text_en)\n",
    "en_batches, fr_batches = next_parallel_batch(text_en, batch_size), next_parallel_batch(text_fr, batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 621,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def next_feed():\n",
    "    en_batch, fr_batch = next(en_batches), next(fr_batches)\n",
    "    encoder_inputs_ = make_batch(en_batch)\n",
    "    decoder_targets_ = make_batch([sequence for sequence in fr_batch])\n",
    "    decoder_inputs_ = make_batch([[1]+sequence[0:-1] for sequence in fr_batch])\n",
    "    return {\n",
    "        encoder_inputs: encoder_inputs_,\n",
    "        decoder_inputs: decoder_inputs_,\n",
    "        decoder_targets: decoder_targets_,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 622,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'int' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-622-2007c71bf1df>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch_n\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_batches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mfd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext_feed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mloss_track\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-621-f0faa583d174>\u001b[0m in \u001b[0;36mnext_feed\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mnext_feed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0men_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfr_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0men_batches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfr_batches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mencoder_inputs_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0men_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mdecoder_targets_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msequence\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msequence\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfr_batch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mdecoder_inputs_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0msequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msequence\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfr_batch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-585-34733ccbecb9>\u001b[0m in \u001b[0;36mnext_parallel_batch\u001b[0;34m(text, batch_size)\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0mnum_seqs\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mnum_remaining\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m             \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnum_seqs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mnum_seqs\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m             \u001b[0mnum_remaining\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0mnum_seqs\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'int' object is not callable"
     ]
    }
   ],
   "source": [
    "loss_track = []\n",
    "\n",
    "max_batches = len(text_en)\n",
    "batches_in_epoch = 1000\n",
    "\n",
    "try:\n",
    "    for batch_n in range(max_batches):\n",
    "        fd = next_feed()\n",
    "        _, l = sess.run([train_op, loss], fd)\n",
    "        loss_track.append(l)\n",
    "\n",
    "        if batch_n == 0 or batch_n % batches_in_epoch == 0:\n",
    "            print('batch {}'.format(batch_n))\n",
    "            print('  minibatch loss: {}'.format(sess.run(loss, fd)))\n",
    "            predict_ = sess.run(decoder_prediction, fd)\n",
    "            for i, (inp, pred) in enumerate(zip(fd[encoder_inputs].T, predict_.T)):\n",
    "                print('  sample {}:'.format(i + 1))\n",
    "                print('    input     > {}'.format(inp))\n",
    "                print('    actual    > {}'.format(trans(inp)))\n",
    "                print('    predicted > {}'.format(pred))\n",
    "                if i >= 2:\n",
    "                    break\n",
    "            print()\n",
    "except KeyboardInterrupt:\n",
    "    print('training interrupted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
